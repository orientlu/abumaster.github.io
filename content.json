[{"title":"","date":"2017-03-24T06:28:18.819Z","path":"2017/03/24/卷积网络应该注意的问题/","text":"title: 卷积网络应该注意的问题date: 2017-03-24 14:28:18categories: 深度学习 tags: [深度学习,caffe]卷积神经网络简介，由于其出色的特征提取特性，使得在计算机视觉方面有了很好的应用，并取得了出色的成绩。 ###1.卷积神经网络的几种基本操作卷积卷积操作是卷积网络中的核心操作，其主要目的是为了提取图像的显著特征，降低特征维数，进而来减少计算量。在 caffe 代码中的主要参数如下：1234567891011121314151617181920212223242526272829303132333435363738394041layer &#123; name: &quot;conv1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; #上层是数据层 top: &quot;conv1&quot; param &#123; #权重学习参数 lr_mult: 1 #权重学习率 需要乘以基础学习率base\\_lr decay_mult: 1 &#125; param &#123; #偏置学习参数 lr_mult: 2 decay_mult: 0 &#125; convolution_param &#123; #卷积参数 num_output: 96 #卷积操作后的输出特征图 kernel_size: 11 #卷积核大小 stride: 4 #步长 #可能也有pad为扩充边缘 weight_filler &#123; #权值初始化 type: &quot;gaussian&quot; #类型为weight-filter 或xavier算法等，默认constant，全部0 std: 0.01 &#125; bias_filler &#123; #偏置的初始化 type: &quot;constant&quot; value: 0 &#125; &#125;&#125;``` 输入：`n*c0*w0*h0` 输出：`n*c1*w1*h2` c1对应num_output，输出对应的大小计算: `w1 = (w0 + 2*pad - kernersize)/stride + 1` `h1 = (h0 + 2*pad - kernelsize)/stride + 1` 在 **caffe** 源码中的计算是将图像和卷积核通过 im2col 转换成矩阵，再对两矩阵内积。 **池化** 池化也称下采样，为了减少运算和数据维度的一种方式，被分为： + 最大池化（Max Pooling），取最大值； + 均值池化（Mean Pooling），取均值； + 高斯池化。 **caffe** 中的配置代码： layer { name: “pool1” type: “Pooling” bottom: “norm1” top: “pool1” pooling_param { #池化参数 pool: MAX #池化类型 kernel_size: 3 #池化核大小 stride: 2 #步长，重叠 }}123456789池化的计算公式与卷积操作类似： 输入：`n*c0*w0*h0` 输出：`n*c1*w1*h2` c1对应num_output，输出对应的大小计算: `w1 = (w0 + 2*pad - kernersize)/stride + 1` `h1 = (h0 + 2*pad - kernelsize)/stride + 1` **LRN层** LRN全称为Local Response Normalization，即局部响应归一化层，没什么用，有一些网络中加入了这一层，对局部区域进行归一化，配置信息和参数说明如下： layer { name: “norm1” type: “LRN” bottom: “conv1” top: “norm1” lrn_param { #参数 local_size: 5 #（1）通道间归一化时表示求和的通道数； #（2）通道内归一化时表示求和区间的边长； alpha: 0.0001 #缩放因子 beta: 0.75 #指数项 }}12345678910111213141516171819202122**激活函数**&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt; 激活函数需要具有以下特性： + 非线性； + 单调、连续可微分； + 范围不饱和，避免梯度为0； + 原点近似线性。 常用的激活函数有：**Sigmoid 函数**、**Tanh 函数**、**ReLU 函数**等。 如 **AlexNet** 中用到的ReLU激活函数： $$f(x)=max(0,x)$$ 这种激活函数的特点是：无梯度损耗，收敛速度快，网络稀疏性大，计算量小。缺点是，梯度大的话，导致权重更新以后变大，输出0，使得神经元不再更新。因此要注意学习率的设置。 **全连接层** 全连接层又称内积层（Inner-Product），是将特征图像全部展开为一维向量。 **caffe** 中的文档显示： + Input `n * c_i * h_i * w_i` + Output `n * c_o * 1 * 1` 这里引用了[dupuleng](http://www.cnblogs.com/dupuleng/articles/4312149.html)的例子。 lenet 网络配置文件中的一段： layers { name: “conv2” type: CONVOLUTION bottom: “pool1” top: “conv2” blobs_lr: 1 blobs_lr: 2 convolution_param { num_output: 50 kernel_size: 5 stride: 1 weight_filler { type: “xavier” } bias_filler { type: “constant” } }}layers { name: “pool2” type: POOLING bottom: “conv2” top: “pool2” pooling_param { pool: MAX kernel_size: 2 stride: 2 }}layers { name: “ip1” type: INNER_PRODUCT bottom: “pool2” top: “ip1” blobs_lr: 1 blobs_lr: 2 inner_product_param { num_output: 500 weight_filler { type: “xavier” } bias_filler { type: “constant” } }}`` conv2 的输入图像是2562727经过了卷积操作，输出502222同样作为了pool2的输入，进行池化，pool2的输出501111，下一层全连接层，输出50011的向量，是如何进行计算的呢？要把所有通道全部展开做卷积，首先要把pool2输出的特征图展开为一维向量，共需要500501111个参数，进行卷积，输出5001*1`的一维向量。","tags":[]},{"title":"Conditional Random Fields as Recurrent Neural Networks","date":"2017-03-21T08:00:18.000Z","path":"2017/03/21/CRFs-as-RNN/","text":"2015 年 ICCV 会议文章 Conditional Random Fields as Recurrent Neural Networks[1] 的阅读笔记。 关键词图像语义分割CRF as RNN摘要像素级别的标注任务，例如图像语义分割在图像理解方面占据着重要的作用。最近的方法开始利用深度学习技术在图像识别任务上的能力来解决像素级别的标注任务。现在的核心问题是深度学习方法在描绘可视化物体具有限制性。为了解决这个问题，我们提出了一个新形式的卷积网络，它结合了卷积网络的优势和条件随机场的概率图模型。为此，我们制定了使用高斯对模型和中值近似的条件随机场作为循环神经网络。这个网路就是 CRF-RNN 被嵌入到 CNN 中，最为一个集 CNNs 和 CRFs 优点于一体的深度网络。更重要的是，我们的系统完全在 CNNs 中集成了 CRF 模型，让使用传统的反向传播算法训练端对端的系统成为了可能，不需要额外的后期处理物体的边界。MarkDown 中使用公式 加入脚本定义，现在用到的是 MathJax 引擎12&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt; 使用Tex公式 $$行间公式；\\\\行内公式，参考MathJax basic tutorial and quick reference 示例$$x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$$ 引言低层次计算机视觉问题，为图像中的像素分配标签。特征表示在个体像素分类中占有重要的作用。同样要考虑到图像的边界和特征、空间关系，以此来获得较为准确地分割结果。设计出一个强大的特征表示器是像素级别标记的关键挑战。传统的方法不再讨论，现在深度学习的方法利用大尺度的卷积网络，在高层次视觉上取得了非常大的成果。这激励着利用卷积网络去解决低层次的问题。主要利用卷积网络提取特征替代以前的手工标注特征。将用于高层视觉的分类网络转换成低层次视觉的任务依然存在着一些问题提出了几个问题： 传统的卷积网络有大接受域的卷积过滤器，会产生比较粗糙的输出图。最大池化层的出现，过滤掉一些特征，导致了输出的分割图不够精细。 缺少了平滑度约束，没有考虑到相似的像素，空间或者外形相似的约束，导致了输出图的边界不明确，或者出现杂散区域。尤其是马尔科夫随机场（MRFs）和它的变体条件随机场（CRFs）已经成为应用到计算机视觉领域中一个成功的模型。用于像素标记的CRFs推理主要的思想是将语义标签分配问题转换成概率推理问题，包括了相似像素之间一致性并入假设。CRFs可以微调分割图的细节，优化边界问题，克服了单纯利用CNNs的缺点。用CRFs作为后期的处理，无法发挥出CRF的优势，卷积网络在训练的阶段也无法根据CRF的表现来调整权重。本文将CNN与CRF结合为一个统一的框架，可以共同训练。相关工作许多方法用深度学习来解决图像语义分割问题，可以归为以下两个类别： 特征提取和分割分离开的策略。使用CNN提取有意义的图像特征，利用超像素去构造图像的模式。首先从图像中获得超像素，再用特征提取器提取特征。存在着一个致命的缺点，前期如果有误差，后面误差越来越大。与他们的方案不同，此文用典型的图模型CRF可以被作为RNN，指定为深度网络的一部分。结合CNN实现端对端的训练。 直接学习从原始图像到标记图像的非线性模型。例如FCN等网络，去掉了最后的全连接层变为卷积层。全连接条件随机场 条件随机场进行图像语义分割的能量函数：定义隐变量Xi为像素点i的分类标签，取值范围为分类语义标签L={l1,l2,l3,…,ln}；Yi为每个随机变量Xi的观测值，即是每个像素的颜色值。条件随机场的目标就是通过观测变量Yi，推理出潜变量Xi的标签。对于一张图像，可以看成图模型G=(V,E)，每个顶点对应了V={X1,X2,...,Xn}，对于边来说，全连接的条件随机场，顶点与所有的点都有连线。条件随机场的目标函数：能量函数有一元势函数和二元势函数，分别表示了当像素点i的观测值是yi时，该像素点属于标签xi的概率。可以直接从cnn中计算出。二元是函数是两个像素值相似或者相邻则两个像素属于同一类的概率很大。实现 参考文献[1] Zheng S, Jayasumana S, Romera-Paredes B, et al. Conditional random fields as recurrent neural networks[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 1529-1537.","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"柔性数组","date":"2017-03-12T13:59:48.000Z","path":"2017/03/12/柔性数组/","text":"C/C++中的0长数组 定义：柔性数组（Flexible Array）也叫伸缩性数组、变长数组。 作用 ：放入结构体中，可以存放动态长度的字符串、数组等。 用法举例：放在结构体的最后，长度为0的数组。长度为0不占用任何空间，数组名只是一个符号，代表了一个不可改变的地址。 1234struct package &#123; int len; char data[0];&#125;; 用途：根据变长数组的特性很容易构造出一些数据结构，缓冲区、数据包等。不会浪费多余的空间，用多少申请多少。 使用:假设用上面的结构来发送1024字节大小的数据包，首先要构造一个数据包：1234char *pMsg = (char *)malloc(sizeof(package)+1024); package *pPack = (package*)pMsg;pPack-&gt;len = 1024;memcpy(pPack-&gt;data, source, 1024); 强制类型转换，将package类型的指针指向了申请的内存的开始，分为两个部分：前一部分表示字符串的长度，后一部分表示实际的内容。将整个数据包发出去，不会浪费一点额外的空间，在网络中传输节省了流量，提升了速度。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]}]