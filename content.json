[{"title":"libev源码阅读3：定时器","date":"2017-08-01T06:51:24.000Z","path":"2017/08/01/libev源码阅读3：定时器/","text":"定时器作为libev的一个重要监测器，用于超时处理和周期执行任务，通过4叉最小堆管理定时器，据说高效利用CPU缓存。 堆的概念堆是一种树形结构，分为最大堆和最小堆，分别是根节点是最大元素或最小元素，stl中利用二叉大顶堆实现优先级队列以及堆算法。堆的节点一般存放在数组中，在数组的排列有一定的规律，堆没有节点漏洞，按层依次排列的，如堆是从数组array的索引为1的位置开始排列，那么某个节点位于i的位置，其左孩子位于2i处，右孩子位于2i+1处，父节点位于i/2处（/ 为取整）。从0开始排列，节点i的左右孩子节点的索引分别为2i+1，2i+2，父节点为(i-1)/2 。n叉堆的孩子[ni+1,…,ni+n]对于堆的调整，一般用到向上调整和向下调整两种方式，下面结合代码详细注释。 四叉堆libev中的四叉堆的根节点索引是3，从3开始依次向后排列，那么i节点的孩子的范围为[4(i-3)+1+3,…,4(i-3)+4+3]，父节点为(i-3-1)/4+3 。堆元素的结构 12345678//使用缓存的情况下typedef struct &#123; ev_tstamp at; WT w; &#125; ANHE;#define ANHE_w(he) (he).w /* access watcher, read-write */#define ANHE_at(he) (he).at /* access cached at, read-only */#define ANHE_at_cache(he) (he).at = (he).w-&gt;at /* update at from watcher */ 堆算法实现如下：downheap 函数：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#if EV_USE_4HEAP //如果定义了4叉堆#define DHEAP 4#define HEAP0 (DHEAP - 1) /* index of first element in heap */#define HPARENT(k) ((((k) - HEAP0 - 1) / DHEAP) + HEAP0) //获得k的父节点#define UPHEAP_DONE(p,k) ((p) == (k)) //是否更新完成//从根向下调整，N为堆的元素个数，k表示要调整元素的索引inline_speed voiddownheap (ANHE *heap, int N, int k)&#123; ANHE he = heap [k];//先获得调整 ANHE *E = heap + N + HEAP0;//结束的指针 for (;;) &#123; ev_tstamp minat; //最小的元素 ANHE *minpos; //最小元素的指针 ANHE *pos = heap + DHEAP * (k - HEAP0) + HEAP0 + 1;//k的第一个孩子的指针 //查找k的最小孩子 if (expect_true (pos + DHEAP - 1 &lt; E))//最后一个孩子没有越界，有四个孩子 &#123; //在四个孩子中找最小的 (minpos = pos + 0), (minat = ANHE_at (*minpos));//设置初值 if (ANHE_at (pos [1]) &lt; minat) (minpos = pos + 1), (minat = ANHE_at (*minpos)); if (ANHE_at (pos [2]) &lt; minat) (minpos = pos + 2), (minat = ANHE_at (*minpos)); if (ANHE_at (pos [3]) &lt; minat) (minpos = pos + 3), (minat = ANHE_at (*minpos)); &#125; else if (pos &lt; E)//有孩子，但是不是4个孩子 &#123; (minpos = pos + 0), (minat = ANHE_at (*minpos)); if (pos + 1 &lt; E &amp;&amp; ANHE_at (pos [1]) &lt; minat) (minpos = pos + 1), (minat = ANHE_at (*minpos)); if (pos + 2 &lt; E &amp;&amp; ANHE_at (pos [2]) &lt; minat) (minpos = pos + 2), (minat = ANHE_at (*minpos)); if (pos + 3 &lt; E &amp;&amp; ANHE_at (pos [3]) &lt; minat) (minpos = pos + 3), (minat = ANHE_at (*minpos)); &#125; else //其他情况，没孩子，不用调整退出循环 break; //当前节点小于最小孩子，已经是最小堆，不用调整退出 if (ANHE_at (he) &lt;= minat) break; //否则将最小元素调到k的位置 heap [k] = *minpos; ev_active (ANHE_w (*minpos)) = k;//将时间监测器设置为索引k k = minpos - heap;//设置下一次调整的根节点 &#125; heap [k] = he;//将元素填充到k中 ev_active (ANHE_w (he)) = k;&#125; 如果没有定义四叉堆的宏，那么就是简单的二叉堆的定义和调整。upheap 函数：1234567891011121314151617181920//从k向根调整inline_speed voidupheap (ANHE *heap, int k)&#123; ANHE he = heap [k];//先记录k位置的元素 //循环调整 for (;;) &#123; int p = HPARENT (k);//获得k的父节点 //是否等于父节点（调整完成）或者父节点的元素小于当前的 if (UPHEAP_DONE (p, k) || ANHE_at (heap [p]) &lt;= ANHE_at (he)) break; heap [k] = heap [p];// ev_active (ANHE_w (heap [k])) = k; k = p; &#125; heap [k] = he; ev_active (ANHE_w (he)) = k;&#125; adjust 和 reheap 函数1234567891011121314151617181920/* move an element suitably so it is in a correct place */inline_size voidadjustheap (ANHE *heap, int N, int k)&#123; if (k &gt; HEAP0 &amp;&amp; ANHE_at (heap [k]) &lt;= ANHE_at (heap [HPARENT (k)])) upheap (heap, k);//k的元素小于父节点的元素，向上调整 else downheap (heap, N, k);//向下调整&#125;/* rebuild the heap: this function is used only once and executed rarely */inline_size voidreheap (ANHE *heap, int N)&#123; int i; /* we don't use floyds algorithm, upheap is simpler and is more cache-efficient */ /* also, this is easy to implement and correct for both 2-heaps and 4-heaps */ for (i = 0; i &lt; N; ++i)//直接向上调整，简单高效 upheap (heap, i + HEAP0);&#125; 超时监视器基本数据结构相对时间。 123456789101112typedef struct ev_timer&#123; //EV_WATCHER_TIME (ev_timer) int active; int pending; int priority; void *data; void (*cb)(struct ev_loop *loop, struct ev_timer *w, int revents); ev_tstamp at; //定时器第一次触发的时间点 ev_tstamp repeat; /* rw */ //每隔几秒触发一次，0表示只触发一次&#125; ev_timer; 初始化超时监视器123456789101112131415//初始化，调用两个宏来初始化成员#define ev_timer_init(ev,cb,after,repeat) \\do &#123; ev_init ((ev), (cb)); \\ ev_timer_set ((ev),(after),(repeat)); \\ &#125; while (0)#define ev_init(ev,cb_) do &#123; \\ ((ev_watcher *)(void *)(ev))-&gt;active = \\ ((ev_watcher *)(void *)(ev))-&gt;pending = 0; \\ ev_set_priority ((ev), 0); \\ ev_set_cb ((ev), cb_); \\&#125; while (0)#define ev_timer_set(ev,after_,repeat_) \\do &#123; ((ev_watcher_time *)(ev))-&gt;at = (after_); \\ (ev)-&gt;repeat = (repeat_); &#125; while (0) 启动超时器1234567891011121314151617181920212223noinlinevoidev_timer_start (EV_P_ ev_timer *w) EV_THROW&#123; if (expect_false (ev_is_active (w))) return; ev_at (w) += mn_now;//设置at时间点，此时间点触发，相对于mn_now，当前日历时间 assert ((\"libev: ev_timer_start called with negative timer repeat value\", w-&gt;repeat &gt;= 0.)); EV_FREQUENT_CHECK; //将timer加入到堆中并向上调整，active表示的是堆数组中的下标 ++timercnt; ev_start (EV_A_ (W)w, timercnt + HEAP0 - 1); array_needsize (ANHE, timers, timermax, ev_active (w) + 1, EMPTY2); ANHE_w (timers [ev_active (w)]) = (WT)w; ANHE_at_cache (timers [ev_active (w)]); upheap (timers, ev_active (w)); EV_FREQUENT_CHECK; /*assert ((\"libev: internal timer heap corruption\", timers [ev_active (w)] == (WT)w));*/&#125; 停止计时器123456789101112131415161718192021222324noinlinevoidev_timer_stop (EV_P_ ev_timer *w) EV_THROW&#123; clear_pending (EV_A_ (W)w);//从pending中移除 if (expect_false (!ev_is_active (w))) return; EV_FREQUENT_CHECK; &#123; int active = ev_active (w);//获得定时器在堆中的索引 assert ((\"libev: internal timer heap corruption\", ANHE_w (timers [active]) == (WT)w)); --timercnt;//数量减一 if (expect_true (active &lt; timercnt + HEAP0)) &#123; timers [active] = timers [timercnt + HEAP0];//最后一个元素补充上来 adjustheap (timers, timercnt, active);//调整 &#125; &#125; ev_at (w) -= mn_now; ev_stop (EV_A_ (W)w); EV_FREQUENT_CHECK;&#125; 周期定时器","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"},{"name":"libev","slug":"libev","permalink":"http://abumaster.com/tags/libev/"}]},{"title":"libev源码阅读2：运行流程","date":"2017-07-31T10:39:49.000Z","path":"2017/07/31/libev源码阅读2：运行流程/","text":"一般的流程：创建默认的事件循环，创建一个事件监测器和回调函数并初始化（init），将监测器放入事件循环（start）中，循环开始等待事件（run）的到来。 1.主要流程如果在libev中创建一个IO监测器，主循环等待IO事件的触发，触发后调用回调函数，执行相关操作。其主要流程如下： 首先调用ev_default_loop初始化struct ev_loop结构； 然后调用ev_io_init初始化监视器中的属性，该宏主要就是调用ev_init和ev_io_set； 然后调用ev_io_start启动该监视器，该函数主要是将监视器添加到loop-&gt;anfds结构中，将监视的描述符添加到((loop)-&gt;fdchanges)中； 调用ev_run开始等待事件的触发。 使用，官方提供的代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344// a single header file is required#include &lt;ev.h&gt;#include &lt;stdio.h&gt; // for puts// every watcher type has its own typedef'd struct// with the name ev_TYPEev_io stdin_watcher;ev_timer timeout_watcher;// all watcher callbacks have a similar signature// this callback is called when data is readable on stdinstatic voidstdin_cb (EV_P_ ev_io *w, int revents)&#123; puts (\"stdin ready\"); // for one-shot events, one must manually stop the watcher // with its corresponding stop function. ev_io_stop (EV_A_ w); // this causes all nested ev_run's to stop iterating ev_break (EV_A_ EVBREAK_ALL);&#125;// another callback, this time for a time-outstatic voidtimeout_cb (EV_P_ ev_timer *w, int revents)&#123; puts (\"timeout\"); // this causes the innermost ev_run to stop iterating ev_break (EV_A_ EVBREAK_ONE);&#125;int main (void)&#123; // use the default event loop unless you have special needs struct ev_loop *loop = EV_DEFAULT; // initialise an io watcher, then start it // this one will watch for stdin to become readable ev_io_init (&amp;stdin_watcher, stdin_cb, /*STDIN_FILENO*/ 0, EV_READ); ev_io_start (loop, &amp;stdin_watcher); // initialise a timer watcher, then start it // simple non-repeating 5.5 second timeout ev_timer_init (&amp;timeout_watcher, timeout_cb, 5.5, 0.); ev_timer_start (loop, &amp;timeout_watcher); // now wait for events to arrive ev_run (loop, 0); // break was called, so exit return 0;&#125; 其中有几个奇怪的宏EV_P EV_P_ EV_A EV_A_，它们代表了： 1234EV_P == struct ev_loop* loop //event parameterEV_P_ == EV_P, == struct ev_loop* loop, EV_A == loop //event argumentEV_A_ == EV_A, == loop, 2.ev_default_loop 函数假设定义了EV_MULTIPLICITY，多循环支持，返回一个ev_loop结构指针，否则返回一个整数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121struct ev_loop * ev_default_loop (unsigned int flags) EV_THROW&#123; if (!ev_default_loop_ptr) &#123;#if EV_MULTIPLICITY EV_P = ev_default_loop_ptr = &amp;default_loop_struct;#else ev_default_loop_ptr = 1;#endif//调用此函数初始化 loop_init (EV_A_ flags); if (ev_backend (EV_A)) &#123;#if EV_CHILD_ENABLE ev_signal_init (&amp;childev, childcb, SIGCHLD); ev_set_priority (&amp;childev, EV_MAXPRI); ev_signal_start (EV_A_ &amp;childev); ev_unref (EV_A); /* child watcher should not keep loop alive */#endif &#125; else ev_default_loop_ptr = 0; &#125; return ev_default_loop_ptr;&#125;//以下是loop_init函数，初始化loop中的各个成员/* initialise a loop structure, must be zero-initialised */noinline ecb_coldstatic voidloop_init (EV_P_ unsigned int flags) EV_THROW&#123; if (!backend) &#123; origflags = flags;#if EV_USE_REALTIME if (!have_realtime) &#123; struct timespec ts; if (!clock_gettime (CLOCK_REALTIME, &amp;ts)) have_realtime = 1; &#125;#endif#if EV_USE_MONOTONIC if (!have_monotonic) &#123; struct timespec ts; if (!clock_gettime (CLOCK_MONOTONIC, &amp;ts)) have_monotonic = 1; &#125;#endif#ifndef _WIN32 if (flags &amp; EVFLAG_FORKCHECK) curpid = getpid ();#endif if (!(flags &amp; EVFLAG_NOENV) &amp;&amp; !enable_secure () &amp;&amp; getenv (\"LIBEV_FLAGS\")) flags = atoi (getenv (\"LIBEV_FLAGS\")); ev_rt_now = ev_time (); mn_now = get_clock (); now_floor = mn_now; rtmn_diff = ev_rt_now - mn_now;#if EV_FEATURE_API invoke_cb = ev_invoke_pending;#endif io_blocktime = 0.; timeout_blocktime = 0.; backend = 0; backend_fd = -1; sig_pending = 0;#if EV_ASYNC_ENABLE async_pending = 0;#endif pipe_write_skipped = 0; pipe_write_wanted = 0; evpipe [0] = -1; evpipe [1] = -1;#if EV_USE_INOTIFY fs_fd = flags &amp; EVFLAG_NOINOTIFY ? -1 : -2;#endif#if EV_USE_SIGNALFD sigfd = flags &amp; EVFLAG_SIGNALFD ? -2 : -1;#endif if (!(flags &amp; EVBACKEND_MASK)) flags |= ev_recommended_backends ();#if EV_USE_IOCP if (!backend &amp;&amp; (flags &amp; EVBACKEND_IOCP )) backend = iocp_init (EV_A_ flags);#endif#if EV_USE_PORT if (!backend &amp;&amp; (flags &amp; EVBACKEND_PORT )) backend = port_init (EV_A_ flags);#endif#if EV_USE_KQUEUE if (!backend &amp;&amp; (flags &amp; EVBACKEND_KQUEUE)) backend = kqueue_init (EV_A_ flags);#endif#if EV_USE_EPOLL if (!backend &amp;&amp; (flags &amp; EVBACKEND_EPOLL )) backend = epoll_init (EV_A_ flags);#endif#if EV_USE_POLL if (!backend &amp;&amp; (flags &amp; EVBACKEND_POLL )) backend = poll_init (EV_A_ flags);#endif#if EV_USE_SELECT if (!backend &amp;&amp; (flags &amp; EVBACKEND_SELECT)) backend = select_init (EV_A_ flags);#endif //如上一章介绍的函数，初始化调用前事件，准备好了，其实什么也没做 //表示在此期间等待监测器到来 ev_prepare_init (&amp;pending_w, pendingcb);#if EV_SIGNAL_ENABLE || EV_ASYNC_ENABLE ev_init (&amp;pipe_w, pipecb);//初始化监测器的pipe ev_set_priority (&amp;pipe_w, EV_MAXPRI);//设置为最大优先级#endif &#125;&#125; 3.ev_io_init 函数初始化io监测器，初始化结构中的成员，上一节中介绍了。4.ev_io_start 函数1234567891011121314151617181920212223242526272829303132333435363738394041void ev_io_start (EV_P_ ev_io *w) EV_THROW&#123; int fd = w-&gt;fd;//获得监视器的描述符 //监视器没开始 if (expect_false (ev_is_active (w))) return; assert ((\"libev: ev_io_start called with negative fd\", fd &gt;= 0)); //屏蔽其他的 //0x80 0x01 0x02 events的取值 assert ((\"libev: ev_io_start called with illegal event mask\", !(w-&gt;events &amp; ~(EV__IOFDSET | EV_READ | EV_WRITE)))); EV_FREQUENT_CHECK; //调整优先级并设置为活动状态， ev_start (EV_A_ (W)w, 1); //调整loop-&gt;anfds数组的大小，并将监测器加入到[fd]的链表中 array_needsize (ANFD, anfds, anfdmax, fd + 1, array_init_zero); wlist_add (&amp;anfds[fd].head, (WL)w); /* common bug, apparently */ assert ((\"libev: ev_io_start called with corrupted watcher\", ((WL)w)-&gt;next != (WL)w)); fd_change (EV_A_ fd, w-&gt;events &amp; EV__IOFDSET | EV_ANFD_REIFY); w-&gt;events &amp;= ~EV__IOFDSET;//掩码消除 EV_FREQUENT_CHECK;&#125;//fd_change函数/* something about the given fd changed */inline_size void fd_change (EV_P_ int fd, int flags)&#123; unsigned char reify = anfds [fd].reify; anfds [fd].reify |= flags; if (expect_true (!reify))//以前不存在，调整大小加入变化数组中 &#123; ++fdchangecnt; array_needsize (int, fdchanges, fdchangemax, fdchangecnt, EMPTY2); fdchanges [fdchangecnt - 1] = fd; &#125;&#125; 4.ev_run 函数主要功能循环等待事件的到来。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168int ev_run (EV_P_ int flags)&#123;#if EV_FEATURE_API ++loop_depth;#endif assert ((\"libev: ev_loop recursion during release detected\", loop_done != EVBREAK_RECURSE)); loop_done = EVBREAK_CANCEL; EV_INVOKE_PENDING; /* in case we recurse, ensure ordering stays nice and clean */ do &#123;#if EV_VERIFY &gt;= 2 ev_verify (EV_A);#endif#ifndef _WIN32 if (expect_false (curpid)) /* penalise the forking check even more */ if (expect_false (getpid () != curpid)) &#123; curpid = getpid (); postfork = 1; &#125;#endif#if EV_FORK_ENABLE /* we might have forked, so queue fork handlers */ if (expect_false (postfork)) if (forkcnt) &#123; queue_events (EV_A_ (W *)forks, forkcnt, EV_FORK); EV_INVOKE_PENDING; &#125;#endif#if EV_PREPARE_ENABLE /* queue prepare watchers (and execute them) */ if (expect_false (preparecnt)) &#123; queue_events (EV_A_ (W *)prepares, preparecnt, EV_PREPARE); EV_INVOKE_PENDING; &#125;#endif if (expect_false (loop_done)) break; /* we might have forked, so reify kernel state if necessary */ if (expect_false (postfork)) loop_fork (EV_A); //检测fd fd_reify (EV_A); /* 计算阻塞的时间 */ &#123; ev_tstamp waittime = 0.; ev_tstamp sleeptime = 0.; /* remember old timestamp for io_blocktime calculation */ ev_tstamp prev_mn_now = mn_now; /* update time to cancel out callback processing overhead */ time_update (EV_A_ 1e100); /* from now on, we want a pipe-wake-up */ pipe_write_wanted = 1; ECB_MEMORY_FENCE; /* make sure pipe_write_wanted is visible before we check for potential skips */ if (expect_true (!(flags &amp; EVRUN_NOWAIT || idleall || !activecnt || pipe_write_skipped))) &#123; waittime = MAX_BLOCKTIME; if (timercnt) &#123; ev_tstamp to = ANHE_at (timers [HEAP0]) - mn_now; if (waittime &gt; to) waittime = to; &#125;#if EV_PERIODIC_ENABLE if (periodiccnt) &#123; ev_tstamp to = ANHE_at (periodics [HEAP0]) - ev_rt_now; if (waittime &gt; to) waittime = to; &#125;#endif /* don't let timeouts decrease the waittime below timeout_blocktime */ if (expect_false (waittime &lt; timeout_blocktime)) waittime = timeout_blocktime; /* at this point, we NEED to wait, so we have to ensure */ /* to pass a minimum nonzero value to the backend */ if (expect_false (waittime &lt; backend_mintime)) waittime = backend_mintime; /* extra check because io_blocktime is commonly 0 */ if (expect_false (io_blocktime)) &#123; sleeptime = io_blocktime - (mn_now - prev_mn_now); if (sleeptime &gt; waittime - backend_mintime) sleeptime = waittime - backend_mintime; if (expect_true (sleeptime &gt; 0.)) &#123; ev_sleep (sleeptime); waittime -= sleeptime; &#125; &#125; &#125;#if EV_FEATURE_API ++loop_count;#endif assert ((loop_done = EVBREAK_RECURSE, 1)); /* assert for side effect */ backend_poll (EV_A_ waittime); assert ((loop_done = EVBREAK_CANCEL, 1)); /* assert for side effect */ pipe_write_wanted = 0; /* just an optimisation, no fence needed */ ECB_MEMORY_FENCE_ACQUIRE; if (pipe_write_skipped) &#123; assert ((\"libev: pipe_w not active, but pipe not written\", ev_is_active (&amp;pipe_w))); ev_feed_event (EV_A_ &amp;pipe_w, EV_CUSTOM); &#125; /* update ev_rt_now, do magic */ time_update (EV_A_ waittime + sleeptime); &#125; /* queue pending timers and reschedule them */ timers_reify (EV_A); /* relative timers called last */#if EV_PERIODIC_ENABLE periodics_reify (EV_A); /* absolute timers called first */#endif#if EV_IDLE_ENABLE /* queue idle watchers unless other events are pending */ idle_reify (EV_A);#endif#if EV_CHECK_ENABLE /* queue check watchers, to be executed first */ if (expect_false (checkcnt)) queue_events (EV_A_ (W *)checks, checkcnt, EV_CHECK);#endif EV_INVOKE_PENDING; &#125; while (expect_true ( activecnt &amp;&amp; !loop_done &amp;&amp; !(flags &amp; (EVRUN_ONCE | EVRUN_NOWAIT)) )); if (loop_done == EVBREAK_ONE) loop_done = EVBREAK_CANCEL;#if EV_FEATURE_API --loop_depth;#endif return activecnt;&#125;","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"},{"name":"libev","slug":"libev","permalink":"http://abumaster.com/tags/libev/"}]},{"title":"libev源码阅读1：数据结构","date":"2017-07-31T02:08:24.000Z","path":"2017/07/31/libev源码阅读1：数据结构/","text":"libev 是一个高性能事件循环网络库，用于开发高性能网络应用。 1.基础宏定义libev中的监视器数据结构的实现是用宏定义以及结构体来实现继承关系，基本的宏定义，展开。123456789101112131415161718/* 所有的监视器共有的数据 */#define EV_WATCHER(type) \\ int active; /* private */ \\ int pending; /* private */ \\ //EV_DECL_PRIORITY /* private */ \\ int priority; \\ //EV_COMMON /* rw */ \\ void *data; \\ //EV_CB_DECLARE (type) /* private */ void (*cb)(EV_P_ struct type *w, int revents);#define EV_WATCHER_LIST(type) \\ EV_WATCHER (type) \\ struct ev_watcher_list *next; /* private */#define EV_WATCHER_TIME(type) \\ EV_WATCHER (type) \\ ev_tstamp at; /* private */ 2.监视器基类由上面的宏定义可以推断，libev的监视器的实现是从watcher，watcher_list和watcher_time三类中派生出去，分为这三个大类，三个基类。12345678910111213141516171819202122232425262728293031//基本监视器 基类typedef struct ev_watcher&#123; int active; int pending; int priority; void *data; void (*cb)(EV_P_ struct type *w, int revents);&#125; ev_watcher;//监视器链表 基类typedef struct ev_watcher_list&#123; int active; int pending; int priority; void *data; void (*cb)(EV_P_ struct type *w, int revents); //list的下一个节点 struct ev_watcher_list *next;&#125; ev_watcher_list;//时间监视器 基类typedef struct ev_watcher_time&#123; int active; int pending; int priority; void *data; void (*cb)(EV_P_ struct type *w, int revents); //计时器时间 ev_tstamp at;&#125; ev_watcher_time; 3.监视的事件libev从三个监视器基类中派生出以下几种类，用于监视事件的变化，主要的分类和作用如下： 类型 作用 ev_io IO 可读可写 ev_singnal 信号处理 ev_timer 定时器 ev_periodic 周期任务 ev_child 子进程状态变化 ev_fork 开辟子进程 ev_stat 文件属性变化 ev_async 激活线程 ev_cleanup 退出触发 ev_idle 空闲时执行 ev_embed 嵌入其他事件循环 ev_prepare eventloop之前 ev_check eventloop之后 1234567891011121314151617181920212223242526272829303132333435363738//io监视器typedef struct ev_io&#123; //EV_WATCHER_LIST (ev_io) //展开宏 int active; int pending; int priority; void *data; void (*cb)(EV_P_ struct type *w, int revents); struct ev_watcher_list *next; int fd; /* ro */ int events; /* ro */&#125; ev_io;//定时器typedef struct ev_timer&#123; //EV_WATCHER_TIME (ev_timer) //展开 int active; int pending; int priority; void *data; void (*cb)(EV_P_ struct type *w, int revents); ev_tstamp at; ev_tstamp repeat; /* rw */&#125; ev_timer;//空闲时触发typedef struct ev_idle&#123; //EV_WATCHER (ev_idle) 展开 int active; int pending; int priority; void *data; void (*cb)(EV_P_ struct type *w, int revents);&#125; ev_idle; 关系图：这种继承关系，可以用指针进行类型自由转换。12345678910111213141516171819//激活监测器，不管是何类型void ev_start (struct ev_loop *loop, ev_watcher* w, int active) &#123; //... w-&gt;active = active; //... &#125; void wlist_add (ev_watcher_list **head, ev_watcher_list *elem) &#123; elem-&gt;next = *head; *head = elem; &#125; void ev_io_start (struct ev_loop *loop, ev_io *w) &#123; //将ev_io退化为ev_watcher使用这个ev_start函数 ev_start (loop, (ev_watcher*)w, 1); //转换成ev_watcher_list指针插入到list中 wlist_add (&amp;anfds[fd].head, (ev_watcher_list *)w); &#125; 4.监视事件的初始化和设置ev的设置也被定义为宏macro，提供了两种方式： ev_init 和 ev_TYPE_set 一起使用； 使用 ev_TYPE_init 进行初始化。 12345678910111213#define ev_init(ev,cb_) do &#123; \\ ((ev_watcher *)(void *)(ev))-&gt;active = \\ ((ev_watcher *)(void *)(ev))-&gt;pending = 0; \\ ev_set_priority ((ev), 0); \\ ev_set_cb ((ev), cb_); \\&#125; while (0)#define ev_io_set(ev,fd_,events_) \\ do &#123; (ev)-&gt;fd = (fd_); (ev)-&gt;events = (events_) | EV__IOFDSET; &#125; while (0)#define ev_io_init(ev,cb,fd,events) \\ do &#123; ev_init ((ev), (cb)); \\ ev_io_set ((ev),(fd),(events)); &#125; while (0)","tags":[{"name":"C","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"},{"name":"libev","slug":"libev","permalink":"http://abumaster.com/tags/libev/"}]},{"title":"STL源码剖析-容器","date":"2017-07-19T07:04:58.000Z","path":"2017/07/19/STL源码剖析-容器/","text":"容器概述容器 用于存放数据，数据在其中的排列具有一定的规律。STL中根据数据的排列方式将容器分为了 序列式容器 和 关联式容器 两种。其中的分类关系如下图所示： 序列式容器vectorvector连续线性空间存储，支持随机访问，类似数组。vector的迭代器是一个T类型的原生指针；vector的空间不是按需分配而是按照多分配的原则，比实际需要的空间要大，也就是说会保留一部分的备用空间用于插入元素，分别定义了三个迭代器指向了目前使用空间的头和尾，可用空间的尾。start finish end_of_storage 定义了函数 size() 和 capacity 分别表示使用空间的大小，以及最大容纳的大小；vector的空间扩充，当没有足够的备用空间用于插入新的元素的时候，这时vecto需要进行空间的扩展，会申请一块原始大小二倍的新空间然后将旧的空间中的元素拷贝入新的空间，也就是说原始的迭代器在执行插入操作后会失效；vector存在的缺点，就是可能浪费一部分空间。 listlist 在stl中的实现是一个双向链表，节点结构是有一个指向后一个节点和前一个节点的指针以及节点中的数据，每次插入和删除元素都要重新配置和释放节点，空间按需分配，插入操作不会改变迭代器。list迭代器设计，内部依然是一个指针，指向了list的节点，内部定义了stl迭代器标准的接口，并实现了双向迭代器具有的操作，自增，自减，取值，比较等；list数据结构，双向循环链表，一些操作就是链表的指针的移动；一个内部函数transfer(position, first, last)将[first,last)内的元素移动到position之前。为splice、merge、sort提供基础。操作见图：12345678910111213void transfer(iterator position, iterator first, iterator last) &#123; if (position != last) &#123; (*(link_type((*last.node).prev))).next = position.node; // (1) (*(link_type((*first.node).prev))).next = last.node; // (2) (*(link_type((*position.node).prev))).next = first.node; // (3) link_type tmp = link_type((*position.node).prev); // (4) (*position.node).prev = (*last.node).prev; // (5) (*last.node).prev = (*first.node).prev; // (6) (*first.node).prev = tmp; // (7) &#125;&#125; list 本身提供了排序的成员函数，不用stl算法（接受随机迭代器）。 dequedeque由一些列连续的空间组成，可以分别在头尾扩展插入。有一个中控器map指向连续的一段段的缓冲区。deque的迭代器，包括了 1234567/***-----------------------------| cur | first | last | node |-----------------------------当前指向，缓冲区的开始和结束在map中的位置***/ deque的数据结构，迭代器start指向第一个节点，finish指向最后一个节点，map指向中控器，是连续的空间，每个元素都是一个指针，指向了一个节点（缓冲区）。在deque上进行元素操作时，考虑在中控器的移动。 stack和queuestack先进后出，没有迭代器，queue先进先出，它们都是以deque为底部数据结构（默认），进行一定的限制保证它们各自的特性，不被称为容器，而是被称为配接器。 heap算法和优先级队列堆不是stl容器组件，但是却是优先级队列的底层实现。它是一棵二叉树，根节点元素是最大或者最小元素，每次插入和取出根节点后都会重新排列保持它的这个特性。 单链表关联式容器主要有set集合和map映射表两种，底部以红黑二叉树实现。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://abumaster.com/tags/STL/"}]},{"title":"像素反卷积网络","date":"2017-07-11T07:30:10.000Z","path":"2017/07/11/像素反卷积网络/","text":"Pixel Deconvolutional Networks Hongyang Gao etc. 2017.1.7 主要介绍了对于传统反卷积操作的新解读。读此论文，做如下笔记。 1.引子反卷积层被广泛地应用在各种各样的深度模型中用于上采样，其中包括了用于语义分割的编码-解码网络、用于无监督学习的深度生成模型。反卷积层容易造成棋盘问题，使得输出的特征图的临近像素没有直接的关系。为了解决这个问题，提出了一种像素反卷积层，在输出特征图的临近像素之间建立一个直接的关系。是对反卷积操作的新的解读，因此可以取代任何的使用反卷积层的网络模型中的反卷积层。效率有所下降但是可以通过实现来解决。实验结果比较良好。 2.像素反卷积层新的层中的中间特征图是按照顺序生成，后面的特征图的生成依赖前面的。如此。反卷积网络中的棋盘问题。卷积层对输入特征图进行不同的卷积核卷积生成了中间特征图，然后上采样生成了输出特征图，其相邻的像素是没有直接联系的，因为是不同的卷积核操作生成的。输入特征图Fin，输出特征图Fout，中间特征图的计算：像素反卷积层，PixelDCL，改用了一种中间特征图的关联生成形式，生成了序列化的特征图，彼此依赖，如图。移除中间特征图和输入特征图之间的关联，因为，中间特征已经包含了输入特征图的信息，去掉不但可以提高计算效率，还能减小模型的参数。计算时只需第一个中间特征图依赖输入特征图，其他的中间特征图依赖前面计算过的特征图：分析（ 4*4 的输入特征图，上采样为 8*8 的特征图）：第一步：2*2的卷积核对输入特征进行卷积操作生成第一个中间特征图，紫色的；第二步：对第一个中间特征进行卷积操作生成第二个中间特征；第三步：扩展和组合前两个特征图，生成8*8的特征图；第四步：对此特征图进行marked卷积，卷积核大小改为3，保持8的大小；第五步：组合两个大小为8的特征图，生成最终的大小为8的输出特征图。 源码地址 3.结果在图像语义分割上的结果：","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"计算机视觉","slug":"computerversion","permalink":"http://abumaster.com/tags/computerversion/"}]},{"title":"使用深度学习技术的图像语义分割最新综述","date":"2017-07-10T08:32:14.000Z","path":"2017/07/10/使用深度学习技术的图像语义分割最新综述/","text":"A Review on Deep Learning Techniques Applied to Semantic Segmentation [A. Garcia-Garcia, S. Orts-Escolano, S.O. Oprea, V. Villena-Martinez, and J. Garcia-Rodriguez] 2017年4月22 文章的主要贡献： 对现有用于图像语义分割的数据集的研究； 深度有组织地对使用深度学习的图像语义分割重要算法它们的起源和贡献进行回顾； 对它们的性能进行粗略的评估； 对上述结果进行讨论，并对未来的研究方向进行探讨。 术语和背景概念图像语义分割不是一个孤立的领域，而是一个从粗略到精细的自然的推理过程：预测输入图像中物体的类别，如果多类物体则预测多个类别；定位不同类别物体的位置；为图像中的每一个像素分类（图像语义分割）；对同一类物体的不同物体进行区分（实例分割）。 数据预处理和增强 对于小的数据集，可以相应作出改变来增大数据集，往往会带来更好的效果。比如1500张图像的数据集可以缩放成不同的尺度，进行不同的旋转，进行不同的伽马变换，生成大数据集。 方法总结 当前，大多数优秀的深度学习技术用于图像语义分割都来自一个共同的先导者：全卷积网络（Long），这种方法的优势就是利用当前存在的CNNs作为有力的视觉模型，可以学习分层特征。通过改变一些著名的分类网络：改变最后的全连接层为全卷积层，输出特征图来取代分类得分。这些特征图（空域图）通过分数阶卷积（也被称为反卷积）来产生稠密像素级标记的输出图。反卷积网络的工作是一个里程碑式的工作，因为它展示了如何用CNNs训练端对端来解决视觉问题，是深度学习用于图像语义分割的基石。缺陷：缺少不同特征的感知，阻碍了在具体问题和场景中的应用。固有的空间不变性，使它不能将全局的上下文信息考虑进去，默认不能感知实例，在高分辨率上不能达到实时的处理速度，不能适应无结构的数据，例如3-D点云和模型。对于它的种种缺陷，不同的方法提供不同的改善方向和效果，主要分为以下几个方向。 解码变种这是一种具有两个组件的网络，分别包含了编码器（卷积网络）和解码器（反卷积网络）。与普通的全卷积网络不同之处在于对低分辨率的特征图的处理，通过一个解码网络的东西。SegNet，解码阶段是由一系列的上采样和卷积层组成的，上采样对应了编码过程的最大池化。上采样过的特征图通过一组可以训练的卷积核进行卷积生成了稠密特征图。经过解码后的图像与原始输入图像具有了相同的分辨率，然后经过一层softmax层分类器产生最终的分割图。 整合上下文信息图像语义分割的一个问题就是需要整合不同空间尺度的信息。这意味着局部信息和全局信息的平衡，一方面，细粒度或者局部信息对于获得良好的像素级预测精度是非常重要的，另一方面，整合全局上下文信息，可以解决分割图局部模糊性。传统的CNNs网络因为池化层的存在是不能感知全局信息的，有许多方法可以使CNNs感知全局信息，比如，使用条件随机场作为后续的处理，膨胀卷积，多尺度聚合，甚至将上下文模型推广到另一种深度网络中如RNNs。条件随机场解决上述的问题，一种可能的方法优化输出图，提高捕捉细节的能力，是用条件随机场作为后期处理。条件随机场（CRF）可以组合低层次的像素级别的信息，这些是CNN无法做到的，其中DeepLab应用了全连接的条件随机场作为分割图的后续处理，像素作为图的节点，建立全连接充分考虑了短程和远程的连接。另一个CRFasRNN，将条件随机场作为网络的一部分进行端对端的训练。 [1] Semantic image segmentation with deep convolutional nets and fully connected crfs[2] Conditional random fields as recurrent neural networks 膨胀卷积也叫阿托斯卷积，通过增大卷积核的步伐来进行卷积操作，获得更宽的接受域。多尺度聚合首先[1]提出了将全卷积网络分为两个路径，图像分为原图和二倍图，分别放入浅层网络和全卷积网络，将全卷积网络的输出上采样结合浅层输出经过一系列的卷积的到最终的输出图。对尺度感知非常敏感？[2]用了不同的思路，四个相同的网络，感知由粗糙到精细的尺度信息，如图，序列进行处理得到最终的输出。[4]提出了n个全卷积网络的结构，分别对应处理不同的尺度，分为两个阶段学习：第一个分别独立训练，第二融合各网络的输出，得到最终的输出图。 [1] Multi-scale convolutional architecture for semantic segmentation[2] A multi-scale cnn for affordance segmentation in rgb images[3] Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture[4] Multiscale fully convolutional network with application to industrial inspection 特征融合提取不同层的特征，包含了不同的局部上下文信息，将之融合。递归神经网络 实例分割实例分割是语义分割之后的一步，同时也是与其他低级像素分割技术相比最具有挑战性的问题。主要是将同类物品的不同实例区别开。","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"计算机视觉","slug":"computerversion","permalink":"http://abumaster.com/tags/computerversion/"}]},{"title":"多线程库c++11","date":"2017-07-09T10:32:25.000Z","path":"2017/07/09/多线程库c-11/","text":"C++ 11 标准中的多线程库，包含了封装的thread类以及用于同步的mutex、atomic和条件变量。 thread类使用包含头文件，std::thread。构造函数常用的构造函数： 12template &lt;class Fn, class... Args&gt;explicit thread (Fn&amp;&amp; fn, Args&amp;&amp;... args); 第一个参数指定了线程执行函数，第二个可选的线程函数所需的参数。为了控制线程同步，可以设置原子变量atomic类型的全局变量；或者传入一个原子变量参数的引用；或者使用一个成员变量。例子，参见cplusplus网站。赋值运算符，可以直接移动分配，不拷贝。等待和独立运行创建线程后可以调用join来阻塞等待线程的结束，同样也提供了一个函数joinable来测试线程是否可以被join，如果想让线程独立于主线程后台运行可以调用detach，使线程分离出去在后台运行，这是测试能否被join则返回的是false，同样主线程也不能调用join来等待线程的结束。this_thread 类表示当前进程，提供了一组函数。 get_id 返回一个thread::id类型，标识了当前线程的id。 yield 让步，为其他线程提供调用的机会。 sleep_until 阻塞直到设置的时间到了，绝对的时间。 sleep_for 阻塞到指定的时间，相对时间。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"c语言中的struct-option结构","date":"2017-07-03T12:52:19.000Z","path":"2017/07/03/c语言中的struct-option结构/","text":"C语言知识拾遗，struct option 结构体。 struct option 指明了一个长参数，在一些控制台程序中经常用到，需要指明不同的参数来运行程序。如开源软件webbench运行./webbench -h后会出现一些可选项，指定不同的参数，程序会做出不同的相应。123456struct option &#123; const char *name; //name表示的是长参数名 int has_arg； int *flag; int val; &#125; 参数说明：name 表示长参数的名称；has_arg 表示参数名称后面是否需要跟着参数，no_argument(0)不需要，required_argument(1)一定要跟个参数，optional_argument(2)可以有也可以没有；flag 决定了getopt_long的返回值，如果为NULL，返回val字段的数值；如果不为NULL，则会使其指向的内容变为val中的值，并且返回0；若未发现长选项，那么指向不变；val 指定的默认值。 长命令参数的解析123int getopt_long(int argc, char * const argv[], const char *optstring, const struct option *longopts, int *longindex); 参数说明：argc 和 argv 是命令行参数；optstring 选项参数组成的字符串，如果一个字母后面跟着一个冒号如 t:，那么表示这个选项后需要参数；longopts 是需要的自定义的option结构体；longindex 指定一个索引指针。 例子：","tags":[{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"},{"name":"C","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"STL源码剖析-迭代器和traits编程技法","date":"2017-06-27T06:46:37.000Z","path":"2017/06/27/STL源码剖析-迭代器和traits编程技法/","text":"STL源码剖析，第三章 迭代器和traits编程技法的读书笔记。 迭代器 是一种类似指针的对象，各种行为中最重要的是内容提领(dereference)和成员访问(member access)。最重要的是对 operator* 和 operator-&gt; 进行重载。 迭代器的相应型别相应型别（associated type）是迭代器所指之物的型别。应用场景：算法中可能用到一个以迭代器所指型别类型的变量，这时如何获取呢？C++ 不支持typeof。解决方法：利用函数模板的参数推导机制，可以推导出型别。如：1234567891011121314151617template &lt;class I, class T&gt;void func_impl(I iter, T t)&#123; T tmp; // T 所指之物的类别 int // ... 这里做原本func做的工作&#125;;template &lt;class I&gt;inlinevoid func(I iter)&#123; func_impl(iter, *iter); // func 的工作全部移往 func_impl&#125;int main()&#123; int i; func(&amp;i);&#125; Traits 编程技法上述的参数推导机制，无法推导出函数返回值的型别。有一种方法：内嵌型别来解决，内嵌一个类型声明 value type 。如：123456789101112131415template &lt;class T&gt;struct MyIter &#123; typedef T value_type; // 内嵌式声明（nested type） T* ptr; MyIter(T* p=0) : ptr(p) &#123; &#125; T&amp; operator*() const &#123; return *ptr; &#125; // ...&#125;;template &lt;class I&gt;typename I::value_type // 这一行是 func 的回返值型別func(I ite)&#123; return *ite; &#125;// 调用MyIter&lt;int&gt; ite(new int(8));cout &lt;&lt; func(ite); // 输出：8 并不是所有的迭代器都可以内嵌型别，如原生指针不是 class type，就无法定义型别。因此，对一般化概念进行特定情况处理，模板偏特化（template partial specialization）可以做到。所谓偏特化是针对任意template参数更进一步限制条件设计出的一个特化版本。如：12template&lt;typeneme T&gt;class C&lt;T*&gt; &#123;...&#125;//T为原生指针的情况，是T为任何类型的进一步条件限制 特征萃取机负责将迭代器或者原生指针中的特征提取出来。12345678template &lt;class I&gt;struct iterator_traits &#123; typedef typename I::iterator_category iterator_category; typedef typename I::value_type value_type; typedef typename I::difference_type difference_type; typedef typename I::pointer pointer; typedef typename I::reference reference;&#125;; 迭代器各个型别的意义：value type 迭代器所指对象的型别。difference_type 两个迭代器之间的距离，也可以用来表示一个容器的最大容量。reference 引用类型。pointer 指针类型。iterator_category 迭代器的分类。迭代器通常分为五类： 类型 描述 Input Iterator 不允许外部改变，只读 Output Iterator 只写 Forward Iterator 单向移动，可读可写 Bidirectional Iterator 双向移动，区间内可读可写 Random Access Iterator 随机访问，涵盖所有指针的算术能力 Traits编程技法。部分源码剖析，参考。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142// 用于标记迭代器类型struct input_iterator_tag &#123;&#125;;struct output_iterator_tag &#123;&#125;;struct forward_iterator_tag : public input_iterator_tag &#123;&#125;;struct bidirectional_iterator_tag : public forward_iterator_tag &#123;&#125;;struct random_access_iterator_tag : public bidirectional_iterator_tag &#123;&#125;;template &lt;class T, class Distance&gt; struct input_iterator&#123; typedef input_iterator_tag iterator_category; typedef T value_type; typedef Distance difference_type; typedef T* pointer; typedef T&amp; reference;&#125;;struct output_iterator&#123; typedef output_iterator_tag iterator_category; typedef void value_type; typedef void difference_type; typedef void pointer; typedef void reference;&#125;;template &lt;class T, class Distance&gt; struct forward_iterator&#123; typedef forward_iterator_tag iterator_category; typedef T value_type; typedef Distance difference_type; typedef T* pointer; typedef T&amp; reference;&#125;;template &lt;class T, class Distance&gt; struct bidirectional_iterator&#123; typedef bidirectional_iterator_tag iterator_category; typedef T value_type; typedef Distance difference_type; typedef T* pointer; typedef T&amp; reference;&#125;;template &lt;class T, class Distance&gt; struct random_access_iterator&#123; typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef Distance difference_type; typedef T* pointer; typedef T&amp; reference;&#125;;#ifdef __STL_USE_NAMESPACEStemplate &lt;class Category, class T, class Distance = ptrdiff_t, class Pointer = T*, class Reference = T&amp;&gt;struct iterator &#123; typedef Category iterator_category; typedef T value_type; typedef Distance difference_type; typedef Pointer pointer; typedef Reference reference;&#125;;#endif /* __STL_USE_NAMESPACES */#ifdef __STL_CLASS_PARTIAL_SPECIALIZATION////////////////////////////////////////////////////////////////////////////////// iterator_traits定义////////////////////////////////////////////////////////////////////////////////// 用于traits出迭代其所指对象的型别template &lt;class Iterator&gt;struct iterator_traits&#123; // 迭代器类型, STL提供五种迭代器 typedef typename Iterator::iterator_category iterator_category; // 迭代器所指对象的型别 // 如果想与STL算法兼容, 那么在类内需要提供value_type定义 typedef typename Iterator::value_type value_type; // 这个是用于处理两个迭代器间距离的类型 typedef typename Iterator::difference_type difference_type; // 直接指向对象的原生指针类型 typedef typename Iterator::pointer pointer; // 这个是对象的引用类型 typedef typename Iterator::reference reference;&#125;;// 针对指针提供特化版本template &lt;class T&gt;struct iterator_traits&lt;T*&gt;&#123; typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference;&#125;;// 针对指向常对象的指针提供特化template &lt;class T&gt;struct iterator_traits&lt;const T*&gt;&#123; typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef const T* pointer; typedef const T&amp; reference;&#125;;////////////////////////////////////////////////////////////////////////////////// iterator_traits支持函数////////////////////////////////////////////////////////////////////////////////// iterator_category(const Iterator&amp;) 返回迭代器类别// distance_type(const Iterator&amp;) 返回表示迭代器距离的类型// value_type(const Iterator&amp;) 返回迭代器所指对象的类型////////////////////////////////////////////////////////////////////////////////template &lt;class Iterator&gt;inline typename iterator_traits&lt;Iterator&gt;::iterator_categoryiterator_category(const Iterator&amp;)&#123; typedef typename iterator_traits&lt;Iterator&gt;::iterator_category category; return category();&#125;template &lt;class Iterator&gt;inline typename iterator_traits&lt;Iterator&gt;::difference_type*distance_type(const Iterator&amp;)&#123; return static_cast&lt;typename iterator_traits&lt;Iterator&gt;::difference_type*&gt;(0);&#125;template &lt;class Iterator&gt;inline typename iterator_traits&lt;Iterator&gt;::value_type*value_type(const Iterator&amp;)&#123; return static_cast&lt;typename iterator_traits&lt;Iterator&gt;::value_type*&gt;(0);&#125; 例子：使用，如一个动物接收机构，不同的动物对应不同的处理，但是对于外界来说只有一个共同的接口，内部不同的动物有不同的方法，用虚函数可以实现，但是用traits编程技巧，也能很好的实现这个需求。123456789101112131415161718192021222324252627282930313233//定义不同的动物标签struct cat_tag&#123;&#125;;struct dog_tag&#123;&#125;;//不同的动物类struct dog&#123; typedef dog_tag animal_type;//内嵌动物类型 //typedef T value_type; //...&#125;;struct cat &#123; typedef cat_tag animal_type; //typedef T value_type;&#125;;//获取动物类型template &lt;class T&gt; struct AnimalTraits &#123; typedef typename T::animal_type animal_type;&#125;;//不同的动物有不同的处理template &lt;class T&gt; void _Accept(T dog, dog_tag)&#123; cout &lt;&lt; \"this is dog accept...\" &lt;&lt; endl;&#125;template &lt;class T&gt; void _Accept(T cat, cat_tag)&#123; cout &lt;&lt; \"this is cat accept...\" &lt;&lt; endl;&#125;//提供外部通用的接口template &lt;class T&gt; void Accept(T animal)&#123; typedef typename AnimalTraits&lt;T&gt;::animal_type type; _Accept(animal, type());//依据类别的临时变量决定调用哪个&#125;","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://abumaster.com/tags/STL/"}]},{"title":"STL源码剖析-空间配置器","date":"2017-06-24T08:15:31.000Z","path":"2017/06/24/STL源码剖析-空间配置器/","text":"《STL 源码剖析》读书笔记，第2章 空间配置器（allocator）。 空间的配置和释放 内存配置 -&gt; 对象构造 -&gt; 对象析构 -&gt; 内存释放 考虑到小内存块可能造成内存碎片的问题，SGI设计了双层配置器，对于大的内存块直接使用以及配置器，直接调用 malloc() 和 free() 函数，其中定义了内存不足的处理函数机制；而对于较小的内存申请（128 bytes 为界限），使用二级配置器，使用了内存池技术（内存的申请和释放交由内存池管理），可以保证效率和减少内存碎片。两个配置器的使用取决于 __USE__MALLOC 宏的定义。123456789# ifdef __USE_MALLOC...typedef __malloc_alloc_template&lt;0&gt; malloc_alloc;typedef malloc_alloc alloc; // 令 alloc 为第一级配置器# else...// 令 alloc 为第二级配置器typedef __default_alloc_template&lt;__NODE_ALLOCATOR_THREADS, 0&gt; alloc;#endif /* ! __USE_MALLOC */ 包装一个接口提供给用户使用，如下：123456789101112template&lt;class T, class Alloc&gt;class simple_alloc &#123;public: static T *allocate(size_t n) &#123; return 0 == n? 0 : (T*) Alloc::allocate (n * sizeof (T)); &#125; static T *allocate(void) &#123; return (T*) Alloc::allocate(sizeof (T)); &#125; static void deallocate(T *p, size_t n) &#123; if (0 != n) Alloc::deallocate(p, n * sizeof (T)); &#125; static void deallocate(T *p) &#123; Alloc::deallocate(p, sizeof (T)); &#125;&#125;; 第二级配置器剖析规定申请的空间小于 128 bytes 时，使用二级配置器完成。二级配置器由自由链表（free-list）组成。内存需求以8的倍数对齐。16个 free-lists 各自管理大小分别为 8,16,24,32,40,48,56,64,72,80,88,96,104,112,120,128 bytes 的小额区块。需要哪个大小直接从链表中调拨。链表结构1234union obj &#123; union obj * free_list_link; char client_data[1];&#125; 分析：union共用存储空间。free_list_link 指向下一个 obj ；第二个字段，可以看成一个指针，指向了实际的区块。client_data 为数组名称，是数组的首地址，因此是一个指针，指向了obj的地址，即&amp;obj == obj-&gt;client_data。实现了链表结点只使用一个指针的大小空间, 却能同时做索引和指向内存区域。空间配置函数 allocate()1234567891011121314151617181920// n must be &gt; 0static void * allocate(size_t n)&#123; obj * volatile * my_free_list; obj * result; // 大于128的调用一级配置器 if (n &gt; (size_t) __MAX_BYTES) return(malloc_alloc::allocate(n)); // 寻找自由链表中的合适的大小 my_free_list = free_list + FREELIST_INDEX(n); result = *my_free_list; if (result == 0) &#123; // 沒找到可用的 free list ，重新填充 void *r = refill(ROUND_UP(n)); // return r; &#125; // 调整空闲链表 *my_free_list = result -&gt; free_list_link; return (result);&#125;; 示意图如下：空间释放函数 deallocate()12345678910111213141516// p 不可以是 0static void deallocate(void *p, size_t n)&#123; obj *q = (obj *)p; obj * volatile * my_free_list; // 大於 128 请求一级配置器 if (n &gt; (size_t) __MAX_BYTES) &#123; malloc_alloc::deallocate(p, n); return; &#125; // 根据大小寻找对应的 free list my_free_list = free_list + FREELIST_INDEX(n); // 重新调整 free list ，回收区块进链表 q -&gt; free_list_link = *my_free_list; *my_free_list = q;&#125; 示意图如下：配置和释放的过程： 根据请求的大小，找到16个free lists中对应的list或者请求一级配置器； 然后将第一块空闲区返回给用户，没有空闲的可以到内存池中再重新注入一些空闲的数据块。重新填充 free lists分配时，发现free list中没有空闲的区块，则从内存池中填充一部分新区快，默认为20个新区快。内存池中没有那么多也可能会少于20个。 1234567891011121314151617181920212223242526272829303132//返回一个大小为n的对象，恰当时候可以为free list增加新的节点//n已经是8的倍数template &lt;bool threads, int inst&gt;void* __default_alloc_template&lt;threads, inst&gt;::refill(size_t n)&#123; int nobjs = 20; //从内存池中申请 nobjs 个大小为 n 的对象(n*objs)，chunk指向这块内存 char * chunk = chunk_alloc(n, nobjs);//nobjs为引用参数 obj * volatile * my_free_list; obj * result; obj * current_obj, * next_obj; int i; //只得到了一块，那么直接返回，不需要加入free list中了 if (1 == nobjs) return(chunk); //找到合适的free list my_free_list = free_list + FREELIST_INDEX(n); result = (obj*)chunk;//返回的空间 //指向下一个空闲块 *my_free_list = next_obj = (obj *)(chunk + n); //开始加入free list中 for (i = 1; ; i++) &#123; // 0的已经返回给用户 current_obj = next_obj; next_obj = (obj *)((char *)next_obj + n); if (nobjs - 1 == i) &#123;//最后一个 current_obj -&gt; free_list_link = 0; break; &#125; else &#123;//分成大小n的块，并连成链表 current_obj -&gt; free_list_link = next_obj; &#125; &#125; return(result);&#125; 内存池12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667 template &lt;bool threads, int inst&gt; char* __default_alloc_template&lt;threads, inst&gt;::chunk_alloc(size_t size, int&amp; nobjs) &#123; char * result; size_t total_bytes = size * nobjs; size_t bytes_left = end_free - start_free; // 计算内存池剩余容量 // 如果内存池中剩余内存&gt;=需要分配的内内存, 返回start_free指向的内存块, // 并且重新设置内存池起始点 if (bytes_left &gt;= total_bytes) &#123; result = start_free; start_free += total_bytes; return(result); &#125; // 如果内存池中剩余的容量不够分配, 但是能至少分配一个节点时, // 返回所能分配的最多的节点, 返回start_free指向的内存块 // 并且重新设置内存池起始点 else if (bytes_left &gt;= size) &#123; nobjs = bytes_left/size; total_bytes = size * nobjs; result = start_free; start_free += total_bytes; return(result); &#125; // 内存池剩余内存连一个节点也不够分配 else &#123; size_t bytes_to_get = 2 * total_bytes + ROUND_UP(heap_size &gt;&gt; 4); // 将剩余的内存分配给指定的free_list[FREELIST_INDEX(bytes_left)] if (bytes_left &gt; 0) &#123; obj * __VOLATILE * my_free_list = free_list + FREELIST_INDEX(bytes_left); ((obj *)start_free) -&gt; free_list_link = *my_free_list; *my_free_list = (obj *)start_free; &#125; start_free = (char *)malloc(bytes_to_get); // 分配失败, 搜索原来已经分配的内存块, 看是否有大于等于当前请求的内存块 if (0 == start_free) &#123; int i; obj * __VOLATILE * my_free_list, *p; //不打算配置较小的内存块 //检索在free list中足够大的空闲块 for (i = size; i &lt;= __MAX_BYTES; i += __ALIGN) &#123; my_free_list = free_list + FREELIST_INDEX(i); p = *my_free_list; // 找到了一个, 将其加入内存池中 if (0 != p) &#123; *my_free_list = p -&gt; free_list_link; start_free = (char *)p; end_free = start_free + i; // 内存池更新完毕, 重新分配需要的内存 //递归调用 return(chunk_alloc(size, nobjs)); // 内存零头被编到了对应free list中 &#125; &#125; // 再次失败, 直接调用一级配置器分配, 期待异常处理函数能提供帮助 // 不过在我看来, 内存分配失败进行其它尝试已经没什么意义了, // 最好直接log, 然后让程序崩溃 end_free = 0; // In case of exception. start_free = (char *)malloc_alloc::allocate(bytes_to_get); &#125; heap_size += bytes_to_get; end_free = start_free + bytes_to_get; // 内存池更新完毕, 重新分配需要的内存 return(chunk_alloc(size, nobjs)); &#125; &#125; 参考链接。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"STL","slug":"STL","permalink":"http://abumaster.com/tags/STL/"}]},{"title":"Nginx源码学习-数据结构","date":"2017-06-18T10:29:52.000Z","path":"2017/06/18/Nginx源码学习-数据结构/","text":"Nginx源码学习中的数据结构，主要包括数组结构ngx_array_t、链表结构ngx_list_t、队列结构ngx_queue_t、哈希结构ngx_hash_t、字符串结构ngx_string_t。在内存池的基础之上进一步整合组织数据。 Nginx数组结构ngx_array_t数组结构位于源文件\\Src\\Core\\Ngx_array.h{c} 数组结构1234567typedef struct &#123; void *elts; //指向数组空间的起始地址 ngx_uint_t nelts; //数组中实际的元素个数 size_t size; //数组元素的大小 ngx_uint_t nalloc; //实际分配的空间 ngx_pool_t *pool; //数组交由此内存池来管理空间&#125; ngx_array_t;//数组头占用的空间为20字节，头+数据 几种数据结构之间的关系图 基本操作1.一个内联函数功能：在内存池pool上分配一块大小为n*size的空间，并将数组的elts指针指向这个空间的首地址。123456789101112131415161718192021//初始化数组大小为n，参数：数组指针，内存池，数组空间的，每个元素大小static ngx_inline ngx_int_tngx_array_init(ngx_array_t *array, ngx_pool_t *pool, ngx_uint_t n, size_t size)&#123; /* * set \"array-&gt;nelts\" before \"array-&gt;elts\", otherwise MSVC thinks * that \"array-&gt;nelts\" may be used without having been initialized */ array-&gt;nelts = 0;//数组中的元素个数为0 array-&gt;size = size;//每个元素的大小 array-&gt;nalloc = n;//分配n个空间，空间大小(n*size) array-&gt;pool = pool; //用内存池函数分配一个大小(n*size)的空间并将首地址返回给数组的elts array-&gt;elts = ngx_palloc(pool, n * size); if (array-&gt;elts == NULL) &#123; return NGX_ERROR; &#125; //成功初始化数组 return NGX_OK;&#125; 2.创建数组功能：提供数组元素的个数并且知道每个元素所占用的空间，在内存池p中创建一个有n个元素的数组。返回数组的指针。 12345678910111213141516ngx_array_t *ngx_array_create(ngx_pool_t *p, ngx_uint_t n, size_t size)&#123; ngx_array_t *a;//首先为数组的头分配一个空间，这个数组指针指向的是数组头的起始地址 a = ngx_palloc(p, sizeof(ngx_array_t)); if (a == NULL) &#123; return NULL; &#125;//用内联函数初始化这个数组 if (ngx_array_init(a, p, n, size) != NGX_OK) &#123; return NULL; &#125; return a;&#125; 3.销毁数组功能：销毁数组实际上没有释放数组占用的内存空间，而是移动首尾指针，这样保证了效率。代码如下:123456789101112131415voidngx_array_destroy(ngx_array_t *a)&#123; ngx_pool_t *p;//数组所用的内存池 p = a-&gt;pool;//数组不是内存池中的最后一个？还能删除？ if ((u_char *) a-&gt;elts + a-&gt;size * a-&gt;nalloc == p-&gt;d.last) &#123; p-&gt;d.last -= a-&gt;size * a-&gt;nalloc;//将内存池的指针向前移动 &#125;//删除数组头 if ((u_char *) a + sizeof(ngx_array_t) == p-&gt;d.last) &#123; p-&gt;d.last = (u_char *) a; &#125;&#125; 4.向数组中插入元素功能：向数组指针a中插入元素，返回插入元素的空间地址 12345678910111213141516171819202122232425262728293031323334353637383940void *ngx_array_push(ngx_array_t *a)&#123; void *elt, *new; size_t size; ngx_pool_t *p;//数组中元素已经满了 if (a-&gt;nelts == a-&gt;nalloc) &#123; size = a-&gt;size * a-&gt;nalloc;//此时数组的占用空间的大小 p = a-&gt;pool; //数组后面有多余的空间可以扩展 if ((u_char *) a-&gt;elts + size == p-&gt;d.last &amp;&amp; p-&gt;d.last + a-&gt;size &lt;= p-&gt;d.end) &#123; /* * the array allocation is the last in the pool * and there is space for new allocation */ //向后扩展一个元素的空间 p-&gt;d.last += a-&gt;size; a-&gt;nalloc++; &#125; else &#123; /* allocate a new array */ //没有多余的空间进行扩展，则重新申请一个数组，大小为当前的2倍 new = ngx_palloc(p, 2 * size); if (new == NULL) &#123; return NULL; &#125; //将原数组元素拷贝到新的数组中，并设置新数组的一些参数（老数组没有销毁） ngx_memcpy(new, a-&gt;elts, size); a-&gt;elts = new; a-&gt;nalloc *= 2; &#125; &#125; //将指针指向下一个空闲区域 elt = (u_char *) a-&gt;elts + a-&gt;size * a-&gt;nelts; a-&gt;nelts++; //返回这个空闲空间的指针 return elt;&#125; 添加n个元素void * ngx_array_push_n(ngx_array_t *a, ngx_uint_t n)。 Nginx链表结构ngx_list_t链表数据结构123456789101112131415typedef struct ngx_list_part_s ngx_list_part_t;//链表节点结构struct ngx_list_part_s &#123; void *elts;//实际指向的内存区域大小为size*nalloc ngx_uint_t nelts;//元素的个数 ngx_list_part_t *next;//下一个节点的地址&#125;;//链表头结构typedef struct &#123; ngx_list_part_t *last;//指向链表最后一个节点 ngx_list_part_t part;//链表头中也有一个节点 size_t size;//每个元素的大小 ngx_uint_t nalloc;//链表包含的空间，实际分配的空间个数 ngx_pool_t *pool;//在此内存池中分配&#125; ngx_list_t; 基本操作1.内联函数-链表的初始化功能：初始化链表实体，头结点 12345678910111213141516171819202122232425262728293031323334353637383940static ngx_inline ngx_int_tngx_list_init(ngx_list_t *list, ngx_pool_t *pool, ngx_uint_t n, size_t size)&#123; list-&gt;part.elts = ngx_palloc(pool, n * size);//实际存储空间 if (list-&gt;part.elts == NULL) &#123; return NGX_ERROR; &#125; list-&gt;part.nelts = 0;//当前元素个数 list-&gt;part.next = NULL;//下一个没有 list-&gt;last = &amp;list-&gt;part;//最后一个指向了自己 list-&gt;size = size;//大小 list-&gt;nalloc = n;//元素的个数 list-&gt;pool = pool;//内存池 return NGX_OK;&#125;/* * * the iteration through the list: * * part = &amp;list.part;//先获得链表头中的节点 * data = part-&gt;elts;//获得数据的存储区域 * * for (i = 0 ;; i++) &#123; *判断此节点中元素的个数，依次取出 * if (i &gt;= part-&gt;nelts) &#123; * if (part-&gt;next == NULL) &#123;//无下一个节点则跳出 * break; * &#125; *取出下一个节点 * part = part-&gt;next; * data = part-&gt;elts; * i = 0; * &#125; *进行此节点中的数据操作 * ... data[i] ... * * &#125; */ 2.创建链表功能：创建一个链表，指定内存池，个数以及每个元素的大小 12345678910111213141516ngx_list_t *ngx_list_create(ngx_pool_t *pool, ngx_uint_t n, size_t size)&#123; ngx_list_t *list;//为链表头分配空间大小sizeof(ngx_list_t) = 28B list = ngx_palloc(pool, sizeof(ngx_list_t)); if (list == NULL) &#123; return NULL; &#125;//调用内联函数进行链表的初始化，包含一个节点的链表头 if (ngx_list_init(list, pool, n, size) != NGX_OK) &#123; return NULL; &#125;//返回此链表头结点 return list;&#125; 3.添加结点功能：向链表中添加一个元素，返回添加元素数据区的地址 1234567891011121314151617181920212223242526272829303132void *ngx_list_push(ngx_list_t *l)&#123; void *elt; ngx_list_part_t *last;//得到链表中的最后一个节点，在链表的尾部插入新的节点 last = l-&gt;last;//最后一个节点的元素个数已经满了 if (last-&gt;nelts == l-&gt;nalloc) &#123; //需要重新创建一个链表节点 last = ngx_palloc(l-&gt;pool, sizeof(ngx_list_part_t)); if (last == NULL) &#123; return NULL; &#125; //为节点分配空间 last-&gt;elts = ngx_palloc(l-&gt;pool, l-&gt;nalloc * l-&gt;size); if (last-&gt;elts == NULL) &#123; return NULL; &#125; //设置新节点信息 last-&gt;nelts = 0; last-&gt;next = NULL; //连接到链表中 l-&gt;last-&gt;next = last; l-&gt;last = last; &#125;//获得地址 elt = (char *) last-&gt;elts + l-&gt;size * last-&gt;nelts; last-&gt;nelts++;//返回可用存储空间的地址 return elt;&#125; 4.链表设计思路在链表头中设置一些链表节点的信息：last指针用于指向链表的最后一个节点，方便插入元素和数据；part链表头中的结点；size链表中存放元素的大小；nalloc一个节点所占用的空间，可以放元素的个数；pool指定内存池。在链表节点中只存放了指向数据元素存储区的指针elts；当前节点存放的元素个数nelts；以及下一个节点指针next。 Nginx队列结构 ngx_queue_t Nginx 中的队列数据结构是用双向循环链表实现。节点结构为ngx_queue_t。 队列数据结构12345typedef struct ngx_queue_s ngx_queue_t;struct ngx_queue_s &#123;//队列的结构 ngx_queue_t *prev;//前指针 ngx_queue_t *next;//后指针&#125;; 队列的基本操作通过定义的一组宏来实现队列的基本操作。 1.初始化队列初始化头尾指针指向本身。 123#define ngx_queue_init(q) \\ (q)-&gt;prev = q; \\ (q)-&gt;next = q 2.判断队列是否为空12#define ngx_queue_empty(h) \\ (h == (h)-&gt;prev) 3.插入节点123456789101112//在头插入#define ngx_queue_insert_head(h, x) \\ (x)-&gt;next = (h)-&gt;next; \\ (x)-&gt;next-&gt;prev = x; \\ (x)-&gt;prev = h; \\ (h)-&gt;next = x//在尾插入#define ngx_queue_insert_tail(h, x) \\ (x)-&gt;prev = (h)-&gt;prev; \\ (x)-&gt;prev-&gt;next = x; \\ (x)-&gt;next = h; \\ (h)-&gt;prev = x 4.访问队列的头结点是固定的，依次链接成了双向链表，进行访问数据。 1234567891011#define ngx_queue_head(h) \\ (h)-&gt;next#define ngx_queue_last(h) \\ (h)-&gt;prev//哨兵，用于排序#define ngx_queue_sentinel(h) \\ (h)#define ngx_queue_next(q) \\ (q)-&gt;next#define ngx_queue_prev(q) \\ (q)-&gt;prev 5.修改队列删除队列中的节点1234567891011#if (NGX_DEBUG)#define ngx_queue_remove(x) \\ (x)-&gt;next-&gt;prev = (x)-&gt;prev; \\ (x)-&gt;prev-&gt;next = (x)-&gt;next; \\ (x)-&gt;prev = NULL; \\ (x)-&gt;next = NULL#else#define ngx_queue_remove(x) \\ (x)-&gt;next-&gt;prev = (x)-&gt;prev; \\ (x)-&gt;prev-&gt;next = (x)-&gt;next#endif 分割队列1234567#define ngx_queue_split(h, q, n) \\ (n)-&gt;prev = (h)-&gt;prev; \\ (n)-&gt;prev-&gt;next = n; \\ (n)-&gt;next = q; \\ (h)-&gt;prev = (q)-&gt;prev; \\ (h)-&gt;prev-&gt;next = h; \\ (q)-&gt;prev = n; h为队列头(即链表头指针)，将该队列从q节点将队列(链表)分割为两个队列(链表)，q之后的节点组成的新队列的头节点为n。合并队列12345#define ngx_queue_add(h, n) \\ (h)-&gt;prev-&gt;next = (n)-&gt;next; \\ (n)-&gt;next-&gt;prev = (h)-&gt;prev; \\ (h)-&gt;prev = (n)-&gt;prev; \\ (h)-&gt;prev-&gt;next = h; 两个队列的头结点。最后只保留h头结点。 数据操作获取队列节点的数据，由队列基本结构和以上操作可知，nginx的队列操作只对链表指针进行简单的修改指向操作，并不负责节点数据空间的分配。因此，用户在使用nginx队列时，要自己定义数据结构并分配空间，且在其中包含一个ngx_queue_t的指针或者对象，当需要获取队列节点数据时，使用ngx_queue_data宏，其定义如下: 12345678910#define ngx_queue_data(q, type, link) \\ (type *) ((u_char *) q - offsetof(type, link))//其中offsetof，是一个宏，用于计算成员在一个数据结构中的偏移量#define offsetof(s, m) (size_t)&amp;(((s *)0)-&gt;m)/*s是一个结构名，它有一个名为m的成员（s和m 是宏offsetof的形参，它实际是返回结构s的成员m的偏移地址.(s *)0 是骗编译器说有一个指向类（或结构）s的指针，其地址值0 &amp;((s *)0)-&gt;m 是要取得类s中成员变量m的地址. 因基址为0，这时m的地址当然就是m在s中的偏移最后转换size_t 型，即unsigned int。 */ 由该宏定义可以看出，一般定义队列节点结构(该结构类型为type)时，需要将真正的数据放在前面，而ngx_queue_t结构放在后面，故该宏使用减法计算整个节点结构的起始地址(需要进行类型转换)。 获取队列中的中间元素，奇数则返回中间的，偶数则会返回第二部分的第一个。123456789101112131415161718192021222324252627ngx_queue_t *ngx_queue_middle(ngx_queue_t *queue)&#123; ngx_queue_t *middle, *next;//队列首元素 middle = ngx_queue_head(queue);//只有一个元素返回 if (middle == ngx_queue_last(queue)) &#123; return middle; &#125;//用一个指针记录 next = ngx_queue_head(queue);//两个指针向前移动 for ( ;; ) &#123; middle = ngx_queue_next(middle); next = ngx_queue_next(next); if (next == ngx_queue_last(queue)) &#123; return middle; &#125;//next指针向前多移动一次 next = ngx_queue_next(next);//到了尾返回middle if (next == ngx_queue_last(queue)) &#123; return middle; &#125; &#125;&#125; 找中间位置，两个指针，middle移动一次，next移动两次，当next到达尾时，那么middle指向的是中间位置。 排序，稳定插入排序。123456789101112131415161718192021222324252627282930voidngx_queue_sort(ngx_queue_t *queue, ngx_int_t (*cmp)(const ngx_queue_t *, const ngx_queue_t *))&#123; ngx_queue_t *q, *prev, *next;//获得第一个元素 q = ngx_queue_head(queue); if (q == ngx_queue_last(queue)) &#123; return; &#125;//获得下一个节点 for (q = ngx_queue_next(q); q != ngx_queue_sentinel(queue); q = next) &#123;// prev = ngx_queue_prev(q); next = ngx_queue_next(q);// ngx_queue_remove(q);// do &#123; if (cmp(prev, q) &lt;= 0) &#123; break; &#125;// prev = ngx_queue_prev(prev);// &#125; while (prev != ngx_queue_sentinel(queue));//插入 ngx_queue_insert_after(prev, q); &#125;&#125; Nginx哈希数据结构哈希表是用于（key-value）对应的一种关系，为了直接由key来计算出value，需要构建一个哈希函数，并想方设法去避免冲突，尽量保证键值对的唯一性。讲解详细的博文链接1和链接2。 hash 结构1.ngx_hash_t结构Nginx中的哈希结构为ngx_hash_t以及元素结构ngx_hash_elt_t。12345678910typedef struct &#123;//hash元素结构 void *value; //key对应的值(key, value)中的key u_short len; //name长度 u_char name[1];//要hash的数据，(key, value)中的key&#125; ngx_hash_elt_t;typedef struct &#123;//hash结构 ngx_hash_elt_t **buckets;//哈希桶 ngx_uint_t size;//哈希桶的个数&#125; ngx_hash_t; 2.ngx_hash_init_t结构123456789101112//hash计算函数指针typedef ngx_uint_t (*ngx_hash_key_pt) (u_char *data, size_t len);typedef struct &#123;//hash初始化结构 ngx_hash_t *hash;//指向待初始化的hash结构 ngx_hash_key_pt key;//hash函数指针 ngx_uint_t max_size;//bucket的最大个数 ngx_uint_t bucket_size;//每个bucket占用的空间 char *name;//该hash结构的名字 ngx_pool_t *pool;//所需空间的由此内存池接管 ngx_pool_t *temp_pool;//临时文件&#125; ngx_hash_init_t; 通常是作为参数传递给ngx_hash_init函数。3.ngx_hash_key_t12345678910typedef struct &#123; //hash key结构 ngx_str_t key; //key，为nginx的字符串结构 ngx_uint_t key_hash; //由该key计算出的hash值(通过hash函数) void *value; //该key对应的值，组成一个键-值对&lt;key,value&gt; &#125; ngx_hash_key_t; typedef struct &#123; //字符串结构 size_t len; //字符串长度 u_char *data; //字符串内容 &#125; ngx_str_t; 该结构也主要用来保存要hash的数据，即键-值对，在实际使用中，一般将多个键-值对保存在ngx_hash_key_t结构的数组中，作为参数传给ngx_hash_init()或ngx_hash_wildcard_init()函数。哈希结构的内存布局： 图片来源 Google Code hash 操作1.计算ngx_hash_elt_t的大小123//name为ngx_hash_key_t#define NGX_HASH_ELT_SIZE(name) \\ (sizeof(void *) + ngx_align((name)-&gt;key.len + 2, sizeof(void *))) sizeof(void *)=4B,4字节对齐。2.hash函数hash函数提供了几种计算hash的方法。12345678910111213141516171819202122232425262728#define ngx_hash(key, c) ((ngx_uint_t) key * 31 + c)ngx_uint_t ngx_hash_key(u_char *data, size_t len);//lc表示lower case，即字符串转换为小写后再计算hash值 ngx_uint_t ngx_hash_key_lc(u_char *data, size_t len);ngx_uint_t ngx_hash_strlow(u_char *dst, u_char *src, size_t n);//如：ngx_uint_tngx_hash_key(u_char *data, size_t len)&#123; ngx_uint_t i, key; key = 0; for (i = 0; i &lt; len; i++) &#123; key = ngx_hash(key, data[i]); &#125; return key;&#125;//相当于：/*Key[0] = data[0] Key[1] = data[0]*31 + data[1] Key[2] = (data[0]*31 + data[1])*31 + data[2] ... Key[len-1] = ((((data[0]*31 + data[1])*31 + data[2])*31) ... data[len-2])*31 + data[len-1] *///key[len-1]即为传入的参数data对应的hash值。 3.hash初始化hash的初始化是用ngx_hash_init完成，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223//hinit hash结构指针；names 为ngx_hash_key_t结构数组；nelts为数组中元素个数/*该函数初始化的结果就是将names数组保存的键-值对&lt;key,value&gt;，通过hash的方式将其存入相应的一个或多个hash桶(即代码中的buckets)中，该hash过程用到的hash函数一般为ngx_hash_key_lc等。hash桶里面存放的是ngx_hash_elt_t结构的指针(hash元素指针)，该指针指向一个基本连续的数据区。该数据区中存放的是经hash之后的键-值对&lt;key',value'&gt;，即ngx_hash_elt_t结构中的字段&lt;name,value&gt;。每一个这样的数据区存放的键-值对&lt;key',value'&gt;可以是一个或多个。 */ngx_int_tngx_hash_init(ngx_hash_init_t *hinit, ngx_hash_key_t *names, ngx_uint_t nelts)&#123; u_char *elts; size_t len; u_short *test; ngx_uint_t i, n, key, size, start, bucket_size; ngx_hash_elt_t *elt, **buckets;//允许的hash桶的最大数量为0，错误 if (hinit-&gt;max_size == 0) &#123; ngx_log_error(NGX_LOG_EMERG, hinit-&gt;pool-&gt;log, 0, \"could not build %s, you should \" \"increase %s_max_size: %i\", hinit-&gt;name, hinit-&gt;name, hinit-&gt;max_size); return NGX_ERROR; &#125;//对于数组中的每个元素，如果hash元素大小大于桶的容量，出错 for (n = 0; n &lt; nelts; n++) &#123; if (hinit-&gt;bucket_size &lt; NGX_HASH_ELT_SIZE(&amp;names[n]) + sizeof(void *)) &#123; ngx_log_error(NGX_LOG_EMERG, hinit-&gt;pool-&gt;log, 0, \"could not build %s, you should \" \"increase %s_bucket_size: %i\", hinit-&gt;name, hinit-&gt;name, hinit-&gt;bucket_size); return NGX_ERROR; &#125; &#125;//分配一块2*max_size大小的空间，没有在内存池上分配，只是临时的 test = ngx_alloc(hinit-&gt;max_size * sizeof(u_short), hinit-&gt;pool-&gt;log); if (test == NULL) &#123; return NGX_ERROR; &#125;//桶的大小减去4字节 bucket_size = hinit-&gt;bucket_size - sizeof(void *);//确定起始位置 start = nelts / (bucket_size / (2 * sizeof(void *))); start = start ? start : 1; if (hinit-&gt;max_size &gt; 10000 &amp;&amp; nelts &amp;&amp; hinit-&gt;max_size / nelts &lt; 100) &#123; start = hinit-&gt;max_size - 1000; &#125; for (size = start; size &lt;= hinit-&gt;max_size; size++) &#123; ngx_memzero(test, size * sizeof(u_short));//标记1：此块代码是检查bucket大小是否够分配hash数据 for (n = 0; n &lt; nelts; n++) &#123; if (names[n].key.data == NULL) &#123; continue; &#125;//计算key和names中所有name长度，并保存在test[key]中 key = names[n].key_hash % size; test[key] = (u_short) (test[key] + NGX_HASH_ELT_SIZE(&amp;names[n]));#if 0 ngx_log_error(NGX_LOG_ALERT, hinit-&gt;pool-&gt;log, 0, \"%ui: %ui %ui \\\"%V\\\"\", size, key, test[key], &amp;names[n].key);#endif if (test[key] &gt; (u_short) bucket_size) &#123; goto next; &#125; &#125; goto found; next: continue; &#125; size = hinit-&gt;max_size; ngx_log_error(NGX_LOG_WARN, hinit-&gt;pool-&gt;log, 0, \"could not build optimal %s, you should increase \" \"either %s_max_size: %i or %s_bucket_size: %i; \" \"ignoring %s_bucket_size\", hinit-&gt;name, hinit-&gt;name, hinit-&gt;max_size, hinit-&gt;name, hinit-&gt;bucket_size, hinit-&gt;name);found://找到//test[i]初始化为4 for (i = 0; i &lt; size; i++) &#123; test[i] = sizeof(void *); &#125; /** * 标记2：与标记1代码基本相同，但此块代码是再次计算所有hash数据的总长度(标记1的检查已通过) 但此处的test[i]已被初始化为4，即相当于后续的计算再加上一个void指针的大小。 */ for (n = 0; n &lt; nelts; n++) &#123; if (names[n].key.data == NULL) &#123; continue; &#125; key = names[n].key_hash % size; test[key] = (u_short) (test[key] + NGX_HASH_ELT_SIZE(&amp;names[n])); &#125; len = 0; for (i = 0; i &lt; size; i++) &#123; if (test[i] == sizeof(void *)) &#123; continue; &#125;//对test[i]按ngx_cacheline_size对齐(32位平台，ngx_cacheline_size=32) test[i] = (u_short) (ngx_align(test[i], ngx_cacheline_size)); len += test[i]; &#125;//在内存池中分配hash头及buckets数组(size个ngx_hash_elt_t*结构) if (hinit-&gt;hash == NULL) &#123; hinit-&gt;hash = ngx_pcalloc(hinit-&gt;pool, sizeof(ngx_hash_wildcard_t) + size * sizeof(ngx_hash_elt_t *)); if (hinit-&gt;hash == NULL) &#123; ngx_free(test); return NGX_ERROR; &#125; buckets = (ngx_hash_elt_t **) ((u_char *) hinit-&gt;hash + sizeof(ngx_hash_wildcard_t)); &#125; else &#123; buckets = ngx_pcalloc(hinit-&gt;pool, size * sizeof(ngx_hash_elt_t *)); if (buckets == NULL) &#123; ngx_free(test); return NGX_ERROR; &#125; &#125; elts = ngx_palloc(hinit-&gt;pool, len + ngx_cacheline_size); if (elts == NULL) &#123; ngx_free(test); return NGX_ERROR; &#125; elts = ngx_align_ptr(elts, ngx_cacheline_size); for (i = 0; i &lt; size; i++) &#123; if (test[i] == sizeof(void *)) &#123; continue; &#125; buckets[i] = (ngx_hash_elt_t *) elts; elts += test[i]; &#125; for (i = 0; i &lt; size; i++) &#123; test[i] = 0; &#125; for (n = 0; n &lt; nelts; n++) &#123; if (names[n].key.data == NULL) &#123; continue; &#125; key = names[n].key_hash % size; elt = (ngx_hash_elt_t *) ((u_char *) buckets[key] + test[key]); elt-&gt;value = names[n].value; elt-&gt;len = (u_short) names[n].key.len; ngx_strlow(elt-&gt;name, names[n].key.data, names[n].key.len); test[key] = (u_short) (test[key] + NGX_HASH_ELT_SIZE(&amp;names[n])); &#125; for (i = 0; i &lt; size; i++) &#123; if (buckets[i] == NULL) &#123; continue; &#125; elt = (ngx_hash_elt_t *) ((u_char *) buckets[i] + test[i]); elt-&gt;value = NULL; &#125; ngx_free(test); hinit-&gt;hash-&gt;buckets = buckets; hinit-&gt;hash-&gt;size = size;#if 0 for (i = 0; i &lt; size; i++) &#123; ngx_str_t val; ngx_uint_t key; elt = buckets[i]; if (elt == NULL) &#123; ngx_log_error(NGX_LOG_ALERT, hinit-&gt;pool-&gt;log, 0, \"%ui: NULL\", i); continue; &#125; while (elt-&gt;value) &#123; val.len = elt-&gt;len; val.data = &amp;elt-&gt;name[0]; key = hinit-&gt;key(val.data, val.len); ngx_log_error(NGX_LOG_ALERT, hinit-&gt;pool-&gt;log, 0, \"%ui: %p \\\"%V\\\" %ui\", i, elt, &amp;val, key); elt = (ngx_hash_elt_t *) ngx_align_ptr(&amp;elt-&gt;name[0] + elt-&gt;len, sizeof(void *)); &#125; &#125;#endif return NGX_OK;&#125; 常用的有创建 hash 和在 hash 中进行查找两个操作，对于创建hash的操作,过程一般为： 构造一个 ngx_hash_key_t 为成员的数组， 包含 key, value 和 使用key计算出的一个hash值 构建一个 ngx_hash_init_t 结构体的变量， 其中包含了 ngx_hash_t 的成员， 为hash的结构体， 还包括一些其他初始设置，如bucket的大小，内存池等 调用 ngx_hash_init 传入 ngx_hash_init_t 结构， ngx_hash_key_t 的数组，和数组的长度， 进行初始化，这样 ngx_hash_init_t的hash成员就是我们要的hash结构 查找的过程很简单 计算 key 的hash值 使用 ngx_hash_find 进行查找，需要同时传入 hash值和key ,返回的就是value的指针 需要注意的是，nginx 的 hash 在查找时使用的是分桶后线性查找法，因此当分桶数确定时查找效率同其中的总 key-val 对数量成反比。","tags":[{"name":"C","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"笔记：虚函数实现机制","date":"2017-06-10T15:26:43.000Z","path":"2017/06/10/笔记：虚函数实现机制/","text":"C++的虚函数是实现多态的一种方法，那么它的实现机制如何，笔记记录如下。 虚函数的实现机制就是：虚表和虚指针。虚函数在运行期间来确定类型，即动态绑定，而构造函数在构造对象的时候就应该知道类型，这也是构造函数不能声明为虚函数的原因。先看一个例子，假设两个类A和B：1234567891011121314class A &#123;public: virtual void f(); virtual void g(); void h(); int a;&#125;class B :public A &#123;public: void g(); int b;&#125; 虚函数地址的获得A *p = new B;p:是个指针。(int *)p：转换成 int 类型的指针*(int *)p：把转换成int 类型指针p 的内容取出(int *)( *(int *)p)：在转换成 int 类型的指针(int *)( *(int *)p) +0：取出第一个元素的地址*((int *)( *(int *)p) +0)：得到第一个元素的内容(void *)(*((int *)( *(int *)p) +0))：得到第一个元素的地址","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"Nginx源码学习-内存池","date":"2017-06-08T08:45:30.000Z","path":"2017/06/08/Nginx源码学习-内存池/","text":"Nginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler（俄文：Рамблер）使用。其特点是占用内存少，并发能力强。其编写简洁高效，有诸多学习之处。 C/C++ 的内存管理，往往让人头痛。要时刻注意分配足够的内存，并在不用的时候记得释放内存，直接使用系统调用 malloc/free, new/delete 会有如下的一些弊端： 系统调用时根据最先匹配、最优匹配原则，有时会合并，产生额外的开销； 频繁使用，会产生大量的内存碎片，降低程序运行速度； 稍有不慎容易造成内存泄漏。 内存池（memory pool）的出现代替了直接的系统调用。它是首先向系统申请足够大的空间，当需要时向内存池申请，而不是来进行系统调用，使用内存池可以对应解决以上的缺陷。 基本数据结构注：Nginx源码中用 xx_xx_t 来表示type；用 xx_xx_s 表示struct。在源码 /Src/Core/Ngx_palloc.h{c} 中内存池数据块类型 ngx_pool_data_t123456typedef struct &#123; u_char *last;//指向已用的数据结尾 u_char *end;//指向存储空间结尾(内存池结束位置) ngx_pool_t *next;//下一个内存块 ngx_uint_t failed;//内存池分配错误次数&#125; ngx_pool_data_t; 内存池头部结构 ngx_pool_s12345678910struct ngx_pool_s &#123; ngx_pool_data_t d; //内存池数据块 size_t max; //内存池数据块的最大值 ngx_pool_t *current; //指向当前的内存池 ngx_chain_t *chain; ngx_pool_large_t *large; //指向大块内存 ngx_pool_cleanup_t *cleanup; //释放内存时的回调函数 ngx_log_t *log; //日志信息&#125;;typedef struct ngx_pool_s ngx_pool_t; 内存池的基本操作内存池对外提供的函数如下： 功能 函数 创建内存池 ngx_pool_t *ngx_create_pool(size_t size, ngx_log_t *log); 销毁内存池 void ngx_destroy_pool(ngx_pool_t *pool); 重置内存池 void ngx_reset_pool(ngx_pool_t *pool); 内存申请（对齐） void *ngx_palloc(ngx_pool_t *pool, size_t size); 内存申请（不对齐） void *ngx_pnalloc(ngx_pool_t *pool, size_t size); 内存申请并且置为0 void *ngx_pcalloc(ngx_pool_t *pool, size_t size); 内存清除 ngx_int_t ngx_pfree(ngx_pool_t *pool, void *p); 封装的系统调用两个函数 ngx_alloc 和 ngx_calloc 对系统调用 malloc 进行封装。源码./src/Os/Unix（Win32）/ngx_alloc.h/.c。调用malloc申请内存。 123456789101112131415void *ngx_alloc(size_t size, ngx_log_t *log)&#123; void *p; p = malloc(size); if (p == NULL) &#123; ngx_log_error(NGX_LOG_EMERG, log, ngx_errno, \"malloc(%uz) failed\", size); &#125; ngx_log_debug2(NGX_LOG_DEBUG_ALLOC, log, 0, \"malloc: %p:%uz\", p, size); return p;&#125; 申请内存并且置0 1234567891011121314#define ngx_memzero(buf, n) (void) memset(buf, 0, n)void *ngx_calloc(size_t size, ngx_log_t *log)&#123; void *p; p = ngx_alloc(size, log); if (p) &#123; ngx_memzero(p, size); &#125; return p;&#125; 内存池的创建1234567891011121314151617181920212223242526272829303132ngx_pool_t *ngx_create_pool(size_t size, ngx_log_t *log)&#123; ngx_pool_t *p;//申请内存并对齐 p = ngx_memalign(NGX_POOL_ALIGNMENT, size, log); if (p == NULL) &#123; return NULL; &#125;//sizeof(ngx_pool_t) = 40B sizeof(ngx_pool_data_t) = 16B p-&gt;d.last = (u_char *) p + sizeof(ngx_pool_t);//指针设置到跳过内存池的头结构 p-&gt;d.end = (u_char *) p + size;//内存池的结尾 p-&gt;d.next = NULL; p-&gt;d.failed = 0;//可用的最大字节数 size = size - sizeof(ngx_pool_t); p-&gt;max = (size &lt; NGX_MAX_ALLOC_FROM_POOL) ? size : NGX_MAX_ALLOC_FROM_POOL;//其他的一些设置 p-&gt;current = p; p-&gt;chain = NULL; p-&gt;large = NULL; p-&gt;cleanup = NULL; p-&gt;log = log; return p;&#125;//它调用了系统函数/*函数：void * memalign (size_t boundary, size_t size) 函数memalign将分配一个由size指定大小，地址是boundary的倍数的内存块。参数boundary必须是2的幂！函数memalign可以分配较大的内存块，并且可以为返回的地址指定粒度。*/ nginx对内存的管理分为大内存与小内存，当某一个申请的内存大于某一个值时，就需要从大内存中分配空间，否则从小内存中分配空间。nginx中的内存池是在创建的时候就设定好了大小，在以后分配小块内存的时候，如果内存不够，则是重新创建一块内存串到内存池中，而不是将原有的内存池进行扩张。当要分配大块内存是，则是在内存池外面再分配空间进行管理的，称为大块内存池。 内存的申请12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576void *ngx_palloc(ngx_pool_t *pool, size_t size)&#123;#if !(NGX_DEBUG_PALLOC) if (size &lt;= pool-&gt;max) &#123;//申请的空间小于内存池的最大空间 return ngx_palloc_small(pool, size, 1); &#125;#endif return ngx_palloc_large(pool, size);&#125;//申请小内存static ngx_inline void *ngx_palloc_small(ngx_pool_t *pool, size_t size, ngx_uint_t align)&#123; u_char *m; ngx_pool_t *p; p = pool-&gt;current; do &#123; m = p-&gt;d.last; if (align) &#123; m = ngx_align_ptr(m, NGX_ALIGNMENT); &#125;//是否需要对齐，需要则按NGX_ALIGNMENT对齐 if ((size_t) (p-&gt;d.end - m) &gt;= size) &#123; //未使用的空间大于申请的，则不需要链接新的内存块了 p-&gt;d.last = m + size;//移动使用空间末尾指针 return m;//返回新申请空间开始的指针(m, m+size)空间 &#125; //空间不够向链表的下一个节点查询 p = p-&gt;d.next; &#125; while (p); //遍历完还是没有找到，那么再申请 return ngx_palloc_block(pool, size);&#125;//内存对齐#define ngx_align_ptr(p, a) \\ (u_char *) (((uintptr_t) (p) + ((uintptr_t) a - 1)) &amp; ~((uintptr_t) a - 1))static void *ngx_palloc_block(ngx_pool_t *pool, size_t size)&#123; u_char *m; size_t psize; ngx_pool_t *p, *new;//计算第一块的大小 psize = (size_t) (pool-&gt;d.end - (u_char *) pool);//申请与第一块内存相同大小的空间并用m指向 m = ngx_memalign(NGX_POOL_ALIGNMENT, psize, pool-&gt;log); if (m == NULL) &#123; return NULL; &#125;//新的内存块，变为内存池类型 new = (ngx_pool_t *) m;//初始化其中的数据 new-&gt;d.end = m + psize; new-&gt;d.next = NULL; new-&gt;d.failed = 0;//申请内存的结尾设置 m += sizeof(ngx_pool_data_t); m = ngx_align_ptr(m, NGX_ALIGNMENT); new-&gt;d.last = m + size;//将新的内存块连接到内存池链表中 for (p = pool-&gt;current; p-&gt;d.next; p = p-&gt;d.next) &#123; if (p-&gt;d.failed++ &gt; 4) &#123; pool-&gt;current = p-&gt;d.next; &#125; &#125; p-&gt;d.next = new;//返回size大小的内存的起始指针(m, m+size)空间 return m;&#125; 对于申请小的内存（申请大小 &lt; 设定的内存池数据块大小），基本流程就是，在内存池的链表中找空闲的内存，不满足条件的话再创建新的内存块并连接到内存池链表中，注意在内存池中申请内存，只是控制移动指针而已，这时注意字节的对齐，保证读写的高效。 大内存块的申请应用场景：当申请的内存比设置内存块大小大的时候，不能通过链接内存块的方法申请内存，这时需要申请大块内存。123456789101112131415161718192021222324252627282930313233343536373839404142//大块内存的结构，类似于一个链表，alloc指向实际的内存typedef struct ngx_pool_large_s ngx_pool_large_t;struct ngx_pool_large_s &#123; ngx_pool_large_t *next; void *alloc;&#125;;static void *ngx_palloc_large(ngx_pool_t *pool, size_t size)&#123; void *p; ngx_uint_t n; ngx_pool_large_t *large;//直接调用申请size大小的空间，p指向 p = ngx_alloc(size, pool-&gt;log); if (p == NULL) &#123; return NULL; &#125; n = 0;//在大内存块链表中查找空的large for (large = pool-&gt;large; large; large = large-&gt;next) &#123; if (large-&gt;alloc == NULL) &#123; large-&gt;alloc = p; return p; &#125; if (n++ &gt; 3) &#123;//为了效率，查找3次没有找到跳出 break; &#125; &#125;//重新分配一块large sizeof(ngx_pool_large_t) = 8B large = ngx_palloc_small(pool, sizeof(ngx_pool_large_t), 1); if (large == NULL) &#123; ngx_free(p); return NULL; &#125;//链接（插入）到链表的头 large-&gt;alloc = p; large-&gt;next = pool-&gt;large; pool-&gt;large = large; return p;&#125; 过程：在已经有的大块内存中查找 large-&gt;alloc == NULL 的节点，不存在则会新建一个 ngx_pool_large_s 的节点，插入大块内存链表的头，并且使 large-&gt;alloc == new。 内存池的重置和清理12345678910111213141516171819202122232425262728293031323334353637383940voidngx_reset_pool(ngx_pool_t *pool)&#123; ngx_pool_t *p; ngx_pool_large_t *l;//重置所有大块内存区 for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (l-&gt;alloc) &#123; ngx_free(l-&gt;alloc); &#125; &#125;//重置所有小块内存区 for (p = pool; p; p = p-&gt;d.next) &#123; p-&gt;d.last = (u_char *) p + sizeof(ngx_pool_t); p-&gt;d.failed = 0; &#125; pool-&gt;current = pool; pool-&gt;chain = NULL; pool-&gt;large = NULL;&#125;ngx_int_tngx_pfree(ngx_pool_t *pool, void *p)&#123; ngx_pool_large_t *l;//只针对大内存进行释放 for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (p == l-&gt;alloc) &#123; ngx_log_debug1(NGX_LOG_DEBUG_ALLOC, pool-&gt;log, 0, \"free: %p\", l-&gt;alloc); ngx_free(l-&gt;alloc); l-&gt;alloc = NULL; return NGX_OK; &#125; &#125; return NGX_DECLINED;&#125; 我们在使用内存池时，可以使用ngx_palloc进行分配，使用ngx_pfree释放。而对于大内存，这样做是没有问题的，而对于小内存就不一样了，分配的小内存，不会进行释放。因为大内存块的分配只对前3个内存块进行检查，否则就直接分配内存，所以大内存块的释放必须及时。void ngx_destroy_pool(ngx_pool_t *pool) 函数是用于完全释放内存池中申请的空间。 Nginx内存池支持通过回调函数，对外部资源的清理。ngx_pool_cleanup_t是回调函数结构体，它在内存池中以链表形式保存，在内存池进行销毁时，循环调用这些回调函数对数据进行清理。1234567typedef void (*ngx_pool_cleanup_pt)(void *data);typedef struct ngx_pool_cleanup_s ngx_pool_cleanup_t;struct ngx_pool_cleanup_s &#123; ngx_pool_cleanup_pt handler; void *data; ngx_pool_cleanup_t *next;&#125;;","tags":[{"name":"C","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-网络IPC","date":"2017-06-05T02:34:09.000Z","path":"2017/06/05/UNIX环境高级编程-网络IPC/","text":"Unix环境高级编程， 第16章 网络IPC：套接字 读书笔记。不同计算机进行通信的机制。 简述套接字 是通信端点的对象，也有套接字描述符，类似于文件描述符，许多操作也可以直接应用到套接字描述符上。创建一个套接字： 123#include &lt;sys/socket.h&gt;int socket(int domain, int type, int protocol);//成功返回套接字描述符，失败返回-1 参数说明：domain 确定通信的特性，通常有 AF_INET 最常用，表示IPv4因特网域。type 套接字类型，tcp和udp的通信协议分别对应 SOCK_STREAM 和 SOCK_DGRAM ，面向连接的字节流和面向无连接的报文。protocol 通常为零，默认协议。 关闭套接字：1int shutdown(int sockfd, int how); how 的类别决定关闭的方式： SHUT_RD 关闭读端，无法从套接字读取数据； SHUT_WR 关闭写端，无法向套接字写数据； SHUT_RDWR 同时关闭读写，无法向套接字读写数据。 有 close 为何还要用 shutdown 这是因为：close 的调用是在最后一个活动关闭时才释放，而 shutdown 可以使套接字处于非活动状态，不用关心引用的多少；同时，也可以关闭一端。 关于地址字节序字节序是处理器的架构特性，指示像整数这样的大数据类型的内部字节顺序。分为大端字节序（big-endian）和小端模式（little-endian）。TCP/IP协议使用的是大端字节序，异构计算机可以直接进行通信，不会混淆。字节序的转换可以在本地计算机上完成，常用到的函数为：123456#include &lt;arpa/inet.h&gt;uint32_t htonl(uint32_t hostint32);//返回以网络字节序表示的32位整数uint16_t htons(uint16_t hostint16);//返回以网络字节序表示的16位整数uint32_t ntohl(uint32_t netint32);//返回以主机字节序表示的32位整数uint32_t ntohs(uint16_t netint16);//返回以主机字节序表示的16位整数 大端：低地址放着高位数据，高地址放着低位数据。小端：低地址放着低位数据，高地址放着高位数据。 地址格式地址标识了特定通信域的套接字端点，不同格式的地址传入套接字函数，可以用一个统一的结构来保存这个地址，被转换为 sockaddr 结构。因特网地址则定义在：12345678910#include &lt;netinet/in.h&gt;struct in_addr &#123; in_addr_t s_addr; //IPv4地址&#125;;struct sockaddr_in &#123; sa_family_t sin_family; in_port_t sin_port; struct in_addr sin_addr;&#125; 其中，in_port_t 为 uint16_t 类型的，而 in_addr_t 是 uint32_t 类型的。不同的系统下可以自由实现和添加额外的字段。有时，地址的格式不易于人去查看，因此要转换为表达式格式（p），点分十进制。计算机理解的是数值格式（n）。BSD网络软件提供了函数 inet_addr 和 inet_ntoa 用于两者之间的转换。只用于IPv4。下面的函数则可以适用不同协议。12345#include &lt;arpa/inet.h&gt;const char *inet_ntop(int domain, const void *restrict addr, char *restrict str,\\ socklen_t size);//成功返回地址字符串指针int inet_pton(int domain, const char* restrict str, void *restrict addr);//成功返回1，无效返回0，失败返回-1 地址查询1.获得给定计算机的主机信息通过调用 gethostent 函数，返回一个 hostent 结构的数据结构。 12345678910111213141516#include &lt;netdb.h&gt;struct hostent *gethostent(void); //成功返回指针，失败返回NULLvoid sethostent(int stayopen); //打开主机数据文件，void endhostent(void);//关闭struct hostent &#123; char *h_name; //host name char **h_aliases; //pointer of alternate host name array int h_addrtype; //address type int h_length; char **h_addr_list; //pointer to array of network addresses . . .&#125;; 返回地址为网络字节序。2.获取网络名字和网络号 1234567891011121314#include &lt;netdb.h&gt;struct netent *getnetbyaddr(unint32_t net, int type);struct netent *getnetbyname(const char *name);struct netent *getnet(void);void setnetent(int stayopen);void endnetent(void);struct netent &#123; char *n_name; char **n_aliasses; int n_addrtype; uint32_t n_net;&#125; 同样，网络号按照网络字节序返回，地址类型为一个地址族常量（AF_INET）。3.服务和端口号服务是由地址的端口号部分表示的。每个服务由一个唯一的、熟知的端口号表示。如ssh的端口号是22，http的端口号80等。1234567891011121314151617#include &lt;netdb.h&gt;//由服务名字来获得信息struct servent *getservbyname(const char *name, const char *proto);//由端口号来获得信息struct servent *getservbyport(int port, const char *proto);//顺序扫描服务数据库struct servent *getservenmt(void);void setservent(int stayopen);void endservent(void);struct servent &#123; char *s_name; char **s_aliases; int s_port; char *s_proto;&#125;; 4.两个函数函数 getaddrinfo 允许将一个主机名和服务名映射到一个地址。 123456789101112131415#include &lt;sys/socket.h&gt;#include &lt;netdb.h&gt;int getaddrinfo( const char *hostname, const char *service, \\ const struct addrinfo *hints, struct addrinfo **result );typedef struct addrinfo &#123; int ai_flags; //AI_PASSIVE,AI_CANONNAME,AI_NUMERICHOST int ai_family; //AF_INET,AF_INET6 int ai_socktype; //SOCK_STREAM,SOCK_DGRAM int ai_protocol; //IPPROTO_IP, IPPROTO_IPV4, IPPROTO_IPV6 etc. size_t ai_addrlen; //must be zero or a null pointer char* ai_canonname; //must be zero or a null pointer struct sockaddr* ai_addr; //must be zero or a null pointer struct addrinfo* ai_next; //must be zero or a null pointer&#125; hostname:一个主机名或者地址串(IPv4的点分十进制串或者IPv6的16进制串)service：服务名可以是十进制的端口号，也可以是已定义的服务名称，如ftp、http等hints：可以是一个空指针，也可以是一个指向某个addrinfo结构体的指针，调用者在这个结构中填入关于期望返回的信息类型的暗示。举例来说：如果指定的服务既支持TCP也支持UDP，那么调用者可以把hints结构中的ai_socktype成员设置成SOCK_DGRAM使得返回的仅仅是适用于数据报套接口的信息。result：本函数通过result指针参数返回一个指向addrinfo结构体链表的指针。返回值：0成功，非0出错 函数 getnameinfo 将地址转换成主机名或服务名。 12int getnameinfo(const struct sockaddr *sa, socklen_t salen, char *host, \\ size_t hostlen, char *serv, size_t servlen, int flags); 例子： 123456789101112131415161718192021222324252627282930313233343536#include \"apue.h\"#include &lt;sys/socket.h&gt;#include &lt;netdb.h&gt;#include &lt;arpa/inet.h&gt;//using getnameinfo()#define MAX_HO 128int main(int argc, char *argv[])&#123; struct sockaddr_in sa_in; char host[MAX_HO], service[MAX_HO]; int flags; int err; if(argc != 3) err_sys(\"Usage: a.out &lt;IP&gt; &lt;port&gt;\"); int port = atoi(argv[2]); //init addr sa_in.sin_family = AF_INET; sa_in.sin_port = htons(port); inet_pton(AF_INET, argv[1], &amp;sa_in.sin_addr.s_addr); flags = 0; err = getnameinfo((struct sockaddr *)(&amp;sa_in), sizeof(struct sockaddr),\\ host, sizeof(host), service, sizeof(service), flags); if(err != 0) &#123; gai_strerror(err); exit(0); &#125; printf(\"host := %s ; service := %s\\n\", host, service); exit(0);&#125; 套接字与地址套接字中没有包含太多信息，只是一个描述符，并不知道通信的端口和I地址，而建立客户和服务器之间的连接时，往往需要这些信息，所以，在编程过程中要将socket函数产生的套接字与地址相关联。地址结构类似： 12345678910111213//IPv4 struct sockaddr_in &#123; unsigned short sin_len; //IPv4地址长度 short int sin_family; //指代协议簇，在TCP套接字编程只能是AF_INET unsigned short sin_port; //存储端口号（使用网络字节顺序），数据类型是一个16为的无符号整形类型 struct in_addr sin_addr;//存储IP地址，IP地址是一个in_add结构体（结构在下面） unsigned char sin_zero[8]; //为了让sockaddr与sockaddr_in两个数据结构保持大小相同而保留的空字节 &#125;; struct in_addr &#123; unsigned long s_addr; //按照网络字节顺序存储IP地址 &#125;; 这时需要一个函数： 1int bind(int sockfd, const struct sockaddr *addr, socklen_t len); 第二个参数就是套接字地址结构对象了，它将与第一个参数套接字描述符进行绑定，这里的套接字地址结构参数的类型是通用套接字地址结构类型，因此，在实际调用的时候需要强制转换了。 建立连接在处理面向连接的网络服务时，开始交换数据前，必须在请求服务的套接字（客户端）和提供服务的套接字（服务器）之间建立连接。 connect 函数可以建立这样一个连接。 123#include &lt;sys/socket.h&gt;int connect(int sockfd, const struct sockaddr *addr, socklen_t len);//成功返回0，失败返回-1 addr 表示是想与之通信的服务器地址。 服务器调用 listen 来宣告可以接受连接请求。 1234int listen(int sockfd, int backlog);int accept(int sockfd, struct sockaddr *restrict addr, socklen_t *restrict len);//成功返回文件描述符，失败返回-1 backlog 指定了可以连接的数量，超过这一个值则拒绝连接。服务器能够接受到请求，那么会再调用 accept 来获得连接请求并建立连接。它返回的是调用 connect 函数的客户端的套接字描述符。如果不关心客户端的地址信息，则可以忽略后两个参数，将它们设为NULL。当 accept 没有连接请求时，服务器会阻塞直到下一个请求的到来，另外可以使用 pool 和 select 来等待一个请求的到来。基本流程：1234567891011121314151617181920212223242526272829303132/** * 套接字类型，地址，长度，可以连接数量 */int initserver(int type, const struct sockaddr *addr, socklen_t alen, int qlen)&#123; int fd; int err = 0; //1.创建套接字 if((fd = socket(addr-&gt;sa_family, type, 0)) &lt; 0) return (-1); //2.绑定套接字和地址 if(bind(fd, addr, alen) &lt; 0) &#123; err = errno; goto errout; &#125; //3.准备连接 if(type == SOCK_STREAM || type == SOCK_SEQPACKET) &#123; if(listen(fd, qlen) &lt; 0) &#123; err = errno; goto errout; &#125; &#125;errout: close(fd); errno = err; return (-1);&#125; 数据传输send和recv函数123#include &lt;sys/socket.h&gt; ssize_t recv(int sockfd, void *buff, size_t nbytes, int flags); ssize_t send(int sockfd, const void *buff, size_t nbytes, int flags); 它们的前三个参数类似于read 和 write函数，最后一个参数一般为0。send函数的参数 sockfd：指定发送端套接字描述符。 buff：存放要发送数据的缓冲区 nbytes: 实际要发送的数据的字节数 flags： 一般设置为0 recv函数的参数 sockfd: 接收端套接字描述符 buff：用来存放recv函数接收到的数据的缓冲区 nbytes: 指明buff的长度 flags: 一般设置为0 sendto和recvfrom函数这是面向无连接的数据传输，sockfd中不包含地址信息，所以需要指定地址。1234int sendto(int sockfd, const void *msg, size_t nbytes, int flags, const struct sockaddr *destaddr, int destlen);int recvfrom(int sockfd, void *restrict buf, size_t len, int flags, struct sockaddr *restrict addr, socklen_t *restrict addrlen); 例子","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-进程间通信","date":"2017-05-30T07:12:26.000Z","path":"2017/05/30/UNIX环境高级编程-进程间通信/","text":"Unix环境高级编程读书笔记，第14章 进程间通信IPC读书笔记。 进程间通信( inteprocess communication ) 的目的是： 进行数据传输，不同进程协作处理一些数据；资源共享，多个进程间共享数据；通知事件，一个进程向其他进程通知一个事件发生；进程间的通信主要分为：pipe，fifo，消息队列，信号量，共享存储，uds，套接字。 pipe和fifopipepipe又称管道，提供了一个半双工的父子进程之间通信的机制。创建管道很简单： 12#include &lt;unistd.h&gt;int pipe(int fd[2]); fd[0]可以用来读数据，fd[1]可以用来写数据。它们中间会有一个缓冲区。123#include &lt;cstdio&gt;FILE* popen(const char* cmd,const char* type);int pclose(FILE* fp); 打开的是一个可执行的命令，type只能是 r 和 w 可能会返回执行命令的结果。实现上我们值得思考一下，就是 popen 通常来说肯定是创建了一个进程，然后FILE里面记录的 fd 必然和这个进程号做了一个绑定。不然我们在 pclose 使用 FILE*必须能够找到，我们应该 wait 什么进程终止。 在 pclose 必须 fclose 掉句柄，不然如果作为一输入命令的话那么会一直等待输入完成。 实例通过 popen 对输入进行变换的程序。向标准输出一个提示，从标准输入读取一行，使用 popen 可以在标准输入和输出之间添加一个程序来对输入进行变换处理，（当然也可以写成一个函数的形式来解决），基本流程如图。从标准输入读入字符，将其转换成小写的程序。myuclc.c123456789101112131415161718#include \"apue.h\"#include &lt;ctype.h&gt;int main()&#123; int c; while((c = getchar()) != EOF) &#123; if(isupper(c)) c=tolower(c); if(putchar(c) == EOF) err_sys(\"output error\"); if(c=='\\n') fflush(stdout); &#125; exit(0);&#125;编译为可执行文件myuclc，然后通过程序调用它。main.c1234567891011121314151617181920212223#include \"apue.h\"#include &lt;sys/wait.h&gt;int main()&#123; char line[MAXLINE]; FILE *fpin; if((fpin=popen(\"./myuclc\",\"r\")) == NULL) err_sys(\"popen error\"); for( ; ;) &#123; fputs(\"prompt&gt; \", stdout); fflush(stdout); if(fgets(line, MAXLINE, fpin) == NULL) break; if(fputs(line, stdout) == EOF) err_sys(\"fputs error to pipe\"); &#125; if(pclose(fpin) == -1) err_sys(\"pclose error\"); putchar('\\n'); exit(0);&#125; 协同进程当一个程序产生某个过滤程序的输入，并且又读取该过滤程序的输出时，该过滤程序被称为 协同进程coprocess ，popen 只提供连接到另一进程的单向管道，所以需要两个单向管道。 FIFO FIFO通常被称为命名管道，它是一种文件类型.stat结构中的st_mode指明其类型，可以用宏S_ISFIFO 进行测试。 123#include &lt;sys/stat.h&gt;int mkfifo(const char* pathname, mode_t mode);//成功返回0，失败返回-1 类似于管道，若用write写一个没有进程为读而打开的FIFO，则会产生SIG_PIPE信号，若FIFO最后一个写进程关闭了该FIFO，那么会为读进程产生一个文件结束标志。 FIFO用途： 将数据从一条管道线传送到另一条，无需创建临时文件； 用于客户进程-服务器进程的程序中，客户服务器之间传送数据。 实例通常打开FIFO的方式有四种：12345open(const char *path, O_RDONLY);//读，阻塞open(const char *path, O_RDONLY | O_NONBLOCK);//非阻塞 open(const char *path, O_WRONLY);//写，阻塞，一直等待open(const char *path, O_WRONLY | O_NONBLOCK);//写，非阻塞//阻塞情况下，没有对应端打开也会一直等待不返回 XPS IPC 即消息队列、信号量、共享存储。 消息队列消息队列是消息的链接表，存放在内核中并由消息队列标识符标识。流程： msgget 创建或打开一个现存的队列， msgsnd 将消息添加到队列尾端， msgrcv 用于从队列中取消息。 使用 key_t ftok(const char *path, int id);来创建键值， path 必须存在，使用 id 的8位，组合。 消息队列相关的 API 有四个，必须包含的头文件。 123#include &lt;sys/types.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/msg.h&gt; 1.打开或者创建一个队列1int msgget(key_t key, int msgflg); 参数key是一个键值，由ftok获得；msgflg参数是一些标志位。该调用返回与健值key相对应的消息队列描述字。如果没有消息队列与健值key相对应，并且msgflg中包含了IPC_CREAT标志位或key参数为IPC_PRIVATE时创建新的队列。参数msgflg可以为以下：IPC_CREAT、IPC_EXCL、IPC_NOWAIT或三者的或结果。调用返回：成功返回消息队列描述字，否则返回-1。 2.读取消息1int msgrcv(int msqid, struct msgbuf *msgp, int msgsz, long msgtyp, int msgflg); 该系统调用从msgid代表的消息队列中读取一个消息，并把消息存储在msgp指向的msgbuf结构中。msqid为消息队列描述字；消息返回后存储在msgp指向的地址，msgsz指定msgbuf的mtext成员的长度（即消息内容的长度），msgtyp为请求读取的消息类型；读消息标志msgflg可以为以下几个常值的或： IPC_NOWAIT 如果没有满足条件的消息，调用立即返回，此时，errno=ENOMSG IPC_EXCEPT 与msgtyp&gt;0配合使用，返回队列中第一个类型不为msgtyp的消息 IPC_NOERROR 如果队列中满足条件的消息内容大于所请求的msgsz字节，则把该消息截断，截断部分将丢失。 调用返回：成功返回读出消息的实际字节数，否则返回-1。 3.向队列发送一个消息1int msgsnd(int msqid, struct msgbuf *msgp, int msgsz, int msgflg); 向msgid代表的消息队列发送一个消息，即将发送的消息存储在msgp指向的msgbuf结构中，消息的大小由msgze指定。对发送消息来说，有意义的msgflg标志为IPC_NOWAIT，指明在消息队列没有足够空间容纳要发送的消息时，msgsnd是否等待。造成msgsnd()等待的条件有两种： 当前消息的大小与当前消息队列中的字节数之和超过了消息队列的总容量； 当前消息队列的消息数（单位”个”）不小于消息队列的总容量（单位”字节数”），此时，虽然消息队列中的消息数目很多，但基本上都只有一个字节。 调用返回：成功返回0，否则返回-1。 4.垃圾桶函数1int msgctl(int msqid, int cmd, struct msqid_ds *buf); 该系统调用对由msqid标识的消息队列执行cmd操作，共有三种cmd操作：IPC_STAT、IPC_SET 、IPC_RMID。 IPC_STAT：该命令用来获取消息队列信息，返回的信息存贮在buf指向的msqid结构中； IPC_SET：该命令用来设置消息队列的属性，要设置的属性存储在buf指向的msqid结构中；可设置属性包括：msg_perm.uid、msg_perm.gid、msg_perm.mode以及msg_qbytes，同时，也影响msg_ctime成员。 IPC_RMID：删除msqid标识的消息队列； 消息队列编程模型：接受消息端：申明消息类型——&gt; msgget建立消息队列 ——&gt;循环接收消息msgrcv——&gt;结束判断strcmp——&gt;msgctl(IPC_RMID)删除消息发送消息端：申明消息类型——&gt;msgget建立消息队列——&gt;循环输入数据到消息中——&gt;msgsend向队列发送消息——结束判断strcmp——&gt;msgctl删除消息 信号量信号量（semaphore） 是一个计数器，用于多进程对共享数据的访问。工作原理，为了获得共享资源，进程需要： 测试控制资源的信号量； 若此信号量值为正，则可以使用信号量，并将信号量减1，表示使用了一个资源单位； 若此信号量值为0，进程休眠，直到信号量大于0，进程唤醒，重复上述。 1.semget函数获取或者创建信号量集。 123#include &lt;sys/sem.h&gt;int semget(key_t key, int nsems, int flag);//成功返回信号量ID，失败返回-1 第一个参数key是整数值（唯一非零），不相关的进程可以通过它访问一个信号量，它代表程序可能要使用的某个资源，程序对所有信号量的访问都是间接的，程序先通过调用semget函数并提供一个键，再由系统生成一个相应的信号标识符（semget函数的返回值），只有semget函数才直接使用信号量键，所有其他的信号量函数使用由semget函数返回的信号量标识符。第二个参数nsems指定需要的信号量数目，创建新集合的时候非零指定值，引用现有的集合则可以为0。第三个参数flag，当想要当信号量不存在时创建一个新的信号量，可以和值IPC_CREAT做按位或操作。设置了IPC_CREAT标志后，即使给出的键是一个已有信号量的键，也不会产生错误。而IPC_CREAT | IPC_EXCL则可以创建一个新的，唯一的信号量，如果信号量已存在，返回一个错误。 2.semop函数自动执行信号量集合上的操作数组，原子操作，改变信号量的值。 1int semop(int semid, struct sembuf semoparray[], size_t nops); sem_id是由semget返回的信号量标识符，sembuf结构的定义如下： 1234567struct sembuf&#123; short sem_num;//除非使用一组信号量，否则它为0 short sem_op;//信号量在一次操作中需要改变的数据，通常是两个数，一个是-1，即P（等待）操作， //一个是+1，即V（发送信号）操作。 short sem_flg;//通常为SEM_UNDO,使操作系统跟踪信号， //并在进程没有释放该信号量而终止时，操作系统释放信号量 &#125;; 一个例子设置一个信号量，使多进程之间共享。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647union semun&#123; int val; struct semid_ds *buf; unsigned short *array;&#125;;//创建信号量sem_id = semget((key_t)1234, 1, 0666|IPC_CREAT);//初始化信号量，使用前必须这样做static int set_semvalue()&#123; union semun sem_union; sem_union.val = 1; if(semctl(sem_id, 0, SETVAL, sem_union)==-1) return 0; return 1;&#125;static void del_semvalue()&#123; union semun sem_union; if(semctl(sem_id, 0, IPC_RMID, sem_union) == -1) err_sys(\"del semvalue error\");&#125;//p操作static int semaphore_p()&#123; struct sembuf sem_b; sem_b.sem_num = 0; sem_b.sem_op = -1; sem_b.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sem_b, 1) == -1) return 0; return 1;&#125;//v操作static int semaphore_v()&#123; struct sembuf sem_b; sem_b.sem_num = 0; sem_b.sem_op = 1; sem_b.sem_flg = SEM_UNDO; if(semop(sem_id, &amp;sem_b, 1) == -1) return 0; return 1;&#125; 3.semctl函数控制信号量信息。 1int semctl(int semid, int semnum, int cmd,.../* union semun arg */); 如果有第四个参数，它通常是一个union semum结构，定义如下：12345union semun&#123; int val; struct semid_ds *buf; unsigned short *arry; &#125;; 共享存储共享存储允许两个或更多的进程共享以给定的存储区。无需进程间的复制，是一种最快的IPC。多个进程对同一存储区的同步访问。1.shmget函数获取一个共享存储标识符。123#include &lt;sys/shm.h&gt;int shmget(key_t key, size_t size, int flag);//成功返回共享存储ID，出错返回-1 第一个参数，与信号量的semget函数一样，程序需要提供一个参数key（非0整数），它有效地为共享内存段命名，shmget函数成功时返回一个与key相关的共享内存标识符（非负整数），用于后续的共享内存函数。不相关的进程可以通过该函数的返回值访问同一共享内存，它代表程序可能要使用的某个资源，程序对所有共享内存的访问都是间接的，程序先通过调用shmget函数并提供一个键，再由系统生成一个相应的共享内存标识符（shmget函数的返回值），只有shmget函数才直接使用信号量键，所有其他的信号量函数使用由semget函数返回的信号量标识符。第二个参数，size以字节为单位指定需要共享的内存容量。第三个参数，flag是权限标志，它的作用与open函数的mode参数一样，如果要想在key标识的共享内存不存在时，创建它的话，可以与IPC_CREAT做或操作。共享内存的权限标志与文件的读写权限一样，举例来说，0644,它表示允许一个进程创建的共享内存被内存创建者所拥有的进程向共享内存读取和写入数据，同时其他用户创建的进程只能读取共享内存。2.shmat函数第一次创建完共享内存时，它还不能被任何进程访问，shmat函数的作用就是用来启动对该共享内存的访问，并把共享内存连接到当前进程的地址空间。 1void *shmat(int shmid, const void *addr, int flag); 第一个参数，是semget返回的存储空间标识；第二个参数，为0，则连接到第一个可用的地址上，推荐使用；非0并且没有指定SHM_RND，则连接到addr指定的地址；第三个参数，是一组标志位，通常为0。3.shmdt函数用于将共享内存从当前进程中分离。注意，将共享内存分离并不是删除它，只是使该共享内存对当前进程不再可用。1int shmdt(void *addr); addr 参数是调用 shmat 的返回值。4.shmctl函数对共享存储段进行多种操作。 1int shmctl(int shmid, int cmd, struct shmid_ds *buf); 第一个参数，shmid是shmget函数返回的共享内存标识符。第二个参数，cmd是要采取的操作，它可以取下面的三个值 ： IPC_STAT：把shmid_ds结构中的数据设置为共享内存的当前关联值，即用共享内存的当前关联值覆盖shmid_ds的值。 IPC_SET：如果进程有足够的权限，就把共享内存的当前关联值设置为shmid_ds结构中给出的值。 IPC_RMID：删除共享内存段。第三个参数，buf是一个结构指针，它指向共享内存模式和访问权限的结构。 shmid_ds结构至少包括以下成员： 123456struct shmid_ds &#123; uid_t shm_perm.uid; uid_t shm_perm.gid; mode_t shm_perm.mode; &#125;; 例子设计流程，注意多进程同时读写的问题。创建共享存储，获得共享存储标识符；将共享存储连接到进程空间，获得首地址指针；设置存储空间格式；读写存储区。","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-高级IO","date":"2017-05-26T07:01:48.000Z","path":"2017/05/26/UNIX环境高级编程-高级IO/","text":"Unix环境高级编程，第14章 高级I/O 读书笔记。高级 I/O 包括：非阻塞 I/O，记录锁、系统V流机制、I/O多路转换、存储映射 I/O 。 I/O多路转换应用场景： 在服务器编程模型中，客户请求到来时，服务器开启一个进程去服务，但是请求量很大时，服务器不可能一直开启的进程无法满足大量请求。这时，一个进程去服务多个客户，多个客户由于情况不同，不能在一个客户身上浪费太多的时间（阻塞），这时就引入了 I/O 多路复用的技术。其实，解决多用户请求可以用到的方法主要有：非阻塞IO，通过一种叫做 轮询 的方法进行遍历多个描述符，符合要求就去读，不符合下一个，这样在“路上”浪费一些时间，避免使用这种方法；还有一种 异步IO 的方法，核心思想是当一个描述符准备好后，用信号通知，这种方法有一定的系统限制；比较好的方法就是 IO多路转换 了，下面详细介绍。 select和pselect函数传向select的参数告诉内核： 关心的描述符； 对于每个描述符关心的状态（读、写）； 愿意等待的时间。返回时，内核告诉我们： 已准备好的描述符数量； 对于读、写、异常的状态的每一个，哪些描述符已准备好。 12345678910#include &lt;sys/select.h&gt;int select(int maxfdp1, fd_set *restrict readfds, fd_set *restrict writefds, fd_set *restrict exceptfds, struct timeval *restrict tvptr);//返回值：准备就绪的描述符，超时返回0，失败返回-1struct timeval &#123; long tv_sec; //seconds long tv_usec; //microseconds&#125; 关于返回值有三种情况： tvpr==NULL 永远等待，有描述符准备好或捕获到一个信号中断等待； tvpr-&gt;tv_sec==0 &amp;&amp; tvpr-&gt;tv_usec==0 完全不等待； 有一个不等于0，则是等待特定时间。中间的三个参数指定描述符集的指针，可以通过以下API来设置。 12345678//清空集合void FD_ZERO(fd_set *fdset); //将一个给定的文件描述符加入集合之中void FD_SET(int fd, fd_set *fdset);//将一个给定的文件描述符从集合中删除 void FD_CLR(int fd, fd_set *fdset); //检查集合中指定的文件描述符是否可以读写int FD_ISSET(int fd, fd_set *fdset); 第一个参数表示最大的描述符加1。为了限制在指定的范围内查找。select 有三个可能的返回值。1.返回值 -1 表示出错。2.返回值 0 表示没有描述符准备好，所有描述符集被清零。3.正返回值，表示准备好的描述符数量，在描述符集中对应的位表示准备好的描述符。 pselect 为 select 的变形，不同点在于，超时的结构，更精细的粒度来控制超时时间；可以设定信号屏蔽字。 1234int pselect(int maxfd1, fd_set *readfds, fd_set *writefds, fd_set exceptfds, const struct timespec *tsptr, const sigset_t *sigmask); 缺点： 每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 select支持的文件描述符数量太小了，默认是1024 pool函数pool函数可用于任何类型的文件描述符，不是为每个状态构造一个描述符集，而是构造了一个 poolfd 结构数组，每个数组元素指定一个描述符编号以及对其关心的状态。123456int poll(struct pollfd fdarray[], nfds_t nfds, int timeout);struct pollfd&#123; int fd; short events; //常用的读POLLIN/写POLLOUT short revents; //在fd上出现的event，可忽略设置&#125; poll 第一个参数是一个fd数组集合, 每个fd关联一个pollfd结构, 该结构说明fd的关心状态是读还是写poll 第二个参数是第一个参数中fd的个数poll 第三个参数是等待时间, -1表示无限等待, 0表示不等待, 其它正值表示可等待的毫秒数流程：将结构数组中的元素events成员设置为标志（POOLIN POOLOUT等），通过设置这些来告诉内核我们对该描述符关心的是什么，返回时内核设置 revents 来对于该描述符上已经发生了什么事件。 12345678910struct poolfd pfds[2];//定义poolfd结构数组pfds[0].fd=STDIN_FILENO;//关心的描述符pfds[0].events=POOLIN;//对于fd关心的events...pool(pfds, 2, -1);//设置pool，永远等待//判断是否有满足的返回if(pfds[0].revents &amp; POOLIN) //满足&#123; ...&#125; 存储映射I/O存储映射I/O（Memory-mapped I/O） 使一个磁盘文件和存储空间的一个缓冲区相映射，于是当从缓冲区中取数据，就相当于读文件中对应字节，向缓冲区写数据相当于自动写到文件中相应字节。可以在不使用 read 和 write 情况下执行IO。 基本使用首先，通知内核将一个文件映射到存储区中，调用 mmap 函数。 123#include &lt;sys/mman.h&gt;void *mmap(void *addr, size_t len, int prot, int flags, int filedes, off_t off);//返回值：若成功则返回映射区的起始地址，出错返回MAP_FAILED addr 参数用于指定映射存储区的起始地址，一般设置为0，表示由系统选择该映射区的起始地址，函数返回地址是映射区的起始地址。 filedes 指定要被映射文件的描述符，先要打开该文件。 len 表示映射的字节数。 off 映射文件在文件中的起始偏移量。 prot protect参数说明对映射存储区的保护要求。PROT_READ, PROT_WRITE, PROT_EXEC, PROT_NONE 可读可写可执行及不可访问。 其他函数： 1234567#include &lt;sys/mman.h&gt;//更改一个现存映射存储区的权限int mprotect(void *addr, size_t len, int prot);//将页冲洗到被映射的文件中int msync(void *addr, size_t len, int flags);//解除映射int munmap(caddr_t addr, size_t len); 应用： 参考ctthuangcheng 博客的例子。 改变文件的内容，拷贝文件 进程间共享文件 父子进程通信 关于内存映射区的地址：将文件或者其他东西映射到内存是以页面大小为单位进行分配的，往往被分配的映射区大小是页面大小的整数倍，如果不够一个页面则强制变为一个页面大小。文件大小到映射区大小之间的映射关系分为三种情况： 文件大小等于映射区大小，此时映射区的大小分配 文件大小大于映射区大小 文件大小小于映射区大小 如图：","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-线程","date":"2017-05-24T02:52:22.000Z","path":"2017/05/24/UNIX环境高级编程-线程/","text":"Unix环境高级编程读书笔记，第 11、12 章线程和线程控制。 单进程程序中需要处理多个任务时，通常用到多线程来分别处理各个任务，各个线程可以共享进程的资源。Linux中线程函数位于 libpthread 共享库中，因此在编译程序时要加上 lpthread 选项。 线程基本操作线程标识 如进程ID一样，线程也有一个为一个标识，只在进程环境中有效，用 _pthread_t_ 数据类型表示，不是一个整数，因此有专门的函数来比较两个线程的ID。 123#include &lt;pthread.h&gt;int pthread_equal(pthread_t tid1, pthread_t tid2);//相等返回非零pthread_t pthread_self(void);//调用线程的线程ID 线程创建 可以直接调用 pthread_create 函数来创建一个新的线程，线程的执行顺序是不定的，无法保证哪个线程先运行，新的线程可以继承和调用线程的浮点环境和信号屏蔽字，多个线程可以共同访问进程的资源。12345#include &lt;pthread.h&gt;int pthread_create(pthread_t *restrict tidp, const pthread_attr_t *restrict attr, void *(*start_rtn)(void *), void *restrict arg); 成功返回0，失败返回错误编号。 tidp 表示新创建线程的ID， attr 定制各种不同的线程属性， _start_rtn_ 新创建线程的线程函数， arg 表示传入线程的参数，通常是结构体指针。线程终止 进程中的任一个线程如果调用了 exit _Exit _exit 函数，那么整个进程就会退出，如果单个线程退出而不影响整个进程，有下面三种方式： 线程从启动例程返回，返回值为线程的退出码； 线程可以被同一进程中的其他线程取消； 线程调用 pthread_exit 。 12345#include &lt;pthread.h&gt;//终止自己，并设置一个无类型指针表示终止码void pthread_exit(void *rval_ptr);//访问上述的指针一直阻塞等待，获得线程的终止状态void pthread_join(pthread_t thread, void **rval_ptr); 当 pthread_join 返回时，指向的内存必须是全局的或者是动态分配的，否则在栈上会出现覆盖的情况。创建的线程才算终止，才会释放占用的资源。 进程原语和线程原语的比较 进程原语 线程原语 描述 fork pthread_create 创建新的控制流 exit pthread_exit 从现有的控制流中退出 waitpid pthread_join 从控制流中得到退出状态 atexit pthread_cleanup_push 注册在退出时调用的函数 getpid pthread_self 获取控制流的ID abort pthread_cancel 请求控制流的非正常退出 线程同步同一进程中的多个线程共享进程的资源，会产生竞争，为了保证数据的一致性，需要线程同步。1.互斥量通过使用pthread的互斥接口保护数据，确保同一时间只有一个线程访问数据， 互斥量（mutex） 相当于一把锁，在访问共享资源前对其加上一把锁，使用过后，释放。其他线程在访问时，如果加锁会阻塞，直到获取这个互斥锁。互斥变量通常用 pthread_mutex_t 的数据类型表示，使用前必须进行初始化，可以静态也可以动态，动态的话使用后要销毁。对应的 API 如下。1234567891011#include &lt;pthread.h&gt;int pthread_mutex_init(pthread_mutex_t *restrict mutex, const pthread_mutexattr_t *restrict attr);int pthread_mutex_destory(pthread_mutex_t *mutex);int pthread_mutex_lock(pthread_mutex_t *mutex);int pthread_mutex_trylock(pthread_mutex_t *mutex);int pthread_mutex_unlock(pthread_mutex_t *mutex); 2.避免死锁通过加锁的顺序可以避免死锁，使用多个互斥量。3.读写锁读写锁允许更高的并行性。读写锁有三种状态：读模式下加锁状态、写模式下加锁状态、不加锁状态。可以多读，单独写的策略，被称为 共享-独占锁 非常适合读的次数大于写的次数的情况。1234567891011121314 int pthread_rwlock_init (pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr);int pthread_rwlock_destroy (pthread_rwlock_t *__rwlock); /* 读模式下加锁 */ int pthread_rwlock_rdlock (pthread_rwlock_t *__rwlock); /* 非阻塞的读模式下加锁 */ int pthread_rwlock_tryrdlock (pthread_rwlock_t *__rwlock); /* 写模式下加锁 */ int pthread_rwlock_wrlock (pthread_rwlock_t *__rwlock); /* 非阻塞的写模式下加锁 */ int pthread_rwlock_trywrlock (pthread_rwlock_t *__rwlock); /* 解锁 */ int pthread_rwlock_unlock (pthread_rwlock_t *__rwlock); 4.条件变量条件变量可以与互斥量一起使用，等待特定条件的发生。条件本身用互斥量保护，获得了互斥量才可以改变条件或者获得条件的状态。数据类型为 pthread_cond_t 用之前用 PTHREAD_COND_INITIALIZER 静态初始化，或者调用函数动态初始化，结束使用后记得销毁。1234567int pthread_cond_init(pthread_cond_t *cond,pthread_condattr_t *cond_attr); int pthread_cond_wait(pthread_cond_t *cond,pthread_mutex_t *mutex);int pthread_cond_timewait(pthread_cond_t *cond,pthread_mutex *mutex, const timespec *abstime);int pthread_cond_destroy(pthread_cond_t *cond); int pthread_cond_signal(pthread_cond_t *cond); //唤醒单个等待线程int pthread_cond_broadcast(pthread_cond_t *cond); //唤醒所有等待线程 使用 pthread_cond_wait 等待条件为真，互斥量用于保护条件，调用函数时，会进行两个原子操作： 把调用线程放到等待条件的线程列表上； 对互斥量解锁。pthread_cond_timewait 多了一个超时时间，当等待的时间内未满足条件，则会返回一个超时的错误。等待时间的结构 1234struct timespec&#123; time_t tv_sec //Seconds. long tv_nsec //Nanoseconds. &#125;; 函数要求传入的时间值是一个绝对值，不是相对值，例如，想要等待3分钟，必须先获得当前时间，然后加上3分钟。 要想获得当前系统时间的timespec值，没有直接可调用的函数，需要通过调用gettimeofday函数获取timeval结构，然后转换成timespec结构。12345678910struct timeval now;struct timespec until;gettimeofday(&amp;now);//获得系统当前时间//把时间从timeval结构转换成timespec结构until.tv_sec = now.tv_sec;until.tv_nsec = now.tv_usec * 1000;//增加minuntil.tv_sec += 3 * 60; 线程控制线程的一些属性设置等。 守护进程守护进程daemonize是生存周期较长的一种没有控制终端、后台运行的进程，伴随着系统的启动和关闭。编程规则： 首先要做的是调用umask将文件模式创建屏蔽字设置为0。由继承得来的文件模式创建屏蔽字可能会拒绝设置某些权限。例如，若守护进程要创建一个组可读、写的文件，而继承的文件模式创建屏蔽字可能屏蔽了这两种权限，于是所要求的组可读、写就不能起作用。 调用fork，然后使父进程退出（exit）。这样做实现了下面几点：第一，如果该守护进程是作为一条简单shell命令启动的，那么父进程终止使得shell认为这条命令已经执行完毕（也就没有了控制终端）；第二，子进程继承了父进程的进程组ID，但具有一个新的进程ID，这就保证了子进程不是一个进程组的组长进程。这对于下面就要做的setsid调用是必要的前提条件。 调用setsid以创建一个新会话。使调用进程：（a）成为新会话的首进程，（b）成为一个新进程组的组长进程，（c）没有控制终端。 将当前工作目录更改为根目录。从父进程出继承过来的当前工作目录可能在一个挂载的文件系统（a mounted file system）中。因为守护进程通常在系统再引导之前是一直存在的，所以如果守护进程的当前工作目录在一个挂载的文件系统中，那么该文件系统就不能被卸载。这与挂载文件系统的原意不符。 关闭不再需要的文件描述符。 某些守护进程打开/dev/null使其具有文件描述符0、1和2，这样，任何一个试图读标准输入、写标准输出和标准出错的库例程都不会产生任何效果。因为守护进程并不与终端设备相关联，所以不能在终端设备上显示其输出，也无处从交互式用户那里接受输入。即使守护进程是从交互式会话启动的，但因为守护进程是在后台运行的，所以登录会话的终止并不影响守护进程。 参考外链接","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-信号","date":"2017-05-22T02:01:10.000Z","path":"2017/05/22/UNIX环境高级编程-信号/","text":"Unix环境高级编程，第10章 信号，读书笔记。信号是一种软件中断，用于处理异步事件。 基本概念信号都有一个名字，以 SIG 开头，在头文件 &lt;signal.h&gt; 中定义为正整数，信号的编号。信号的产生条件： 终端输入中断按键，如 Ctrl+C 产生了 SIGINT 中断信号； 硬件异常产生的信号，无效内存引用，除0，等，硬件检测到，通知内核； 进程调用 kill(2) 函数可将信号发送给同一用户的另一个进程或进程组； 用户调用 kill(1) 将信号发送给其他进程； 软件中断。 对于信号的处理，有三种方式：忽略此信号、捕捉信号、执行默认动作。系统信号 POSIX 信号 说明 默认动作 SIGHUP 挂起 终止 SIGINT 终端中断符 终止 SIGQUIT 退出 内核中断 SIGILL 非法指令 内核中断 SIGTRAP 断点或陷阱指令 内核中断 SIGABRT/SIGIOT abort发送的信号 内核中断 SIGBUS 非法内存访问 内核中断 SIGFPE 浮点异常 内核中断 SIGKILL kill信号 终止(+) SIGUSR1 用户信号1 终止 SIGSEGV 无效内存访问 内核中断 SIGUSR2 用户信号2 终止 SIGPIPE 管道错误 终止 SIGALRM alrm发送信号 终止 SIGTERM 终止信号 终止 SIGCHLD 子进程退出 忽略 SIGCONT 进程继续 忽略(*) SIGSTOP 进程停止 stop(*)(+) SIGTSTP 终端停止 stop(*) SIGTTIN 后台读控制tty stop(*) SIGTTOU 后台写tty stop(*) SIGURG 紧急情况 忽略 SIGXCPU 超过CPU限制 内核中断 SIGXFSZ 超过文件长度限制 内核中断 SIGVTALRM 虚拟时钟超时 终止 SIGPROF 梗概时间超时 终止 SIGPOLL/SIGIO 轮询事件pool 终止 SIGSYS/SIGUNUSED 无效系统调用 内核中断 SIGSTKFLT 协处理器栈故障 终止 SIGWINCH 终端窗口大小改变 忽略 SIGPWR 电源失效或重启 终止 SIGEMT 硬件故障 内核中断 signal 函数Unix 系统的信号机制最简单的接口就是 signal 函数，当程序收到指定信号时，调用指定的函数。函数原型为 123456#include &lt;signal.h&gt;void (*signal(int signo, void(*func)(int)))(int);//成功返回信号以前的配置，出错返回 SIG_ERR#define SIG_ERR (void (*) ())-1#define SIG_DFL (void (*)())0#define SIG_IGN (void (*)())1 说明： signal 函数有两个参数，返回一个函数指针，这个函数指针有一个参数，并且返回空。 signo 表示上表的函数名称或者编号，第二个参数是一个函数指针，整型参数，返回空。通过宏可以更清晰表示函数：12typedef void Sigfunc(int);Sigfunc *signal(int, Sigfunc); 简单示例：捕获信号 SGIUSR1 和 SGIUSR2 123456789101112131415161718192021static void sig_usr(int); //signal proc functionint main(void)&#123; if(signal(SIGUSR1, sig_usr) == SIG_ERR) err_sys(\"can't catch SIGUSR1\"); if(signal(SIGUSR2, sig_usr) == SIG_ERR) err_sys(\"can not catch SIGUSR2\"); for(;;) pause();&#125;static void sig_usr(int signo)&#123; if(signo == SIGUSR1) printf(\"received SIGUSR1\\n\"); else if(signo == SIGUSR2) printf(\"received SIGUSR2\\n\"); else err_dump(\"received signal:%d\\n\", signo);&#125; 当在终端后台运行程序后，输入 kill USR1 (进程ID) 会捕获相应的信号，输出对应的信息。 sigaction 函数sigaction 函数的功能是用来检查或者修改与指定信号相关联的处理动作，可以用来取代早期的 signal 函数。 12#include &lt;signal.h&gt;ing sigaction(int signo, const struct sigaction *restrict act, struct sigaction *restrict oact); 其中， signo 是要检查的信号编号， act 指针非空，则是要修改动作，如果 oact 非空则会经由该指针返回该信号的上一个动作。使用数据结构：1234567struct sigaction&#123; void (*sa_handler) (int);//信号捕获函数的地址 sigset_t sa_mask;//信号集，调用捕获函数之前，加到信号屏蔽字中 int sa_flags;//信号处理的选项 void (*sa_restorer) (void);//没有使用&#125; sigprocmask 函数信号屏蔽字规定了当前阻塞而不能递送给该进程的信号集，调用 sigprocmask 函数可以检测和更改其信号屏蔽字，或同时执行两个动作。12#include &lt;signal.h&gt;int sigprocmask(int how, const sigset_t *restrict set, sigset_t *restrict oset); oset 为非空指针，那么进程的当前信号屏蔽字通过 oset 返回。 set 为空，不改变进程的屏蔽字， set 非空，由 how 指定如何修改。","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"googletest使用","date":"2017-05-21T03:02:25.000Z","path":"2017/05/21/googletest使用/","text":"googletest是Google的一个C++单元测试框架，Github地址。其中包括了googletest和googlemock。使测试具有良好的独立性和重用性，并可以跨平台使用。 编译安装从github下载源码，本地解压。在 Windows 平台下用vs打开msvc目录中的gtest.sln，全部生成，根据平台的不同会在同目录下的debug和release中生成gtestd.lib和gtest_maind.lib，用时拷贝include和lib文件，并在工程项目中添加依赖。Linux平台下用cmake生成，在源文件目录下创建一个新文件目录如build，进入build打开终端输入cmake ..，生成makefile文件，输入make，生成libgtest.a文件，使用时将include文件包含入项目，动态链接-lgtest由于用到线程也需要链接-lpthread。更多详细信息可以在源码的README.MD。 断言 Google Test 中使用了类似宏的断言来定义测试内容。一般分为两个版本：ASSERT_*，错误抛出异常并终止运行；EXPECT_*生成不致命的错误，不会终止功能的运行。 基本断言用于判断true/false的断言。 致命断言 非致命 验证 ASSERT_TRUE(condition); EXPECT_TRUE(condition); condition is true ASSERT_FALSE(condition); EXPECT_FALSE(condition); condition is false 二元比较测试比较两个值。 致命断言 非致命断言 验证 ASSERT_EQ(val1,val2); EXPECT_EQ(val1,val2); val1 == val2 ASSERT_NE(val1,val2); EXPECT_NE(val1,val2); val1 != val2 ASSERT_LT(val1,val2); EXPECT_LT(val1,val2); val1 &lt; val2 ASSERT_LE(val1,val2); EXPECT_LE(val1,val2); val1 &lt;= val2 ASSERT_GT(val1,val2); EXPECT_GT(val1,val2); val1 &gt; val2 ASSERT_GE(val1,val2); EXPECT_GE(val1,val2); val1 &gt;= val2 字符串比较测试两个字符串string。 致命断言 非致命断言 验证 ASSERT_STREQ(str1,str2); EXPECT_STREQ(str1,_str_2); 两个c字符串有相同的内容 ASSERT_STRNE(str1,str2); EXPECT_STRNE(str1,str2); 两个c字符串不同 ASSERT_STRCASEEQ(str1,str2); EXPECT_STRCASEEQ(str1,str2); 两字符串相同，忽略案例 ASSERT_STRCASENE(str1,str2); EXPECT_STRCASENE(str1,str2); 两字符串不同，忽略用例 简单的使用创建简单测试创建简单测试的过程： 使用TEST()宏定义和命名一个测试函数，不需要返回值，像普通的c++函数一样； 在其中可以使用任何合法的C++语句，并包含Googletest的测试宏，用来检查值； 由其中定义的宏决定返回值，成功或者失败。 如：123TEST(test_case_name, test_name) &#123; //具体测试宏和普通语句&#125; 第一个参数为测试用例的名字，第二个参数为测试的名字，名字符合C++命名规范。 例子： 测试一个函数 int Factorial(int n); // 返回n的阶乘 则测试用例可以写为：123456789101112// Tests factorial of 0.TEST(FactorialTest, HandlesZeroInput) &#123; EXPECT_EQ(1, Factorial(0));&#125;// Tests factorial of positive numbers.TEST(FactorialTest, HandlesPositiveInput) &#123; EXPECT_EQ(1, Factorial(1)); EXPECT_EQ(2, Factorial(2)); EXPECT_EQ(6, Factorial(3)); EXPECT_EQ(40320, Factorial(8));&#125; 上述一个测试用例，包含了两个不同输入的测试。 Test Fixture 为不同测试配置相同的数据写了多组测试，需要用到相似的数据，这时就需要 test fexture ，可以在不同测试中使用相同的对象配置。创建一个 fixture 的过程如下： 先从 ::testing::Test 类中继承一个类，成员函数定义为 public: 或者 protected:，可以使子类访问； 在类中定义你想用到的对象； 如果有必要可以写一个默认构造函数或者 SetUp() 函数，来准备测试所需的对象； 如果有必要写一个析构函数或者 TearDown() 函数，来释放申请的资源信息，与上一步配对使用； 为测试写子程序。 同样，TEST_F() 取代了上面的 TEST() 宏，允许访问 test fixture 中的子程序和对象：123TEST_F(test_case_name, test_name) &#123; //测试&#125; 第一个参数 为测试用例的名称，必须为 test fixture 类的名称（_F 代表了 fixture）。如何使用。 例子：需要测试的一个类 Queue 定义如下： 123456789template &lt;typename E&gt; // E is the element type.class Queue &#123;public: Queue(); void Enqueue(const E&amp; element); E* Dequeue(); // Returns NULL if the queue is empty. size_t size() const; ...&#125;; 定义 fixture 类，命名规范如果待测试的类为 Foo 则 fixture 类命名为 FooTest 。 1234567891011121314class QueueTest : public ::testing::Test &#123; protected: virtual void SetUp() &#123; q1_.Enqueue(1); q2_.Enqueue(2); q2_.Enqueue(3); &#125; // virtual void TearDown() &#123;&#125; Queue&lt;int&gt; q0_; Queue&lt;int&gt; q1_; Queue&lt;int&gt; q2_;&#125;; 使用 TES_F() 和 fixture class 创建测试 1234567891011121314151617181920TEST_F(QueueTest, IsEmptyInitially) &#123; EXPECT_EQ(0, q0_.size());&#125;TEST_F(QueueTest, DequeueWorks) &#123; int* n = q0_.Dequeue(); EXPECT_EQ(NULL, n); n = q1_.Dequeue(); ASSERT_TRUE(n != NULL); EXPECT_EQ(1, *n); EXPECT_EQ(0, q1_.size()); delete n; n = q2_.Dequeue(); ASSERT_TRUE(n != NULL); EXPECT_EQ(2, *n); EXPECT_EQ(1, q2_.size()); delete n;&#125; 进行如上工作时，如何运作的呢？ 构造一个 QueueTest 对象，如t1； 调用 t1.SetUp() 来初始化 t1 ； 在 t1 上运行第一个测试 IsEmptyInitially ； 测试完成后，调用t1.TearDown() ； 析构 t1 ； 重复上述测试。 调用测试初始化，运行所有测试，代码如下：12345int main(int argc, char *argv[])&#123; testing::InitGoogleTest(&amp;argc, argv); return RUN_ALL_TESTS();&#125;","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"},{"name":"测试","slug":"test","permalink":"http://abumaster.com/tags/test/"}]},{"title":"UNIX环境高级编程-进程","date":"2017-05-19T02:22:59.000Z","path":"2017/05/19/UNIX环境高级编程-进程/","text":"Unix环境高级编程，第7、8、9章有关进程的读书笔记。 进程环境进程的启动和终止。一般c程序从入口函数main开始，调用一系列用户函数等；进程终止有正常终止和异常终止两种，其中，正常终止是程序从main函数返回(return)，或者正常调用退出函数exit _exit _Exit，或者线程的返回或退出，异常终止通常会调用abort或者信号中断。命令行参数和环境表它们都是有外界给程序的参数，就像标注的 ISO C 规定的主函数书写格式 1int main(int argc,char *argv[] 将命令行参数保存，而环境变量表则被取消了，仍可以通过函数访问环境表。 查看和设置环境变量，12345#include &lt;stdlib.h&gt;char *getenv(const char* envname);int putenv(char *str);//不会分配空间int setenv(char *name, char *value, int rewrite);//分配空间int unsetenv(const char *name); C 程序的存储空间分布如图： 正文段，存放程序运行所需的机器指令部分，具有只读属性； 初始化数据段，明确初始化的变量； 未初始化的数据； 栈，存放自动变量或者临时变量； 堆，动态分配的空间。 非局部goto123#include &lt;setjmp.h&gt;int setjmp(jmp_buf env);//设置返回的位置void longjmp(jmp_buf env, int val);//开始返回 回滚一些变量的值，如果不想回滚到之前的值，可以将变量定义为：volatile，全局或静态变量的值也会保持不变。 进程控制进程标识符非负整型来表示唯一进程ID，但是可以重用，通常ID=0表示交换进程或者调度进程，ID=1表示init进程，ID=2表示页守护进程。123#include &lt;unistd.h&gt;pid_t getpid();//进程IDpid_t getppid();//父进程ID fork函数12#include &lt;unistd.h&gt;pid_t fork(void); 两个返回，子进程返回0，通过getppid获得父进程id，ID为0，是交换进程使用，父进程返回子进程的ID，因为，这是父进程获得子进程ID的唯一方式。exec函数fork创建新进程，exec可以执行新程序，exit处理终止，wait等待终止。1234567#include &lt;unistd.h&gt;int execl(const char *pathname, const char *arg0, ...);int execv(const char *pathname, char * const argv[]);int execle(const char *pathname, const char *argv0, ..., /*char *const envp[]*/);int execve(const char *pathname, char *const argv[], char *const envp[]);int execlp(const char *filename, const char *argv0, ...);int execvp(const char *filename, char *const argv[]); 区别前四个函数取路径名，后两个取文件名作为参数。system函数12#include &lt;stdlib.h&gt;int system(const char *cmdstring); 用于执行一个命令字符串，调用了fork函数，exec函数，waitpid函数。 进程关系终端登录和网络登录的进程关系图： 进程组进程组是一个或多个进程的集合，通常与一个作业关联。1234#include &lt;unistd.h&gt;pid_t getpgrp(void);//调用进程的进程组IDpid_t getpgid(pid_t pid);//pid的进程组ID//getpgrp()等价于getpgid(0); 会话会话是一个或多个进程组的集合。","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-标准IO库","date":"2017-05-18T00:39:42.000Z","path":"2017/05/18/UNIX环境高级编程-标准IO库/","text":"Unix环境高级编程读书笔记，第5章 标准I/O库。引入流的概念，并引入缓冲，减少read和write的调用次数。 1.文件I/O和标准I/O区别标准I/O使用了缓冲机制，文件I/O不使用，而是直接调用内核中的一个系统调用完成。操作的对象不同，文件io操作的是文件描述符，标准io操作的是流，流与磁盘等外围设备关联。他们的函数对比。 操作 标准I/O 文件I/O 打开 fopen, froen, fdopen open 关闭 fclose close 读 getc, fgetc, getchar,fgets, gets,fread read 写 putc, fputc, putchar,fputs, puts,fwrite write 2.缓冲 标准I/O提供的几种缓冲及其区别。 全缓冲，填满缓冲区后再进行实际的I/O操作，磁盘文件通常使用全缓冲。填满缓冲区后，调用fflush来刷新缓冲区，flush(冲洗)用来将缓冲区的内容写到磁盘上；flush(刷清)丢弃已经存储在缓冲区中的数据，用在终端驱动程序方面。 行缓冲，用在终端的输入输出，遇到换行符的时候，或者缓冲区满。 无缓冲，标准出错流，stderr，错误信息及时显示出来。 对于一个打开的流，设置更改缓冲区。 12345678#include &lt;stdio.h&gt;void setbuf(FILE *restrict fp, char *restrict buf);void setvbuf(FILE *restrict fp, char *restrict buf, int mode, size_t size);/* mode 参数： _IOFBF 全缓冲；_IOLBF 行缓冲；_IONBF 不带缓冲 *///强制冲洗流int fflush(FILE *fp); 3.操作打开关闭流打开关闭标准I/O流，如上表的函数所示。读写流打开了流，有三种类型的方式进行读写操作： 每次一个字符的I/O; 每次一行的I/O; 直接I/O。 每个流在FILE对象上维持了两个标志：出错标志，文件结束标志。gets 和fgets，不推荐使用前者，因为不能指定缓冲区大小，容易造成缓冲区溢出，另外，gets不保留换行符。4.临时文件123#include&lt;stdio.h&gt;char* tmpnam(char *ptr);//指向唯一路径的指针char *tmpfile(void); //返回文件指针","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"},{"name":"c","slug":"c","permalink":"http://abumaster.com/tags/c/"},{"name":"编程","slug":"编程","permalink":"http://abumaster.com/tags/编程/"}]},{"title":"UNIX环境高级编程-文件和目录","date":"2017-05-16T11:39:00.000Z","path":"2017/05/16/UNIX环境高级编程-文件和目录/","text":"UNIX环境高级编程读书笔记，第4章 文件和目录。 I/O操作描述的是普通文件的读写等操作，本章介绍文件系统的其他特征和文件的性质。 1.三个stat函数1234#include &lt;sys/stat.h&gt;int stat(const char *restrict pathname, struct stat *restrict buf);int fstat(int filedes, struct stat *buf);int lstat(const char *restrict pathname, struct stat *restrict buf); 返回与此文件相关联的信息结构stat，关于stat的结构说明：123456789101112131415struct stat &#123; mode_t st_mode;//文件类型 ino_t st_ino;//i节点 dev_t st_dev;//设备号 文件系统 dev_t st_rdev; nlink_t st_nlink; uid_t st_uid; gid_t st_gid; off_t st_size;//大小 time_t st_atime;//访问时间 time_t st_mtime;//修改时间 time_t st_ctime;//改变时间 blksize_t st_blksize;//块大小 blkcnt_t st_blocks;//分配的磁盘块&#125; 2.文件类型 普通文件； 目录文件； 块特殊文件； 字符特殊文件； FIFO，进程间通信，命名管道； 套接字，网络间通信； 符号链接在&lt;sys/stat.h&gt;中定义了获取文件类型的宏，参数为st_mode成员。 宏 文件类型 S_ISREG() 普通文件 S_ISDIR() 目录文件 S_ISCHR() 字符特殊文件 S_ISBLK() 块特殊文件 S_ISFIFO() 管道或FIFO S_ISLNK() 符号链接 S_ISSOCK() 套接字 3.文件的访问权限分为三类：用户、组、其他，而每类对应的权限为：读、写、执行。4.文件系统i节点：固定长度的记录项，保存着文件的大部分信息。理解inode。内核中，以inode编号来标识文件，而不是以文件名标识文件。","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"UNIX环境高级编程-文件IO","date":"2017-05-15T12:29:43.000Z","path":"2017/05/15/UNIX环境高级编程-文件IO/","text":"UNIX环境高级编程读书笔记，第3章 文件 I/O。 文件描述符Linux一切皆文件，无论是设备还是文档都是一个文件，这种抽象显示了Linux系统的灵活和通用性。文件描述符一般是一个非负整数，当打开或者创建一个文件时，内核向进程返回一个文件描述符，此描述符用于其他操作的参数。通常在unistd.h中定义了常量：STDIN_FILENO STDOUT_FILENO STDERR_FILENO分别代表数字0,1,2是标准输入输出错误输出三种基本的文件描述符。open函数描述：打开或者创建文件，返回文件描述符或者-112#include &lt;fcntl.h&gt;int oepn(const char* pathname, int flags,.../*mode_t mode*/); creat函数描述：创建一个文件，只能只写的方式打开，成功返回文件描述符，失败-1close函数描述：关闭文件描述符lseek函数描述：为一个打开的文件描述符设置偏移量，成功返回新的文件偏移量，失败-112#include &lt;unistd.h&gt;off_t lseek(int filedes, off_t offset, int whence); 偏移量的方式取决于第三个参数。SEEK_SET 开始处设置偏移量，绝对偏移量；SEEK_CUR 当前位置设置偏移量，相对偏移量；SEEK_END 结束开始设置偏移量，相对于文件末端偏移量。read函数打开的文件中读取数据，返回读取的字节数，如果剩余文件不够要读的字节数。write函数向打开的文件中写数据，返回实际写入的数据字节数。 文件共享不同进程之间共享打开的文件，内核使用三种数据结构表示打开的文件。1.进程表项描述一个打开的文件描述表，每个文件描述符表包含了两项： 文件描述符标志 指向文件表项的指针2.文件表每个文件表包含如下信息： 文件状态标志（读写…) 当前文件偏移量 指向文件v节点表项的指针3.v节点表v节点表表示文件类型，以及对文件进行各种操作的指针，也包含了i节点及文件长度等信息。不同进程打开同一个文件的各项状态。 dup和dup2函数用来复制一个现存的文件描述符。123#include &lt;unistd.h&gt;int dup(int filedes);int dup2(int filedes, int filedes2); dup返回的文件描述符是当前可用文件描述符的最小值；dup2可以用filedes来指定新的描述符，如果filedes2已经打开，则先将其关闭，如果相等，则返回filedes2，不必关闭。执行dup后，文件表项和v节点表项不变。作用：一般用于重定向和共享文件，如父进程处理了一些文件，现在需要子进程处理，可以dup一份；同样dup2的使用，可以看为dup2(源, 目标)，目标将会被源替换掉。具体使用。fcntl函数可以读取和改变打开文件的性质。12#include &lt;fcntl.h&gt;int fcntl(int filedes, int cmd, .../*int arg*/); fnctl的功能： 复制一个现有的描述符，cmd=F_DUPFD 获取/设置文件描述符标记(cmd=F_GETFD / F_SETFD) 获得和设置文件状态标志cmd=F_GETFL F_SETFL 获取和设置异步I/O所有权cmd=F_GETOWN F_SETOWN 获得和设置记录锁cmd = F_GETLK F_SETLK同样，复制文件描述符函数：dup(filedes)等价于fcntl(filedes, F_DUPFD, 0)。调用dup2(filedes1,filedes2)相当于调用：close(filedes2); fcntl(filedes1, F_DUPFD, filedes2)。不同之处在于dup2函数是原子操作，而用fcntl是两个函数调用。dup2的功能:12345dup2(fd, 0);dup2(fd, 1);dup2(fd, 2);if(fd &gt; 2) close(fd); 假设fd=1，则执行后的结果图如下：fd=3时，结果同，把3的文件复制到前3个上，删除以后的。","tags":[{"name":"Linux","slug":"linux","permalink":"http://abumaster.com/tags/linux/"}]},{"title":"High-performance Semantic Segmentation using VDFC","date":"2017-05-10T07:37:56.000Z","path":"2017/05/10/High-performance-Semantic-Segmentation-using-VDFC/","text":"High-performance Semantic Segmentation Using Very Deep Fully Convolution [1] ，论文阅读笔记。 本文做的贡献： 探索不同的全卷积残差网络找到更好的配置，诸如，网络的层数、特征图的分辨率、感受野的大小等，由于内存的限制等因素，提出了用低分辨率网络来模拟高分辨网络进行训练和测试； 提出了在线引导（online booststrapping）的方法进行训练，已经论证可以达到更好的正确率； 将传统的dropout应用到残差块中； 达到了很好的结果。 1.低分辨率近似高分辨率的模型由于内存的限制，网络不允许输入过大分辨率的图像，但是分辨率大的图像往往可以保存更多的细节信息，可以达到更好的分割效果，所以，提出了这个低分辨率来近似高分辨率的模型。基本的做法是：如果输入一个图像，经过了中间的若干层，图像的分辨率会下降，假设缩小为原始的1/8，（1）产生了一个1/8的特征图，这时，（2）可以在上一层池化层提取出剩下1/8的图像，（3）分别获得两个1/8的得分图，（4）组合，得到1/4的得分图或者是标签。 2.损失函数$$ e = -\\frac{1}{\\sum_i^N \\sum_j^K{1\\{y_i=j\\ and\\ p_{ij}&lt;t\\}}}(\\sum_i^N\\sum_j^K1\\{y_i=j \\ and\\ p_{ij}&lt;t\\}logp_{ij})$$ [1] Wu Z, Shen C, Hengel A. High-performance semantic segmentation using very deep fully convolutional networks[J]. arXiv preprint arXiv:1604.04339, 2016. K表示语义标签，N表示像素的个数，$p_{ij}$表示像素$a_i$分到标签$c_j$的概率，$y_i$表示$a_i$的正确标签。符号$1{.}$表示满足括号里的条件为1，不满足为0。","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"计算机视觉","slug":"computerversion","permalink":"http://abumaster.com/tags/computerversion/"}]},{"title":"宏定义","date":"2017-05-09T12:36:26.000Z","path":"2017/05/09/宏定义/","text":"宏定义进入编译器之前展开替换。 宏常量#define MAX 100用100替换符号MAX，c++中一般不推荐使用，通常用常量const定义；用于条件编译的宏如避免包含重复头文件的宏： 12345#ifdefine XXX #define XXX //some include file#endif` 宏函数避免函数调用，提高执行效率，以空间换取时间。对于一些重复的函数可以声明为宏函数，就像内联函数一样…例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667typedef int (*Onefunction)();//定义函数指针typedef map&lt;string, Onefunction&gt; OneMap;//名称，函数指针相关联的mapOneMap g_one_map;//全局变量保存//注册函数的宏，其中展开为一个按名定义的类，//构造函数,将函数地址和函数名称放入全局的map中//最后一个简单的类对象声明，可以保证构造函数的执行，//作用域可以保证在执行完后对象的销毁，用过即销毁。#define RegisterOneFunction(func) \\&#123; \\class __Register_##func &#123; \\public: \\__Register_##func() &#123; \\g_one_map[#func] = &amp;func; \\&#125; \\&#125;; \\__Register_##func g_register_##func; \\&#125;//自定义的函数，无参，返回intint func1()&#123; cout &lt;&lt; \"func1 out...\\n\"; return 0;&#125;int func2()&#123; cout &lt;&lt; \"func2 out...222\\n\"; return 0;&#125;//调用宏，注册函数void WrapperRegisterFunction()&#123; RegisterOneFunction(func1); RegisterOneFunction(func2);&#125;//根据函数名称获得函数的指针Onefunction GetOneFunction(const string&amp; fname)&#123; if(g_one_map.count(fname)) &#123; return g_one_map[fname]; &#125; else &#123; cout &lt;&lt; \"not found\"&lt;&lt;endl; for(OneMap::iterator it=g_one_map.begin(); it!=g_one_map.end(); it++) &#123; cout &lt;&lt;it-&gt;first&lt;&lt;\" \"; &#125; cout&lt;&lt;endl; return NULL; &#125;&#125;int main()&#123; string funNmae; WrapperRegisterFunction(); cin &gt;&gt; funNmae; //以名称来使用函数 GetOneFunction(funNmae)(); return 0;&#125; 注意事项 1.普通宏定义 宏名一般用大写 使用宏可提高程序的通用性和易读性，减少不一致性，减少输入错误和便于修改 预处理是在编译之前的处理，而编译工作的任务之一就是语法检查，预处理不做语法检查 宏定义末尾不加分号 宏定义写在函数的花括号外边，作用域为其后的程序，通常在文件的最开头 可以用#undef命令终止宏定义的作用域 宏定义可以嵌套 字符串””中永远不包含宏 宏定义不分配内存，变量定义分配内存2.带参宏定义 实参如果是表达式容易出问题 宏名和参数的括号间不能有空格 宏替换只作替换，不做计算，不做表达式求解 函数调用在编译后程序运行时进行，并且分配内存。宏替换在编译前进行，不分配内存 宏的哑实结合不存在类型，也没有类型转换 函数只有一个返回值，利用宏则可以设法得到多个值 宏展开使源程序变长，函数调用不会 宏展开不占运行时间，只占编译时间，函数调用占运行时间（分配内存、保留现场、值传递、返回值）","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"caffe学习-分类","date":"2017-05-07T11:29:00.000Z","path":"2017/05/07/caffe学习-分类/","text":"在用caffe的c++接口时，遇到了许多问题，学习源码中解决问题，熟悉一些细节。 1.预测分类的流程图 2.代码注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239//classification.cpp/*一些头文件*/#ifdef USE_OPENCV/* Pair (label, confidence) * 代表一个预测结果，标签和概率的组合 */typedef std::pair&lt;string, float&gt; Prediction;//定义一个分类的类class Classifier &#123; public: Classifier(const string&amp; model_file, const string&amp; trained_file, const string&amp; mean_file, const string&amp; label_file);//提供给外部的接口，返回一个预测。参数：需要预测的图像和概率最大的N个结果 std::vector&lt;Prediction&gt; Classify(const cv::Mat&amp; img, int N = 5); private: void SetMean(const string&amp; mean_file);//设置中值 std::vector&lt;float&gt; Predict(const cv::Mat&amp; img); void WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels); void Preprocess(const cv::Mat&amp; img, std::vector&lt;cv::Mat&gt;* input_channels); private: shared_ptr&lt;Net&lt;float&gt; &gt; net_; cv::Size input_geometry_; int num_channels_; cv::Mat mean_; std::vector&lt;string&gt; labels_;&#125;;Classifier::Classifier(const string&amp; model_file, const string&amp; trained_file, const string&amp; mean_file, const string&amp; label_file) &#123;#ifdef CPU_ONLY Caffe::set_mode(Caffe::CPU);#else Caffe::set_mode(Caffe::GPU);#endif //加载网络配置并初始化 net_.reset(new Net&lt;float&gt;(model_file, TEST)); net_-&gt;CopyTrainedLayersFrom(trained_file); CHECK_EQ(net_-&gt;num_inputs(), 1) &lt;&lt; \"Network should have exactly one input.\"; CHECK_EQ(net_-&gt;num_outputs(), 1) &lt;&lt; \"Network should have exactly one output.\"; //取出输入层的blob结构，可以提取出通道和输入图像的高宽 Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0]; num_channels_ = input_layer-&gt;channels(); CHECK(num_channels_ == 3 || num_channels_ == 1) &lt;&lt; \"Input layer should have 1 or 3 channels.\"; input_geometry_ = cv::Size(input_layer-&gt;width(), input_layer-&gt;height()); //加载中值文件 SetMean(mean_file); //加载标签文件 std::ifstream labels(label_file.c_str()); CHECK(labels) &lt;&lt; \"Unable to open labels file \" &lt;&lt; label_file; string line; while (std::getline(labels, line)) labels_.push_back(string(line)); //检查标签数目和输出维度是否匹配 Blob&lt;float&gt;* output_layer = net_-&gt;output_blobs()[0]; CHECK_EQ(labels_.size(), output_layer-&gt;channels()) &lt;&lt; \"Number of labels is different from the output layer dimension.\";&#125;//自定义比较函数，用于排序预测结果static bool PairCompare(const std::pair&lt;float, int&gt;&amp; lhs, const std::pair&lt;float, int&gt;&amp; rhs) &#123; return lhs.first &gt; rhs.first;&#125;//返回v中元素最大的N个数的下标索引static std::vector&lt;int&gt; Argmax(const std::vector&lt;float&gt;&amp; v, int N) &#123; std::vector&lt;std::pair&lt;float, int&gt; &gt; pairs; for (size_t i = 0; i &lt; v.size(); ++i) pairs.push_back(std::make_pair(v[i], static_cast&lt;int&gt;(i))); std::partial_sort(pairs.begin(), pairs.begin() + N, pairs.end(), PairCompare); std::vector&lt;int&gt; result; for (int i = 0; i &lt; N; ++i) result.push_back(pairs[i].second); return result;&#125;//输入图像，返回前N个概率最大的预测(标签，概率)std::vector&lt;Prediction&gt; Classifier::Classify(const cv::Mat&amp; img, int N) &#123; std::vector&lt;float&gt; output = Predict(img); N = std::min&lt;int&gt;(labels_.size(), N); std::vector&lt;int&gt; maxN = Argmax(output, N); std::vector&lt;Prediction&gt; predictions; for (int i = 0; i &lt; N; ++i) &#123; int idx = maxN[i]; predictions.push_back(std::make_pair(labels_[idx], output[idx])); &#125; return predictions;&#125;/* Load the mean file in binaryproto format. */void Classifier::SetMean(const string&amp; mean_file) &#123; BlobProto blob_proto; ReadProtoFromBinaryFileOrDie(mean_file.c_str(), &amp;blob_proto); /* Convert from BlobProto to Blob&lt;float&gt; */ Blob&lt;float&gt; mean_blob; mean_blob.FromProto(blob_proto); CHECK_EQ(mean_blob.channels(), num_channels_) &lt;&lt; \"Number of channels of mean file doesn't match input layer.\"; /* The format of the mean file is planar 32-bit float BGR or grayscale. */ std::vector&lt;cv::Mat&gt; channels; float* data = mean_blob.mutable_cpu_data(); for (int i = 0; i &lt; num_channels_; ++i) &#123; /* Extract an individual channel. */ cv::Mat channel(mean_blob.height(), mean_blob.width(), CV_32FC1, data); channels.push_back(channel); data += mean_blob.height() * mean_blob.width(); &#125; /* Merge the separate channels into a single image. */ cv::Mat mean; cv::merge(channels, mean); /* Compute the global mean pixel value and create a mean image * filled with this value. */ cv::Scalar channel_mean = cv::mean(mean); mean_ = cv::Mat(input_geometry_, mean.type(), channel_mean);&#125;//预测函数，返回输出的概率std::vector&lt;float&gt; Classifier::Predict(const cv::Mat&amp; img) &#123; Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0]; input_layer-&gt;Reshape(1, num_channels_, input_geometry_.height, input_geometry_.width); /* Forward dimension change to all layers. */ net_-&gt;Reshape(); std::vector&lt;cv::Mat&gt; input_channels; WrapInputLayer(&amp;input_channels); Preprocess(img, &amp;input_channels); net_-&gt;Forward(); /* Copy the output layer to a std::vector */ Blob&lt;float&gt;* output_layer = net_-&gt;output_blobs()[0]; const float* begin = output_layer-&gt;cpu_data(); const float* end = begin + output_layer-&gt;channels(); return std::vector&lt;float&gt;(begin, end);&#125; /* 包装网络的输入层，将每个通道保存为Mat对象， * 最后直接将分割的通道写入到输入层中 */void Classifier::WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels) &#123; Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0]; int width = input_layer-&gt;width(); int height = input_layer-&gt;height(); //获取可更改的输入层数据指针 float* input_data = input_layer-&gt;mutable_cpu_data(); for (int i = 0; i &lt; input_layer-&gt;channels(); ++i) &#123; cv::Mat channel(height, width, CV_32FC1, input_data); input_channels-&gt;push_back(channel); input_data += width * height; &#125;//将各个通道变为Mat，依次放入vector中&#125;//图像拷贝入输入层中void Classifier::Preprocess(const cv::Mat&amp; img, std::vector&lt;cv::Mat&gt;* input_channels) &#123; /* 将输入图像转换为网络要求的输入格式 */ //通道数 cv::Mat sample; if (img.channels() == 3 &amp;&amp; num_channels_ == 1) cv::cvtColor(img, sample, cv::COLOR_BGR2GRAY); else if (img.channels() == 4 &amp;&amp; num_channels_ == 1) cv::cvtColor(img, sample, cv::COLOR_BGRA2GRAY); else if (img.channels() == 4 &amp;&amp; num_channels_ == 3) cv::cvtColor(img, sample, cv::COLOR_BGRA2BGR); else if (img.channels() == 1 &amp;&amp; num_channels_ == 3) cv::cvtColor(img, sample, cv::COLOR_GRAY2BGR); else sample = img; //大小 cv::Mat sample_resized; if (sample.size() != input_geometry_) cv::resize(sample, sample_resized, input_geometry_); else sample_resized = sample; //浮点数 cv::Mat sample_float; if (num_channels_ == 3) sample_resized.convertTo(sample_float, CV_32FC3); else sample_resized.convertTo(sample_float, CV_32FC1); //归一化处理：减去中值 cv::Mat sample_normalized; cv::subtract(sample_float, mean_, sample_normalized); //直接将mat拷贝到输入层，已经处理过输入层为Mat对象了 cv::split(sample_normalized, *input_channels); CHECK(reinterpret_cast&lt;float*&gt;(input_channels-&gt;at(0).data) == net_-&gt;input_blobs()[0]-&gt;cpu_data()) &lt;&lt; \"Input channels are not wrapping the input layer of the network.\";&#125;//主函数命令行调用int main(int argc, char** argv) &#123; if (argc != 6) &#123; std::cerr &lt;&lt; \"Usage: \" &lt;&lt; argv[0] &lt;&lt; \" deploy.prototxt network.caffemodel\" &lt;&lt; \" mean.binaryproto labels.txt img.jpg\" &lt;&lt; std::endl; return 1; &#125; ::google::InitGoogleLogging(argv[0]); string model_file = argv[1]; string trained_file = argv[2]; string mean_file = argv[3]; string label_file = argv[4]; Classifier classifier(model_file, trained_file, mean_file, label_file); string file = argv[5]; std::cout &lt;&lt; \"---------- Prediction for \" &lt;&lt; file &lt;&lt; \" ----------\" &lt;&lt; std::endl; cv::Mat img = cv::imread(file, -1); CHECK(!img.empty()) &lt;&lt; \"Unable to decode image \" &lt;&lt; file; std::vector&lt;Prediction&gt; predictions = classifier.Classify(img); /* Print the top N predictions. */ for (size_t i = 0; i &lt; predictions.size(); ++i) &#123; Prediction p = predictions[i]; std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(4) &lt;&lt; p.second &lt;&lt; \" - \\\"\" &lt;&lt; p.first &lt;&lt; \"\\\"\" &lt;&lt; std::endl; &#125;&#125;#elseint main(int argc, char** argv) &#123; LOG(FATAL) &lt;&lt; \"This example requires OpenCV; compile with USE_OPENCV.\";&#125;#endif // USE_OPENCV","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"Caffe笔记","date":"2017-05-01T06:41:52.000Z","path":"2017/05/01/Caffe笔记/","text":"Caffe学习中的遇到的一些问题拾遗。 1..solverstate的使用在网络训练过程中当保存一个快照时，会保存两个文件：**.caffemodel 和 **.solverstate 第一个文件是训练过程中，迭代了N次，保存的模型，第二个文件是训练过程意外暂停，如ctrl+C 或者电脑死机，保存的网络状态，下一次网络可以接着训练，参考Caffe Wiki - Training and Resuming。使用： 命令行训练：caffe train -solver solver.prototxt状态中恢复训练：caffe train -solver solver.prototxt -snapshot train_190000.solverstate Python 接口从模型中copy参数：1234weights = '../ilsvrc-nets/vgg16-fcn.caffemodel'# initsolver = caffe.SGDSolver('solver.prototxt')solver.net.copy_from(weights) 从状态中恢复训练： 12solver = caffe.SGDSolver('solver.prototxt')solver.restore('snapshot/train_iter_2000.solverstate') 这时不需要copy参数了。 2.编写网络配置文件通常创建一个创建一个 solver 来表示网络的参数信息，包括：迭代次数，训练策略以及保存快照等。其中包含了一个训练网络模型定义和一个测试网络模型定义文件，也可以写在一个配置文件中，当写在一个文件中的时候，要在网络的不同之处加上： 123include &#123; phase: TEST (TRAIN) &#125; 3.网络运行过程 加载 solver 有两种方式（Python 接口）：solver = caffe.get_solver(&#39;models/bvlc_reference_caffenet/solver.prototxt&#39;) 和solver = caffe.SGDSolver(&#39;models/bvlc_reference_caffenet/solver.prototxt&#39;) 开始训练： 12solver.net.forward() # train netsolver.test_nets[0].forward() # test net (there can be more than one) 这是一次从输入层到损失层的计算过程，最后计算出loss，反向传播时，可以写为：solver.net.backward()，这是计算从损失层到输入层的梯度，并更新网络中各层的参数信息。前向传播和反向传播可以合并写，表示一次完整的计算：solver.step(1)。如果要按照配置文件中的最大迭代次数运行网络，则写为：solver.solve()。 4.验证模型正确率12345678accuracy = 0batch_size = solver.test_nets[0].blobs['data'].num #训练批次test_iters = int(len(Xt) / batch_size) #迭代次数for i in range(test_iters): solver.test_nets[0].forward() #测试网络 accuracy += solver.test_nets[0].blobs['accuracy'].data #相加每次迭代的正确率accuracy /= test_iters #平均正确率print(\"Accuracy: &#123;:.3f&#125;\".format(accuracy)) 5.定义自己的Python层Python层通常用来对输入数据进行预处理，如在图像语义分割中，输入为Python层，用于读取训练图像和分割图像。自定义Python层是，需在prototxt文件中指明层的类型为python并且指明需要的函数，如：1234567891011layer &#123; name: 'MyPythonLayer' type: 'Python' top: 'output' bottom: 'conv' python_param &#123; module: 'mypythonlayer' layer: 'MyLayer' param_str: \"'num': 21\" &#125;&#125; 然后，需要按以下格式定义自己的Python文件，如：12345678910111213141516171819import caffeimport numpy as npimport yamlclass MyLayer(caffe.Layer): def setup(self, bottom, top): self.num = yaml.load(self.param_str)[\"num\"] print \"Parameter num : \", self.num def reshape(self, bottom, top): pass def forward(self, bottom, top): #前传 top[0].reshape(*bottom[0].shape) top[0].data[...] = bottom[0].data + self.num def backward(self, top, propagate_down, bottom): pass 使用时还与普通网络调用一样进行，只是会直接用python定义的层完成输入数据的重新组织，再进行传递。","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"}]},{"title":"尺度感知模型","date":"2017-04-25T07:02:25.000Z","path":"2017/04/25/尺度感知模型/","text":"来自 2016 年 ICCV 论文：Attention to Scale: Scale-aware Semantic Image Segmentation，注意尺度：尺度敏感图像语义分割。在全卷积网络中合并多尺度特征已经是提高图像语义分割效果的一个关键因素。通过不同图像尺寸的输入，提取出不同尺度的信息，通过一个注意力模型获得权重融合特征图，最终得到分割图像。 1.注意力模型 Attention modelAttention model(AM)最先在计算机视觉中被应用于图片识别的问题，之后在自然语言处理(NLP)和计算机视觉(CV)中经常结合递归神经网络结构RNN、GRU、LSTM等深度学习算法，被称之为Recurrent Attention Model(RAM)，其核心就是一个Encoder-Decoder的过程。图像识别中，经常把图像缩放成固定大小，引起信息的丢失，结合人看物体时，目光会沿着感兴趣的方向移动，甚至聚焦感兴趣的区域，Attention（注意力）就是在网络中加入关注区域的移动、缩放机制、连续部分信息序列化输入。知乎问题回答。可以分为两种模型： hard：Attention 每次移动固定大小区域； soft：Attention 每次是所有区域的一个加权和。注意力，人看一副图像不是按像素点去看的，往往是一个区域一个区域看的，关注感兴趣区域（Region of Interest），Attention 可以自动寻找感兴趣的区域？强化学习。2.如何利用多尺度信息在 FCNs 场景下，有两种方式利用多尺度信息，如图所示： 利用网络中间层信息，由于随着网络层数的增加，图像不断缩小，图像的特征也会不断地丢失，在经典的FCN-8s网络中提出了融合中间层的特征图，优化最后的分割结果； 多尺度图像输入，网络共享权重，不同尺度会产生不同大小的特征图，每个尺度的特征图关注点也不同，通过在最后对不同尺度特征图的融合，产生最终的分割结果。3.模型介绍模型如何运作？不同尺度图像输入 FCNs 中会生成不同的热力图（得分图），然后，如何融合不同的得分图，论文中提出了一个注意力模型，对于每个尺度特征图输出一个权重图，权重是如何生成的呢，通过学习，对于大物体在褚略的特征图上置为较大的权重。有了权重图，结合特征图，很容易加权融合多个尺度特征图，得到最后的输出。每个尺度，对应着一个score map，这里乘以由尺度获得的权重图，得到最终的输出图。权重是由注意力模型产生的score map的所占比重决定的，表示摸个尺度的重要性。","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"计算机视觉","slug":"computerversion","permalink":"http://abumaster.com/tags/computerversion/"}]},{"title":"零散","date":"2017-04-19T06:25:45.000Z","path":"2017/04/19/零散/","text":"VMware虚拟机在Windows下错误 出现如下错误：VMware Workstation and Device/Credential Guard are not compatible Windows的虚拟化技术Hyper-v和VMware的虚拟化技术不兼容的问题！解决方案：1.关闭hyper-v服务如图，关闭红色框内的功能。2.增加开机启动选项stackoverflow 问题回答在CMD管理员身份运行，注意不能用PowerShell。编辑bcd。12345C:\\&gt;bcdedit /copy &#123;current&#125; /d &quot;No Hyper-V&quot; The entry was successfully copied to &#123;ff-23-113-824e-5c5144ea&#125;. C:\\&gt;bcdedit /set &#123;ff-23-113-824e-5c5144ea&#125; hypervisorlaunchtype off The operation completed successfully. 重启经过一段时间配置，开机启动项出现了两个选项： Windows 10 No Hyper-V 删除开启启动项：在CMD中输入：123C:\\&gt;bcdedit /v列出了开机启动项，删除对应的选项即可。C:\\&gt;bcdedit /delete &#123;ff-23-113-824e-5c5144ea&#125; 另一种，在系统配置中直接配置引导项。 图像分类： Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.Papandreou G, Kokkinos I, Savalle P A. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 390-399. 物体检测： Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 580-587.Erhan D, Szegedy C, Toshev A, et al. Scalable object detection using deep neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014: 2147-2154.Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems. 2015: 91-99.He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 770-778. CNN用于图像分割Schulz H, Behnke S. Learning Object-Class Segmentation with Convolutional Neural Networks[C]//ESANN. 2012.Farabet C, Couprie C, Najman L, et al. Scene parsing with multiscale feature learning, purity trees, and optimal covers[J]. arXiv preprint arXiv:1202.2160, 2012.Farabet C, Couprie C, Najman L, et al. Learning hierarchical features for scene labeling[J]. IEEE transactions on pattern analysis and machine intelligence, 2013, 35(8): 1915-1929.Dai J, He K, Sun J. Convolutional feature masking for joint object and stuff segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3992-4000. Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440. 刘丹,刘学军,王美珍. 一种多尺度CNN的图像语义分割算法[J]. 遥感信息,2017,(01):57-64.蒋应锋,张桦,薛彦兵,周冕,徐光平,高赞. 一种新的多尺度深度学习图像语义理解方法研究[J]. 光电子·激光,2016,(02):224-230. Mostajabi M, Yadollahpour P, Shakhnarovich G. Feedforward semantic segmentation with zoom-out features[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3376-3385.Lin G, Shen C, van den Hengel A, et al. Efficient piecewise training of deep structured models for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 3194-3203.","tags":[{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"}]},{"title":"Caffe的C++接口调用","date":"2017-04-18T12:25:06.000Z","path":"2017/04/18/Caffe的C-接口调用/","text":"Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。 1.配置第三方库Windows上运行的是官方的 Caffe-Windows 项目，第三方库是从别人打包好的下载，主要分为几大类：boost、gflags、glog、hdf5、LevelDB、lmdb、OpenBLAS、OpenCV、protobuf。配置内容包括（调试器最好配置Release版本的x64平台）：头文件新建一个工程，打开项目-&gt;工程属性页，C/C++ -&gt; 常规 -&gt; 附加包含目录，添加caffe相关的头文件,caffe及第三方依赖库，我的如下：1D:\\caffeDev\\caffe-master\\include;D:\\caffeDev\\NugetPackages\\boost.1.59.0.0\\lib\\native\\include;D:\\caffeDev\\NugetPackages\\OpenCV.2.4.10\\build\\native\\include;D:\\caffeDev\\NugetPackages\\gflags.2.1.2.1\\build\\native\\include;D:\\caffeDev\\NugetPackages\\glog.0.3.3.0\\build\\native\\include;D:\\caffeDev\\NugetPackages\\hdf5-v120-complete.1.8.15.2\\lib\\native\\include;D:\\caffeDev\\NugetPackages\\lmdb-v120-clean.0.9.14.0\\lib\\native\\include;D:\\caffeDev\\NugetPackages\\protobuf-v120.2.6.1\\build\\native\\include;D:\\caffeDev\\NugetPackages\\OpenBLAS.0.2.14.1\\lib\\native\\include; 附加库目录链接器 -&gt; 常规 -&gt; 附加库目录 ，添加内容为lib库所在的目录：1&lt;AdditionalLibraryDirectories&gt;D:\\caffeDev\\NugetPackages\\glog.0.3.3.0\\build\\native\\lib\\x64\\v120\\Release\\dynamic;D:\\caffeDev\\caffe-master\\Build\\x64\\Release;D:\\caffeDev\\NugetPackages\\OpenCV.2.4.10\\build\\native\\lib\\x64\\v120\\Release;D:\\caffeDev\\NugetPackages\\boost_date_time-vc120.1.59.0.0\\lib\\native\\address-model-64\\lib;D:\\caffeDev\\NugetPackages\\boost_filesystem-vc120.1.59.0.0\\lib\\native\\address-model-64\\lib;D:\\caffeDev\\NugetPackages\\boost_system-vc120.1.59.0.0\\lib\\native\\address-model-64\\lib;D:\\caffeDev\\NugetPackages\\protobuf-v120.2.6.1\\build\\native\\lib\\x64\\v120\\Release;D:\\caffeDev\\NugetPackages\\boost_thread-vc120.1.59.0.0\\lib\\native\\address-model-64\\lib;D:\\caffeDev\\NugetPackages\\boost_chrono-vc120.1.59.0.0\\lib\\native\\address-model-64\\lib;D:\\caffeDev\\NugetPackages\\hdf5-v120-complete.1.8.15.2\\lib\\native\\lib\\x64;D:\\caffeDev\\NugetPackages\\gflags.2.1.2.1\\build\\native\\x64\\v120\\dynamic\\Lib;D:\\caffeDev\\NugetPackages\\OpenBLAS.0.2.14.1\\lib\\native\\lib\\x64;%(AdditionalLibraryDirectories)&lt;/AdditionalLibraryDirectories&gt; 依赖项输入 -&gt; 附加依赖项，中填写需要的链接库，为上述目录中的链接库：12345678910111213141516171819202122232425262728293031323334353637383940&lt;AdditionalDependencies&gt;opencv_calib3d2410.lib;opencv_contrib2410.lib;opencv_core2410.lib;opencv_features2d2410.lib;opencv_flann2410.lib;opencv_gpu2410.lib;opencv_highgui2410.lib;opencv_imgproc2410.lib;opencv_legacy2410.lib;opencv_ml2410.lib;opencv_nonfree2410.lib;opencv_objdetect2410.lib;opencv_ocl2410.lib;opencv_photo2410.lib;opencv_stitching2410.lib;opencv_superres2410.lib;opencv_ts2410.lib;opencv_video2410.lib;opencv_videostab2410.lib;libglog.lib;caffe.lib;libprotobuf.lib;libcaffe.lib;gflags.lib;gflags_nothreads.lib;hdf5.lib;hdf5_cpp.lib;hdf5_f90cstub.lib;hdf5_fortran.lib;hdf5_hl.lib;hdf5_hl_cpp.lib;hdf5_hl_f90cstub.lib;hdf5_hl_fortran.lib;hdf5_tools.lib;szip.lib;zlib.lib;libopenblas.dll.a;%(AdditionalDependencies)&lt;/AdditionalDependencies&gt; 2.运行时问题实际新建一个项目（从caffe工程中拷的源码，配置好一切环境），可以编译成功，但是运行时出现问题：F0519 14:54:12.494139 14504 layer_factory.hpp:77] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Input (known types: Input )一者说，只有在caffe解决方案中新建项目，才可以正常运行问题。还有利用别人改进的caffe来减少外部的依赖关系，dtmoodie。另外一种，解决方法主要解决方案是将caffe中的各层都放进一个头文件中包含进工程中，1234#include \"caffe/common.hpp\" #include \"caffe/layers/input_layer.hpp\"extern INSTANTIATE_CLASS(InputLayer);//添加层信息REGISTER_LAYER_CLASS(Input);//注册层信息 可以完美运行了。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"高效分片训练结构化模型用于图像语义分割","date":"2017-04-17T08:58:15.000Z","path":"2017/04/17/高效分片训练结构化模型用于图像语义分割/","text":"cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。 特点： 制定了基于CNN的在CRFs上总体分段潜在函数模型用于衡量语义图像片之间的关系； 分段训练CRFs，避免重复推导，提高速度； 多尺度图像输入，用于探索图像背景和前景上下文信息； Featmap-Net是一个卷积网络，用于输出特征图，低分辨率的特征图； 创建CRF图，首先对于卷积网络生成的特征图，创建一些边界框，在边界框内被认为空间近似，顶点才会全连接，不同空间会创建不同的边界框。 上下文深度CRFs分为一元组的图的顶点和二元组的图的边，分别对应一个能量函数，通过一元和二元网络对应生成了类别的预测。利用背景上下文产生特征图的网络： 首先将输入图像缩放为三个不同的大小，放入网络，共享权重。图像缩放大小为1.2,0.8,0.4，再经过一层独立的卷积产生多尺度特征图，然后经过滑动金字塔池化产生了组合的特征图，金字塔池化如下图所示：使用双线性上采样和简单的边界优化对粗糙的预测结果进行后期处理，可能又更复杂的优化方式，比如：训练反卷积网络，训练复杂的从粗糙到精细的网络，利用中间特征图到高分辨率的预测。","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"计算机视觉","slug":"computerversion","permalink":"http://abumaster.com/tags/computerversion/"}]},{"title":"拉普拉斯重建和细化用于图像语义分割","date":"2017-04-16T08:05:56.000Z","path":"2017/04/16/拉普拉斯重建和细化用于图像语义分割/","text":"来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。 空间语义不确定性原则，探索在CNN特征层次结构中的空间和语义正确性。网络的顶层图像语义预测准确，但是带来的缺陷是在低分辨率下的图像空间上的定位，边界清晰但是标签有噪声。提出了一种重建模型在给定层次上提高空间定位的准确性，和一种细化技术用来融合多层的信息来优化图像的语义分割结果。与传统FCN的区别：不同之处在于，上采样和重建。CNN 特征图固有的缺少空间细节信息用一些不同的方法可以解决，如条件随机场、超像素、边界检测。还有一些成对的特征映射，可以进行反向传播进行训练。此论文的方法是直接提高输出激活图空间分辨率。双线性上采样是从低分辨率特征图中计算出高分辨率分割图的一种标准方法，首先卷积网络从特征图中计算出低分辨率的得分图，然后使用线性过滤器上采样为高分辨率的得分图。这种方法可能会从多通道低分辨率特征图中丢失定位信息。为了保留更多的空间信息，论文避免了将高维特征图折叠成低分辨率的类别预测。取而代之的是利用高分辨率基函数的线性组合对高分辨率的分类得分图的空间模式进行编码，这些函数的权重被高维特征图预测得到。实现：将高分辨率的特征图分成不重叠的图像块，大小取决于网络中池化层的个数次幂，通过一个卷积网络预测从高纬度低分辨率到特征图像块的映射。这些特征图像块和类别系数与一个基本函数集合相乘，再与一个基本的去卷积层相加，得到期望的全分辨率类别图。连接样条插值更高阶的样条插值替代上采样。学习基本函数基本结构首先，网络从上到下，分辨率越来越小。在每一次缩小时，特征图重建，再进行组合，产生对应倍数特征图的分割得分图，上图的水平方向，通过组合不同倍数的得分图。一种从高分辨率中减去低频成分的方法，边界masking，孤立出边界成分。金字塔的应用：下层分割图得分上采样作为上一层采样的参考，用于得分图和像素对的产生。Conclusion 以特定类重建为基础作为上采样； 合成低分辨率的语义丰富的特征图和拥有更多空间特性的高分辨率特征图，多层拉普拉斯金字塔重建结构。 最后可以加上CRF进行后期处理，优化结果。","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"计算机视觉","slug":"computerversion","permalink":"http://abumaster.com/tags/computerversion/"}]},{"title":"网易2017春招笔试编程题","date":"2017-04-14T06:14:18.000Z","path":"2017/04/14/网易2017春招笔试编程题/","text":"感悟：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"算法","slug":"algorithm","permalink":"http://abumaster.com/tags/algorithm/"}]},{"title":"FCN图像语义分割计算的细节问题","date":"2017-04-11T08:59:57.000Z","path":"2017/04/11/FCN图像语义分割计算的细节问题/","text":"Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。 从论文中地址中，下载FCN源码到本地。 1.使用现有模型进行图像语义分割 解压源代码，在根目录下，有一个infer.py的文件，打开，配置自己的模型路径，运行即可。 1234567891011121314151617181920212223import numpy as npfrom PIL import Imageimport matplotlib.pyplot as pltimport caffe# load image, switch to BGR, subtract mean, and make dims C x H x W for Caffeim = Image.open('voc-fcn8s/21.jpg')in_ = np.array(im, dtype=np.float32)in_ = in_[:,:,::-1]#in_ -= np.array((104.00698793,116.66876762,122.67891434))in_ -= np.array((106.08069,103.75618,100.05657))in_ = in_.transpose((2,0,1))# load netnet = caffe.Net('voc-fcn8s/deploy.prototxt', 'voc-fcn8s/fcn8s-heavy-pascal.caffemodel', caffe.TEST)# shape for input (data blob is N x C x H x W), set datanet.blobs['data'].reshape(1, *in_.shape)net.blobs['data'].data[...] = in_# run net and take argmax for predictionnet.forward()out = net.blobs['score'].data[0].argmax(axis=0)#print outplt.imshow(out,cmap='gray');plt.axis('off')plt.savefig('test1.png') 2.源码阅读 在源码的voc-fcn32s问价夹下，net.py用于生成网络的配置文件：train.prototxt、val.prototxt，solve.py用来运行训练网络，solver.prototxt是训练的配置文件：12345678910111213141516171819train_net: &quot;train.prototxt&quot;test_net: &quot;val.prototxt&quot;test_iter: 736# make test net, but don&apos;t invoke it from the solver itselftest_interval: 999999999display: 20average_loss: 20lr_policy: &quot;fixed&quot;# lr for unnormalized softmaxbase_lr: 1e-10# high momentummomentum: 0.99# no gradient accumulationiter_size: 1max_iter: 100000weight_decay: 0.0005snapshot: 4000snapshot_prefix: &quot;snapshot/train&quot;test_initialization: false solve.py 文件解读它调用了根目录下的 surgery.py 和 score.py 文件，后面再介绍。主要作用： 用现有的分类网络模型初始化网络； 自定义上采样层的卷积核； 加载验证图片，自定义最后的得分输出。初始化网络： 12345678weights = '../ilsvrc-nets/vgg16-fcn.caffemodel' #加载训练好的分类模型solver = caffe.SGDSolver('solver.prototxt')#加载网络配置文件solver.net.copy_from(weights)#从模型中复制权重#也可以写为如下方式：#solver = caffe.SGDSolver('solver.prototxt')#vgg_net = caffe.Net('solver.prototxt', weights, caffe.TRAIN)#surgery.transplant(solver.net, vgg_net)#del vgg_net 调用surgery.py中的上采样层，双线性插值，将图像变为原始大小。 12interp_layers = [k for k in solver.net.params.keys() if 'up' in k]surgery.interp(solver.net, interp_layers) 得分层 12345# scoringval = np.loadtxt('../data/segvalid11.txt', dtype=str)#加载验证图片for _ in range(25): solver.step(4000) score.seg_tests(solver, False, val, layer='score')#测试网络的得分情况 surgery.py 文件解读主要作用是制作适用于给定长宽的双线性插值内核，用于上采样。主要函数为:123456789101112def upsample_filt(size): \"\"\" Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size. \"\"\" factor = (size + 1) // 2 if size % 2 == 1: center = factor - 1 else: center = factor - 0.5 og = np.ogrid[:size, :size] return (1 - abs(og[0] - center) / factor) * \\ (1 - abs(og[1] - center) / factor) score.py 文件解读主要作用：计算当前网络分割图的准确性。主要有以下几个标准：mean loss, overall accuracy, per-class accuracy, per-class IU。如何计算的呢？首先理解两个函数：1234567891011121314151617181920212223242526272829#计算a和b对应相同的就在矩阵中对应坐标加1。a和b保存着各个像素的分的类别0-20共21类def fast_hist(a, b, n): k = (a &gt;= 0) &amp; (a &lt; n)#过滤掉多余的分类 #bincount用于统计在范围内出现的个数，即直方图，如果不够n^2个， #那就填充到n^2，这样可以reshpe为n*n的矩阵，正好表示分割图和正确标记图在相同 #类别上像素出现的个数 return np.bincount(n * a[k].astype(int) + b[k], minlength=n**2).reshape(n, n)#调用计算直方图函数，指定了数据来源def compute_hist(net, save_dir, dataset, layer='score', gt='label'): n_cl = net.blobs[layer].channels#得到score层的通道数，fcn中为21通道，21类物体 if save_dir:#是否将分割图保存为文件 os.mkdir(save_dir) #hist表示：分割图中21类和标记图21类出现的像素数 #如：在i,j像素位置上分割图标记为2类物体，而实际标记为3那么在hist（2,3）+=1 # 在i,j+1像素位置分割图标记2类物体，实际标记图也为2类，则hist(2,2)+=1 # 可以看出hist对角矩阵是正确的分割； hist = np.zeros((n_cl, n_cl))#初始化21*21的二维矩阵 loss = 0 for idx in dataset: net.forward()#网络向前传播 #展开为一维数组 hist += fast_hist(net.blobs[gt].data[0, 0].flatten(), net.blobs[layer].data[0].argmax(0).flatten(),n_cl) if save_dir: im = Image.fromarray(net.blobs[layer].data[0].argmax(0).astype(np.uint8), mode='P') im.save(os.path.join(save_dir, idx + '.png')) # compute the loss as well 计算网络的损失 loss += net.blobs['loss'].data.flat[0]#flat[0]取第一个数 return hist, loss / len(dataset) 计算几个分割效果指标：1234567891011121314#mean loss print '&gt;&gt;&gt;', datetime.now(), 'Iteration', iter, 'loss', loss # overall accuracy acc = np.diag(hist).sum() / hist.sum()#对角线正确像素/总像素 print '&gt;&gt;&gt;', datetime.now(), 'Iteration', iter, 'overall accuracy', acc # per-class accuracy acc = np.diag(hist) / hist.sum(1)#每一类的 print '&gt;&gt;&gt;', datetime.now(), 'Iteration', iter, 'mean accuracy', np.nanmean(acc) # per-class IU iu = np.diag(hist) / (hist.sum(1) + hist.sum(0) - np.diag(hist)) print '&gt;&gt;&gt;', datetime.now(), 'Iteration', iter, 'mean IU', np.nanmean(iu) freq = hist.sum(1) / hist.sum() print '&gt;&gt;&gt;', datetime.now(), 'Iteration', iter, 'fwavacc', \\ (freq[freq &gt; 0] * iu[freq &gt; 0]).sum() 其他文件：训练文件的输入层类型是Python，作者自定义了一个voc_layers.py的Python数据加载层。 setup函数，设置voc训练集的路径，及中值文件，挑选数据的随机数； load_image和load_label函数，用于从数据集中加载图像和标记图像，并转换成数组形式，图像减去中值并转换成chanl*height*weight形式，label变为1*height*weight形式； forward和backward函数，前向传播将图像、标签复制到top[0]和top[1]中，反向传播不需要任何操作。 学习到的东西Python中numpy中的一些函数，诸如bincount、flatten、diag等。","tags":[{"name":"学习","slug":"学习","permalink":"http://abumaster.com/tags/学习/"},{"name":"caffe","slug":"caffe","permalink":"http://abumaster.com/tags/caffe/"}]},{"title":"Stanford Background Dataset介绍和使用","date":"2017-04-10T06:35:07.000Z","path":"2017/04/10/Stanford-Background-Dataset介绍和使用/","text":"Stanford Background Dataset是一个从各个数据库（LabelMe, MSRC, PASCAL VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。 images文件夹包含了715张图像； horizons.txt 图像名称、大小、水平线位置； labels/*.regions.txt 标识每个像素的语义，0-7代表八类语义； labels/*.surfaces.txt 标识每个像素的几何类别（天空，水平，垂直）； labels/*.layers.txt 表示不同图像区域的整数矩阵。 读取图像和分割图像1.首先读取标签文件123456789101112131415vector&lt;char&gt; vec;//保存像素标记void readlabel(string labelname)&#123; ifstream infile(labelname.c_str(), std::ios::in); char line[1024] = &#123; 0 &#125;; while (infile.getline(line, sizeof(line))) &#123; stringstream word(line); char ch; while (word &gt;&gt; ch) &#123; vec.push_back(ch); &#125; &#125;&#125; 2.显示分割图像，根据语义标签，设置不同的颜色以区别 //显示分割图像 Mat colorim(im.rows, im.cols, CV_8UC3); int index = 0; //遍历所有像素，并设置像素值 for (int i = 0; i &lt; colorim.rows; ++i) { //获取第 i 行首像素指针 Vec3b * p = colorim.ptr&lt;Vec3b&gt;(i); for (int j = 0; j &lt; colorim.cols; ++j) { int lab = vec[index++]; switch (lab) { case '0'://sky p[j][0] = 128; //Blue p[j][1] = 128; //Green p[j][2] = 128; //Red break; case '1'://tree p[j][0] = 84; //Blue p[j][1] = 230; //Green p[j][2] = 80; //Red break; case '2'://road p[j][0] = 115; //Blue p[j][1] = 0; //Green p[j][2] = 100; //Red break; case '3'://grass p[j][0] = 0; //Blue p[j][1] = 255; //Green p[j][2] = 0; //Red break; case '4'://water p[j][0] = 255; //Blue p[j][1] = 0; //Green p[j][2] = 0; //Red break; case '5'://building p[j][0] = 0; //Blue p[j][1] = 0; //Green p[j][2] = 160; //Red break; case '6'://mountain p[j][0] = 63; //Blue p[j][1] = 214; //Green p[j][2] = 8; //Red break; case '7'://obj p[j][0] = 37; //Blue p[j][1] = 159; //Green p[j][2] = 230; //Red break; default://somthing else p[j][0] = 255; //Blue p[j][1] = 255; //Green p[j][2] = 255; //Red break; } } } imshow(\"分割图\", colorim); 结果","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"dataset","slug":"dataset","permalink":"http://abumaster.com/tags/dataset/"}]},{"title":"caffe提取各层特征","date":"2017-04-09T12:07:29.000Z","path":"2017/04/09/caffe提取各层特征/","text":"根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：1.caffe创建分类器Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\\python\\caffe下。 初始化这个分类器的时候，出现了一个问题：12345678net = caffe.Classifier(caffe_root + 'models/bvlc_reference_caffenet/deploy.prototxt',caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel')net.set_phase_test()net.set_mode_cpu()net.set_mean('data', caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy')net.set_channel_swap('data', (2,1,0)) net.set_input_scale('data', 255) 就是在网络设置时，一直提示没有set_phase_test(*)的成员函数，试了几个平台都是如此提示，后来在网上找到了一点信息其中提到了，可以直接创建的时候初始化，对应于函数的声明所需的参数：12345net = caffe.Classifier(MODEL_FILE, PRETRAINED, mean=np.load(os.path.join(CAFFE_DIR, 'python/caffe/imagenet/ilsvrc_2012_mean.npy')), channel_swap=(2, 1, 0), raw_scale=255, image_dims=(256, 256)) 维度不匹配问题代码如下：1234567 File &quot;one.py&quot;, line 14, in &lt;module&gt; image_dims=(256, 256)) File &quot;/home/zgf/caffe-master/python/caffe/classifier.py&quot;, line 34, in __init__ self.transformer.set_mean(in_, mean) File &quot;/home/zgf/caffe-master/python/caffe/io.py&quot;, line 259, in set_mean raise ValueError(&apos;Mean shape incompatible with input shape.&apos;)ValueError: Mean shape incompatible with input shape. 中值文件读取的错误，在网络上找到了解决方案，将读取中值文件改为：mean=np.load(&#39;/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy&#39;).mean(1).mean(1)可以解决。 2.显示特征图像问题按照文档描述依次往下进行，文档使用的工具为ipython，显示图片用：ipt.show()，而我用的工具是jupyter，所以一直找不到这个命令，无法查看图像，从网上查到，可以在代码前面加上一句%matplotlib inline然后用import matplotlib as plt plt.imshow(img)实现。 3.结果加载网络123456789101112131415161718192021222324import numpy as npimport matplotlib.pyplot as pltcaffe_root='/home/zgf/caffe-master/'import sysimport ossys.path.insert(0, caffe_root + 'python/caffe')import caffeplt.rcParams['figure.figsize'] = (10, 10)plt.rcParams['image.interpolation'] = 'nearest'plt.rcParams['image.cmap'] = 'gray'ref_model_file = caffe_root+'/models/bvlc_reference_caffenet/deploy.prototxt'ref_pretrained = caffe_root+'/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'net = caffe.Classifier(ref_model_file, ref_pretrained, mean=np.load('/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1), channel_swap=(2,1,0), raw_scale=255, image_dims=(256, 256))scores = net.predict([caffe.io.load_image(caffe_root + 'examples/images/cat.jpg')])#显示网络的结构信息[(k, v.data.shape) for k, v in net.blobs.items()] [out]： 123456789101112131415[(&apos;data&apos;, (10, 3, 227, 227)), (&apos;conv1&apos;, (10, 96, 55, 55)), (&apos;pool1&apos;, (10, 96, 27, 27)), (&apos;norm1&apos;, (10, 96, 27, 27)), (&apos;conv2&apos;, (10, 256, 27, 27)), (&apos;pool2&apos;, (10, 256, 13, 13)), (&apos;norm2&apos;, (10, 256, 13, 13)), (&apos;conv3&apos;, (10, 384, 13, 13)), (&apos;conv4&apos;, (10, 384, 13, 13)), (&apos;conv5&apos;, (10, 256, 13, 13)), (&apos;pool5&apos;, (10, 256, 6, 6)), (&apos;fc6&apos;, (10, 4096)), (&apos;fc7&apos;, (10, 4096)), (&apos;fc8&apos;, (10, 1000)), (&apos;prob&apos;, (10, 1000))] 显示参数信息1[(k, v[0].data.shape) for k, v in net.params.items()] [out]：12345678[(&apos;conv1&apos;, (96, 3, 11, 11)), (&apos;conv2&apos;, (256, 48, 5, 5)), (&apos;conv3&apos;, (384, 256, 3, 3)), (&apos;conv4&apos;, (384, 192, 3, 3)), (&apos;conv5&apos;, (256, 192, 3, 3)), (&apos;fc6&apos;, (4096, 9216)), (&apos;fc7&apos;, (4096, 4096)), (&apos;fc8&apos;, (1000, 4096))] 输入层12345678910111213141516171819202122232425%matplotlib inlinedef showimage(im): if im.ndim == 3: m = im[:, :, ::-1] plt.imshow(im)def vis_square(data, padsize=1, padval=0): data -= data.min() data /= data.max() # force the number of filters to be square n = int(np.ceil(np.sqrt(data.shape[0]))) padding = ((0, n ** 2 - data.shape[0]), (0, padsize), (0, padsize)) + ((0, 0),) * (data.ndim - 3) data = np.pad(data, padding, mode='constant', constant_values=(padval, padval)) # 对图像使用滤波器 data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1))) data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:]) showimage(data) #plt.imshow(data)# index four is the center crop# 输出输入的图像image = net.blobs['data'].data[4].copy()image -= image.min()image /= image.max()showimage(image.transpose(1, 2, 0))#plt.imshow(image.transpose(1,2,0)) [out]：第一个卷积层，参数有[weight, biases]对应索引0,1。的96个过滤器：12345filters = net.params['conv1'][0].datavis_square(filters.transpose(0, 2, 3, 1))#96 feature mapfeat = net.blobs['conv1'].data[4, :96]vis_square(feat, padval=1) [out]：第二卷积层的过滤器，每个尺寸5*5*48，显示前48个，机器对应的输出只显示36张。12345filters = net.params['conv2'][0].datavis_square(filters[:48].reshape(48**2, 5, 5))feat = net.blobs['conv2'].data[4, :36]vis_square(feat, padval=1) [out]：接下来的卷积层的提取和输出一样：1234567891011feat = net.blobs['conv3'].data[4]vis_square(feat, padval=0.5)feat = net.blobs['conv4'].data[4]vis_square(feat, padval=0.5)#第5卷积层feat = net.blobs['conv5'].data[4]vis_square(feat, padval=0.2)#池化层feat = net.blobs['pool5'].data[4]vis_square(feat, padval=1) 最后的全连接层fc6和fc7，输出直方图： 1234567891011feat = net.blobs['fc6'].data[4]plt.subplot(2, 1, 1)plt.plot(feat.flat)plt.subplot(2, 1, 2)_ = plt.hist(feat.flat[feat.flat &gt; 0], bins=100)feat = net.blobs['fc7'].data[4]plt.subplot(2, 1, 1)plt.plot(feat.flat)plt.subplot(2, 1, 2)_ = plt.hist(feat.flat[feat.flat &gt; 0], bins=100) 最后的输出层，显示1000类概率的直方图信息： 123feat = net.blobs['prob'].data[4]plt.subplot(2, 1, 1)plt.plot(feat.flat) 显示最后的类别信息top5： 12345678imagenet_labels_filename = caffe_root + 'data/ilsvrc12/synset_words.txt'try: labels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')except: !../data/ilsvrc12/get_ilsvrc_aux.shlabels = np.loadtxt(imagenet_labels_filename, str, delimiter='\\t')top_k = net.blobs['prob'].data[4].flatten().argsort()[-1:-6:-1]print labels[top_k] [out]：12345[&apos;n02123045 tabby, tabby cat&apos; &apos;n02123159 tiger cat&apos; &apos;n02124075 Egyptian cat&apos; &apos;n02119022 red fox, Vulpes vulpes&apos; &apos;n02127052 lynx, catamount&apos;]","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"caffe","slug":"caffe","permalink":"http://abumaster.com/tags/caffe/"}]},{"title":"结合特定任务边缘检测的图像语义分割","date":"2017-04-07T07:38:22.000Z","path":"2017/04/07/结合特定任务边缘检测的图像语义分割/","text":"DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。 主要思想取代最后的全连接条件随机场和与其关联的双向过滤器，变为域变换（DT）一种边缘感知过滤器。域变换的递归公式等于信号的自适应递归滤波，其中信息不允许在某些参考信号中跨越边缘传播。速度快。前期工作 图像语义分割网络中最大池化和下采样的出现，使稠密网络最后的输出图无法精准定位物体的边界信息，为了解决这个问题，出现了很多解决方案：组合中间特征图信息；反卷积和上采样；超像素等底层的分割方法；条件随机场，利用像素之间的依赖关系。 边缘检测学习物体的边界直接优化图像语义分割的表现。 长距离依赖（Long range dependency）通过DT输入进行反向传播，以共同学习端对端可训练系统中的分割图得分和边缘图。提出模型论文中提出的模型图：分为三个部分：1.语义分割预测，得出一个大致的分割图，与全卷积网络输出图类似；2.边缘预测网络，生成一个边缘预测图；3.域转换，使用物体边界限制分割图。 x表示需要过滤的原始信号量，y表示域转换密度信号d。使用递归公式计算，初始化y1=x1，然后递归计算i=2,...,N：$$y_i=(1-w_i)x_i+w_iy_{i-1}$$其中权重wi的计算依赖di：$$w_i=exp(-\\sqrt2d_i/{\\sigma_{s}})$$一维计算树，前向和反向传播的计算：$$\\frac{\\partial L}{\\partial x_i}\\leftarrow (1-w_i)\\frac{\\partial L}{\\partial y_i}$$$$\\frac{\\partial L}{\\partial w_i}\\leftarrow \\frac{\\partial L}{\\partial w_i}+(y_{i-1}-x_i)\\frac{\\partial L}{\\partial y_i}$$$$\\frac{\\partial L}{\\partial y_{i-1}}\\leftarrow \\frac{\\partial L}{\\partial y_{i-1}}+w_i\\frac{\\partial L}{\\partial y_i}$$源码和模型地址。接下来学习。 参考文献[1] “Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform” Liang-Chieh Chen, Jonathan T. Barron, George Papandreou, Kevin Murphy, and Alan L. Yuille In Conference on Computer Vision and Pattern Recognition (CVPR), 2016","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"进制转换","date":"2017-04-06T13:16:07.000Z","path":"2017/04/06/进制转换/","text":"题目描述将任意长度的二进制转换成十进制。要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：数字的n次方、大数相加、大数相乘。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。 解法二进制转换成十进制观察：10001000的计算过程，转换成十进制为：2^7+0+0+0+2^3+0+0+0。因此问题分为两个部分：计算二进制位置上为1时对应的十进制数是多少；对所有的位置得到的数字求和。代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * bin2dec 二进制转换成十进制 * @param decnum 十进制数字串 * @param n 二进制1后面的0的个数 */void bin2dec(int *decnum, int n)&#123; int index = LEN-1; decnum[index] = 1; int jinwei = 0; while (n--) //总共几个0 &#123; for(int i = LEN-1; i&gt;=0; i--) &#123; int nowtemp = 2*decnum[i]+jinwei; if(nowtemp&gt;=10)//需要进位 &#123; decnum[i] = nowtemp%10; //改变当前的数值 jinwei = nowtemp/10; //进位的多少 &#125; else &#123; decnum[i] = nowtemp; jinwei=0; &#125; &#125; &#125;&#125;/** * 将两个大数合并，放入左边数组 * @param left 相加结果放入此 * @param right 数组 */void sumbignum(int *left, int *right, int n=LEN)&#123; int jinwei = 0; for(int i=n-1; i&gt;=0; i--) &#123; int temp = left[i]+right[i]+jinwei;//俩数之和加上进位标志 if(temp &gt;= 10)//需要进位的 &#123; left[i] = temp%10; jinwei = temp/10; &#125; else //不用进位 &#123; left[i] = temp; jinwei = 0; &#125; &#125;&#125; 十进制转换成二进制同理，位数少的十进制转换成二进制一般应用除2求余，然后直到商为0。参考。对于大数，可以保存在一个数组中，用前一位的余数与当前的位数拼成一个数，除以2，商替换原数字对应的位数上，余数更新，直到把数字的位数计算完，算作得出二进制的一位（最后得出的余数）。直到商为0结束。代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#include &lt;iostream&gt;#include &lt;string.h&gt;using namespace std;const int LEN = 100;/** * 检查数组代表的数字是否为空 * @param arr [description] * @param len [description] * @return [description] */bool IsZero(int *arr, int len)&#123; bool ret = true; for(int i=0; i&lt;len; i++) &#123; if(arr[i] != 0) &#123; ret = false; break; &#125; &#125; return ret;&#125;/** * 十进制转换成二进制的核心函数 * @param decnum 十进制保存位置 * @param binnum 二进制字符串 * @param len 十进制长度 */void dec2binCore(int *decnum, int *binnum, int len)&#123; int mod; int index = LEN-1; while(!IsZero(decnum, len))//十进制表示的数字不为0 &#123; mod = 0; for (int i =0; i&lt;len; i++) &#123; int tempnum = 10*mod+decnum[i]; int sang = tempnum/2; mod = tempnum%2; decnum[i] = sang; //更新商 &#125; binnum[index--] = mod;//最后的余数是二进制 &#125;&#125;void PrintInt(int *arr, int n)&#123; int start = 0;//bug for (int i=0; i&lt;n-1; i++) &#123; int j = i+1; if(arr[i]==0 &amp;&amp; arr[j]!=0 &amp;&amp; !start) &#123; start = 1; &#125; if (start) cout &lt;&lt; arr[j]; &#125; cout &lt;&lt; endl;&#125;void testdec2bin()&#123; string strnum; while(cin &gt;&gt; strnum) &#123; int len = strnum.size(); int *decnum = new int[len]; memset(decnum, 0, len*sizeof(int)); for(int i=0; i&lt;len; i++) decnum[i]= strnum[i]-'0'; int *binnum = new int[LEN]; memset(binnum, 0, LEN*sizeof(int)); dec2binCore(decnum, binnum, len); PrintInt(binnum, LEN); &#125;&#125;int main()&#123; testdec2bin(); system(\"pause\"); return 0;&#125; 感悟 看似简单的问题，还要细思量。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"},{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"}]},{"title":"全卷积网络和全连接条件随机场","date":"2017-04-05T07:08:55.000Z","path":"2017/04/05/全卷积网络和全连接条件随机场/","text":"来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015. 主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。 主要创新点：1.带孔卷积在最后两个池化层后，跳过子采样，修改之后的卷积过滤器，变为卷积层。命名为孔算法，解释如图： 高效的特征提取算法，有效的稠密滑动窗口特征提取器 控制接受域大小，加速卷积网络的计算 2.边界恢复问题目前定位物体边界的挑战主要从两个方面： 利用融合不同层特征图的相关信息，估计物体边界 利用超像素表征，将任务委托给低层次的分割任务 模型： $$E(x)=\\sum_i\\theta_i(x_i)+\\sum_{ij}\\theta_{ij}(x_i,x_j)$$有一元项和二元项。3.多尺度预测为了增加边界定位的准确性，用了多尺度预测。具体是，为输入图像和第一个四层最大池化层附加一个双层MLP（第一层：128 个3*3的卷积核，第二层：128个1*1的卷积核）与最后一层的特征图连接。汇总的特征图，放入softmax层，产生5*128=640通道。 系统实现DeepLab：使用深度卷积网络，atrous卷积和全连接crfs的图像语义分割模型。针对传统方法的不足： 减少特征解析度（重复的最大池化和下采样） 存在多个尺度的对象 由于深度网络的稳定性导致定位精度下降提出的优化方案： 不采样 atrous spatial pyramid pooling 空间金字塔池化 结合条件随机场细节atrous卷积的计算，一维信号量示例如图：$$y[i]=\\sum_{k=1}^Kx[i+r\\cdot{k}]w[k]$$全连接条件随机场：关于能量函数，第一项由预测网络给出的预测值；第二项：公式分为两项，第一项是节点值不相等时为1，相等时为0，为了表示不同的标签将要受到惩罚。第二项，有两个高斯核组成，第一个是用像素的位置和像素的值表示，第二个是用像素之间的位置表示，他们是不同空间的特征。","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"Linux配置OpenCV","date":"2017-04-03T08:23:00.000Z","path":"2017/04/03/Linux配置OpenCV/","text":"源码安装OpenCV从OpenCV官网下载，最新版的OpenCV（opencv-3.2.0）。解压文件，得到文件夹（opencv-3.2.0），并进入；进行源码编译： 12345mkdir release cd release cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local .. make sudo make install 配置依赖库安装完成后，编译完成，运行时会出现找不到依赖库的情况如：error while loading shared libraries: libopencv_core.so.2.4: cannot open shared object file: No such file or directory这是因为没有把共享库放在加载器可以找到的位置，解决方法：首先定位到Opencv动态库所在的目录，一般在/usr/local/lib/或者/usr/lib/x86_64-linux-gun/中，在/etc/ld.so.conf.d/目录下创建一个opencv.conf的文件，并把上述的路径写入文件，然后执行sudo ldconfig -v编译1.第一种方式g++ DisplayImage.cpp -o DisplayImage &#39;pkg-config opencv --cflags --libs&#39;在上面的编译命令中我们其实用到了一个工具“pkg-config”，它主要有以下几个功能： 检查库的版本号。如果所需要的库的版本不满足要求，它会打印出错误信息，避免链接错误版本的库文件。 获得编译预处理参数，如宏定义，头文件的位置。 获得链接参数，如库及依赖的其它库的位置，文件名及其它一些连接参数。 自动加入所依赖的其它库的设置 2.cmake工具CMake工具，需要一个CMakeLists.txt文件，然后输入命令cmake .会生成Makefile文件，然后make就行了。CMakeLists.txt文件书写（opencv源码中带的例子example_cmake文件夹）：1234567891011121314151617181920212223242526# CMakeLists.txt# 必须的信息cmake_minimum_required(VERSION 2.8)# 工程的名称project(opencv_example_project)# 查找opencv的包find_package(OpenCV REQUIRED)# 打印库的状态信息message(STATUS &quot;OpenCV library status:&quot;)message(STATUS &quot; version: $&#123;OpenCV_VERSION&#125;&quot;)message(STATUS &quot; libraries: $&#123;OpenCV_LIBS&#125;&quot;)message(STATUS &quot; include path: $&#123;OpenCV_INCLUDE_DIRS&#125;&quot;)if(CMAKE_VERSION VERSION_LESS &quot;2.8.11&quot;) # Add OpenCV headers location to your include paths include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)endif()# 生成的目标以及源文件add_executable(opencv_example example.cpp)# 程序与opencv动态库连接target_link_libraries(opencv_example $&#123;OpenCV_LIBS&#125;)","tags":[{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"}]},{"title":"C++类构造函数","date":"2017-04-02T06:45:54.000Z","path":"2017/04/02/C-类构造函数/","text":"C++中构造函数和析构函数应该注意的问题构造方法用来初始化类的对象，与父类的其它成员不同，它不能被子类继承（子类可以继承父类所有的成员变量和成员方法，但不继承父类的构造方法）。因此，在创建子类对象时，为了初始化从父类继承来的数据成员，系统需要调用其父类的构造方法。C++11新标准中，派生类可以重用其直接基类定义的构造函数，类不能继承默认、拷贝、移动构造函数，如果派生类没有指定，则编译器会自动合成。 构造原则如下： 如果子类没有定义构造方法，则调用父类的无参数的构造方法。 如果子类定义了构造方法，不论是无参数还是带参数，在创建子类的对象的时候,首先执行父类无参数的构造方法，然后执行自己的构造方法。 在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数，则会调用父类的默认无参构造函数。 在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数且父类自己提供了无参构造函数，则会调用父类自己的无参构造函数。 在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数且父类只定义了自己的有参构造函数，则会出错（如果父类只有有参数的构造方法，则子类必须显示调用此带参构造方法）。 如果子类调用父类带参数的构造方法，需要用初始化父类成员对象的方式 析构函数基类的析构函数声明为虚函数，这样销毁对象时子类会调用子类的析构函数，防止内存泄漏。如果没有定义为虚析构函数，销毁一个子类或者父类对象时，都会调用父类析构函数。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"数据结构-红黑二叉树","date":"2017-04-01T04:25:53.000Z","path":"2017/04/01/数据结构-红黑二叉树/","text":"红黑树（Red Black Tree）是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。它是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。红黑树和AVL树（平衡二叉树）类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能，而统计性能要优于AVL树，广泛应用到各种程序库中。 它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n是树中元素的数目。性质红黑树是每个节点都带有黑色或者红色的二叉查找树。具有二叉树的性质，并且具有以下几个性质： 根节点是黑色 叶子节点（空节点）是黑色的 每个红色节点的两个子节点都是黑色的，叶子到根的路径上不能有连续的红色节点 从任一节点开始到其每个叶子节点的所有路径包含相同数目的黑色节点基本操作左旋、右旋、重新着色三个操作。右旋操作类似，左旋就是将旋转的节点变为左子树，提取右节点上来，右旋是将右旋节点变为右子树，提取左节点上来。插入根据规则4，可知新增节点必须为红；根据规则3，新增节点的父节点必须为黑，当未符合条件的时候必须进行一定的调整。假设新的节点 X，其父节点为 P，祖父节点 G，伯父节点 S，曾祖父节点 GG，根据 X 的插入位置以及外围节点的颜色，通常null节点为黑色。分为四种情况讨论： 状况 1：S 为黑且 X 为外侧插入，对此情况，先对 P 和 G 做一次单旋转，并更改 P 和 G 的颜色，可以重新满足红黑树规则。 状况 2：S 为黑色且 X 为内侧插入。必须先对 P，X 做一次单旋转并更改G,X的颜色，再将结果对G做一次单旋转。 状况 3：S 为红且 X 为外侧插入，先对P,G做一次单旋转，并且改变 X 的颜色，此时，如果GG为黑色，一切调整完毕，如果GG为红色，那么继续向上调整… 状况 4：S 为红色且 X 为外侧插入，这种情况，先对P,G 做一次单旋转并且改变 X 的颜色。此时 GG 为红色，则继续往上做，直到父子不连续为红。自上而下的程序设计 为了避免状况4的出现。top down procedure : 假设新增一个节点为 A，那么就沿着 A 的路径，只要发现某个节点 X 的两个孩子都是红色，就把 X 改为红色，并把两个孩子的颜色改为黑色。这样调整可能 X 的父节点 P 也是红色，可以像状况 1 一样做一次单旋转并改变颜色，或者像状况2 一样做一次双旋转并改变颜色。再一次插入新的节点就容易了。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"动态规划-背包问题","date":"2017-03-31T00:41:50.000Z","path":"2017/03/31/动态规划-背包问题/","text":"题目描述有 a，b，c 三个物体，重量记为 W 5，4，3价值记为 V 20 10 12有一个背包容量 C = 10 ，问：可以装的最大价值为多少？ 解决动态规划问题的主要方法是找到状态转移方程，动态规划全局最优包含了局部最优解。分析上述问题：背包容量10，首先，第一个物品有装入和不装入两种情况，转入的话状态变为：容量5，物品重量4,3物品价值10,12；不装入则变为：容量10，物品质量4,3，价值10,12。因此可以定义：dp[i][j]表示前i个物品装到剩余容量为j的背包中的价值 dp[3][10]即为所求的结果，有了状态，这个状态是如何转移的呢？由上面的分析，可知，第i个物品有装入和不装入两种情况，因此状态转移方程可以表示如下：dp[i][j] = Max(dp[i-1][j], dp[i-1][j-w[i]]+v[i])。容易写出代码：123456789for(int i=0; i&lt;n; i++)&#123; for(int j=0; j&lt;=C; j++) &#123; dp[i][j] = (i==0?0:dp[i-1][j]); if(i&gt;0 &amp;&amp; j&gt;=W[i]) dp[i][j] = Max(dp[i-1][j], dp[i-1][j-w[i]]+v[i]); &#125;&#125; 关于优化空间复杂度上述存储状态方程为二维数组，可以压缩为一维数组，dp[i][j]变为dp[j]避免了重复的计算。123456789memeset(dp, 0, sizeof(dp));for(int i=0; i&lt;n; i++)&#123; for(int j=C; j&gt;=0; j++) &#123; if(i&gt;0 &amp;&amp; j&gt;=W[i]) dp[j] = Max(dp[j], dp[j-W[i]]+V[i]); &#125;&#125; [网易2017实习笔试题-双核处理]题目描述：一种双核CPU的两个核能够同时的处理任务，现在有n个已知数据量的任务需要交给CPU处理，假设已知CPU的每个核1秒可以处理1kb，每个核同时只能处理一项任务。n个任务可以按照任意顺序放入CPU进行处理，现在需要设计一个方案让CPU处理完这批任务所需的时间最少，求这个最小的时间。输入描述： 输入包括两行： 第一行为整数n(1 ≤ n ≤ 50) 第二行为n个整数lengthi，表示每个任务的长度为length[i]kb，每个数均为1024的倍数。 输出描述： 输出一个整数，表示最少需要处理的时间 输入输出例子： 53072 3072 7168 3072 10249216 解题思路:双核可以同时运行，故可以把任务分成两组，交由两个核顺序执行，最短执行时间取决于最后一个执行完成的时间，因此，两个数组长度相差越小，执行的时间也是越短的，换句话说，使其中一个数组无限接近输入数据总长度的一半sum/2即可。执行的时间为sum-sum/2。可以变为简单的背包问题：背包容量sum/2，物体重量为输入数据的长度，尽可能装满背包。状态转移方程可以记为：dp[i][j] = max(dp[i-1][j], dp[i-1][j-w[i]]+w[i]), dp[i][j]表示前i个物品在体积为j时可以填充的重量。 同样可以压缩数组变为一维，如上。 代码：123456789101112131415161718192021#include &lt;iostream&gt; using namespace std; int dp[210000]; int n,arr[51]; int main() &#123; int n; scanf(\"%d\",&amp;n); int sum = 0; for(int i = 0 ; i &lt; n ; i ++)&#123; scanf(\"%d\",&amp;arr[i]); arr[i] /= 1024; sum += arr[i]; &#125; memset(dp, 0, sizeof(dp)); for(int i = 0 ; i &lt; n ; i ++) for(int j = sum/2 ; j &gt;= arr[i] ; --j) dp[j] = max(dp[j],dp[j-arr[i]]+arr[i]); printf(\"%d\\n\",(sum-dp[sum/2])*1024); return 0; &#125;","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]},{"title":"深度解析网络用于图像语义分割","date":"2017-03-30T02:20:52.000Z","path":"2017/03/30/深度解析网络用于图像语义分割/","text":"2015 年 ICCV 论文：Semantic Image Segmentation via Deep Parsing Network [1]，针对图像语义分割将丰富信息（上下文关系）并入马尔科夫随机场（MRF），取代用迭代法去优化 MRFs 提出了一种卷积网络，被称为深度解析网络（DPN），可以通过一次前向传递决定端对端的计算。 $$E(y)=\\sum_{\\forall{i}\\in \\upsilon}\\Phi({y_i^u})+\\sum_{\\forall{i,j}\\in\\varepsilon}\\Psi(y_i^u,y_j^v)$$ 主要贡献：使用DPN交叉训练VGG16网络，通过一次迭代近似MF，减少计算量并且保证性能。MRF对于一副图片，看成一个无向图。边代表像素之间的联系，顶点是一个二值隐变量可以看成像素i是否分到标签u。如公式所示：能量函数可以写为：\\y ,\\upsilon ,\\varepsilon\\分别代表了潜变量、顶点和边。上述能量函数分为一元项和二元项，很明显，一元项是一个预测值，表示预测像素是某一个标签，二元项则是代表一组平滑约束。$$\\Phi{(y_i^u)}=-\\ln{p\\left(y_i^u=1|I\\right)}$$像素i用标签u表示的可能性。对于二元项是距离和共存性的乘积决定的。不可能共存，则值很大。如果两个像素临近并且相似，那么将会被鼓励分配相同的标签。这种衡量方法有两个主要的缺点：1.第一项是从训练数据中获得两个标签同时发生的频率来衡量，忽略了两个标签的空间上下文信息，比如人可以出现在桌子旁边，但是不太可能在桌子下面或者上面。空间上下文是一个混合模式，不同物体的形态可能出现在不同的图片中。2.只在像素间定义了成对的关系，没有考虑到高阶的相互作用。不理解，先放着。","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"公式专辑","date":"2017-03-29T07:53:21.000Z","path":"2017/03/29/公式专辑/","text":"公式的使用，论文中经常用到公式，在本地编写文章时常有 word 自带的基本上可以解决问题，当用 Markdown 书写时，又不想贴图，只好用在线的公式编辑器，一般有两种方法，一是在线生成公式，并引出外链，直接嵌入到文章中；另外一种用Mathjax引擎，引入一个脚本，在文章中编辑。 1.MathJax 引擎参考stackexchange，很简单引入一个脚本：1&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt; 然后编写公式一个栗子：1$$\\sum_&#123;i=0&#125;^n i^2 = \\frac&#123;(n^2+n)(2n+1)&#125;&#123;6&#125;$$ 就生成了：$$\\sum_{i=0}^n i^2 = \\frac{(n^2+n)(2n+1)}{6}$$注意：想要在浏览器上预览，需要更改markdown priview的配置文件，运行mathjax运行。 2.在线 LaTeX 公式编辑器在线LaTeX公式编辑器，使用LaTeX公式。在其中编写好公式后，直接生成了一段html代码，直接复制到 Markdown 文本中。如代码:1&lt;a href=&quot;https://www.codecogs.com/eqnedit.php?latex=$$f(x)=\\sum_&#123;i=1&#125;^n&amp;space;a_i$$&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://latex.codecogs.com/gif.latex?$$f(x)=\\sum_&#123;i=1&#125;^n&amp;space;a_i$$&quot; title=&quot;$$f(x)=\\sum_&#123;i=1&#125;^n a_i$$&quot; /&gt;&lt;/a&gt; 生成：优点：可以本地预览；缺点：只是引用的图片，右键不可操作，公式大的话可能加载慢，图片不清晰。 3.基本语法 无论使用哪种方式，公式的基本语法是相同的。常用的总结如下。 公式样式行内公式\\\\(公式\\\\)，行间公式$$公式$$**空格的表示：`\\quad’表示一个quad空格 字符\\为转义符，特殊字符前要加。 上下标用^表示上标，用_表示下标 字母上下标记用\\overline{}表示上划线，用\\underline{}表示下划线；用\\hat{}表示字母上面有一个小尖角，而\\widehat{}表示有一个大尖角; 用\\bar{} \\acute{} \\check{} \\grave{}分别表示四个声调：一声平，二声扬，三声拐弯，四声降；\\tilde{}波浪线, \\vec{}向量,\\dot{}点。 希腊字符\\alpha, \\beta, …, \\omega: α,β,…ω；\\Gamma, \\Delta, …, \\Omega: Γ,Δ,…,Ω。 数学函数例如sin x要表示成\\sin x；log x要表示成\\log x；lim x表示成\\lim_{x\\to0}。 分数开方\\frac{ }{ }分数；\\sqrt{n}{r}表示开n次方。 括号和分割符() [] |是不变的； {}要转义，写为\\{\\}用\\left 和 \\right调整大小。 数学公式求和：\\sum_{i=0}^n{a_i}积分：\\int例子参见stackexchange","tags":[{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"}]},{"title":"图床测试","date":"2017-03-29T06:20:44.000Z","path":"2017/03/29/图床测试/","text":"图床一般是专门用来存储图片的服务器，同时向外提供链接。国内和国外之分，本次测试的是极简图床。优点：不必把图片上传到博客服务器，节省服务器的空间。缺点：不能上传大于5M的图片，稳定性待测。 来一波从wallhaven下载的图片","tags":[{"name":"技巧","slug":"jq","permalink":"http://abumaster.com/tags/jq/"}]},{"title":"Feedforward semantic segmentation with zoom-out features","date":"2017-03-27T06:21:29.000Z","path":"2017/03/27/Feedforward-semantic-segmentation-with-zoom-out-features/","text":"使用缩小特征的前馈语义分割 Feedforward semantic segmentation with zoom-out features 2015年CVPR论文，在PASCAL VOC 2012测试集上达到了69.9%的正确率。将小的图像元素（超像素）映射到丰富的特征表示中，这些特征是从嵌套的增加区域中获得。这些区域通过从超像素一直缩小到场景级别的分辨率获得。这种方法充分利用了图像和隐藏空间中的统计结构，而不显式设置结构化预测机制，从而避免了复杂、昂贵的推论。从而超像素是由多层前馈网络进行分类。 从大量的现代分割著作中，得到了一种被广泛接受的知识，分割可以看成一个结构化预测的任务，可以用条件随机场和结构化支持向量机模型。作者脱离传统，提出图像语义分割看作单阶段的分类任务，其中每个像素元素（超像素）被标记为一个标签，使用一个前馈模型，依据从图像计算的证据。用在前馈分类中的证据不是从孤立的局部区域中获得，而是从序列中获得，序列是怎么组成的呢？首先得到一个超像素，再向外扩展，获得一个更大的闭合区域，直到扩展到整张图片。计算每一个层次的丰富特征，结合所有特征，放入分类网络中。 ###缩小的特征融合将图像的类别分割转换成对一组超像素分类。由于我们期望为每个超级像素应用相同的分类机，我们希望超像素的性质是相似的，特别是它们的大小。使用了SLIC。本地超像素本身有很窄的范围，我们希望特征提取器可以捕获更多的本地信息：颜色，上下文，其他一些属性，在临近的超像素之间这些属性有很大的不同。近似距离场景","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"全卷积网络用于图像语义分割","date":"2017-03-25T07:31:02.000Z","path":"2017/03/25/全卷积网络用于图像语义分割/","text":"全卷积网络用于图像语义分割 (Fully Convolutional Networks for Semantic Segmentation)[1] 全卷积网络实际上就是把普通卷积网络的最后的全连接层变为卷积层，因为全连接层会把空间信息隐藏，全部展开为一维向量，换为卷积可以保留空间信息。如VGG-16网络在处理ImageNet数据集时，最后的1000个输出，是1000维向量，来表示1000类事物的概率，当换为卷积层时，输出了1000个1*1大小的输出，对此上采样，可以输出对应的heat-map。这是分类网络作为稠密输出的关键。 文章解决的问题是如何生成稠密的预测即dense prediction Shift-and-stitch假设原图和FCN输出图之间的降采样因子f，对于原图的每个f*f区域，对于0 &lt;= x,y &lt;f处理这 f2 个输入，并且交替输出，使得预测在接受域的中心像素。每个像素对应一个中心像素，因此为稠密输出。缺点：感受野没变，但是原图被划分为了f*f大小的图像片作为输入图像，使得网络无法感受更加精细的信息。 稀疏过滤器调整下采样过程中的步长，变为1，可以保证下采样不会损失图像的大小。缺点：下采样的功能被减弱，同时保留了更多信息，接受域相对变小，可能损失全局信息，同样为卷积层带来了更多的运算。 上采样上采样（Upsampling）也称反卷积（Deconvolution），参数和卷积一样可以在训练中学习。运算也和卷积类似，为逆过程。设输入大小w0*h0，经过卷积后的大小为w1*h1，计算公式如下：卷积运算：w1 = (w0 + 2*pad - kernelsize)/stride + 1h1 = (h0 + 2*pad - kernelsize)/stride + 1反卷积运算：w0 = (w1 - 1)*stride + kernelsize - 2*padh0 = (h1 - 1)*stride + kernelsize - 2*pad经过上采样后的图像可能会比原图大，需要裁剪为原图像大小，caffe中的crop层，提供了很好的算法。 语义分割的框架结构文中提出的框架结构如图所示：作者发现32倍率的上采样导致输出图非常粗糙，因此想出了利用上层的一些特征来优化输出图像，就有了FCN-16s和FCN-8s的方案，其主要思想是利用上层的池化层的信息，减少上采样的倍率，保留了更多的特征。 具体的实践针对传统网络的全连接层变为卷积层，如VGG-16网络中第一个卷积层是25088*4096，将之解释为512*7*7*4096。产生端对端的训练模型。在论文提供的源码中，FCN-32s的配置文件，第一个卷积层为： layer { name: &quot;conv1_1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; top: &quot;conv1_1&quot; param { lr_mult: 1 decay_mult: 1 } param { lr_mult: 2 decay_mult: 0 } convolution_param { num_output: 64 pad: 100 #填充100 kernel_size: 3 stride: 1 } } 填充100的原因为：在VGG-16网络中卷积的参数，kernersize=3，stride=1，pad=1，所以卷积层不会改变图像的大小，所以图像只有在池化层改变大小，且变为原大小的一半。为了方便将图像看为一维的，设原图像大小h，经过了5层池化后，图像缩小了32倍，变为h5 = h/32，紧接着全连接层，可以看成是卷积层，卷积参数为：kernelsize=7 pad=0 stride=1，根据卷积计算公式，经过卷积层fc6后的输出图像大小为h6 = (h5-7)/1 + 1 = (h-192)/32 因此，图像小于192的就无法往下计算了，所以要pad=100，解决了网络输入图像固定大小的弊端，全卷积网络可以输入任意大小的图像。 例子根据FCN-32s的配置文件如果输入图像大小为3*320*320经过了卷积conv1的输出为：64*518*518经过了池化pool1的输出为：64*259*259经过了卷积conv2的输出为：128*259*259经过了池化pool2的输出为：128*130*130经过了卷积conv3的输出为：256*130*130经过了池化pool3的输出为：256*65*65经过了卷积conv4的输出为：512*65*65进过了池化pool4的输出为：512*32*32 经过了卷积conv5的输出为：512*32*32经过了池化pool5的输出为：512*16*16经过了fc6的卷积后输出为：4096*10*10经过了fc7的卷积后输出为：4096*10*10经过score_fr的卷积输出：21*10*10上采样（反卷积）输出为：21*352*352score层裁剪后输出为：21*320*320","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"卷积网络应该注意的问题","date":"2017-03-24T06:28:18.000Z","path":"2017/03/24/卷积网络应该注意的问题/","text":"卷积神经网络简介，由于其出色的特征提取特性，使得在计算机视觉方面有了很好的应用，并取得了出色的成绩。卷积卷积操作是卷积网络中的核心操作，其主要目的是为了提取图像的显著特征，降低特征维数，进而来减少计算量。在 caffe 代码中的主要参数如下： 123456789101112131415161718192021222324252627layer &#123; name: &quot;conv1&quot; type: &quot;Convolution&quot; bottom: &quot;data&quot; #上层是数据层 top: &quot;conv1&quot; param &#123; #权重学习参数 lr_mult: 1 #权重学习率 需要乘以基础学习率base\\_lr decay_mult: 1 &#125; param &#123; #偏置学习参数 lr_mult: 2 decay_mult: 0 &#125; convolution_param &#123; #卷积参数 num_output: 96 #卷积操作后的输出特征图 kernel_size: 11 #卷积核大小 stride: 4 #步长 #可能也有pad为扩充边缘 weight_filler &#123; #权值初始化 type: &quot;gaussian&quot; #类型为weight-filter 或xavier算法等，默认constant，全部0 std: 0.01 &#125; bias_filler &#123; #偏置的初始化 type: &quot;constant&quot; value: 0 &#125; &#125;&#125; 输入：n*c0*w0*h0输出：n*c1*w1*h2c1对应num_output，输出对应的大小计算:w1 = (w0 + 2*pad - kernersize)/stride + 1h1 = (h0 + 2*pad - kernelsize)/stride + 1在 caffe 源码中的计算是将图像和卷积核通过 im2col 转换成矩阵，再对两矩阵内积。 池化池化也称下采样，为了减少运算和数据维度的一种方式，被分为： 最大池化（Max Pooling），取最大值； 均值池化（Mean Pooling），取均值； 高斯池化。caffe 中的配置代码： 1234567891011layer &#123; name: &quot;pool1&quot; type: &quot;Pooling&quot; bottom: &quot;norm1&quot; top: &quot;pool1&quot; pooling_param &#123; #池化参数 pool: MAX #池化类型 kernel_size: 3 #池化核大小 stride: 2 #步长，重叠 &#125;&#125; 池化的计算公式与卷积操作类似：输入：n*c0*w0*h0输出：n*c1*w1*h2c1对应num_output，输出对应的大小计算:w1 = (w0 + 2*pad - kernersize)/stride + 1h1 = (h0 + 2*pad - kernelsize)/stride + 1 LRN层LRN全称为Local Response Normalization，即局部响应归一化层，没什么用，有一些网络中加入了这一层，对局部区域进行归一化，配置信息和参数说明如下：123456789101112layer &#123; name: &quot;norm1&quot; type: &quot;LRN&quot; bottom: &quot;conv1&quot; top: &quot;norm1&quot; lrn_param &#123; #参数 local_size: 5 #（1）通道间归一化时表示求和的通道数； #（2）通道内归一化时表示求和区间的边长； alpha: 0.0001 #缩放因子 beta: 0.75 #指数项 &#125;&#125; 激活函数 激活函数需要具有以下特性： 非线性； 单调、连续可微分； 范围不饱和，避免梯度为0； 原点近似线性。常用的激活函数有：Sigmoid 函数、Tanh 函数、ReLU 函数等。如 AlexNet 中用到的ReLU激活函数：$$f(x)=max(0,x)$$这种激活函数的特点是：无梯度损耗，收敛速度快，网络稀疏性大，计算量小。缺点是，梯度大的话，导致权重更新以后变大，输出0，使得神经元不再更新。因此要注意学习率的设置。 全连接层全连接层又称内积层（Inner-Product），是将特征图像全部展开为一维向量。caffe 中的文档显示： Inputn * c_i * h_i * w_i Outputn * c_o * 1 * 1这里引用了dupuleng的例子。lenet 网络配置文件中的一段： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647layers &#123; name: &quot;conv2&quot; type: CONVOLUTION bottom: &quot;pool1&quot; top: &quot;conv2&quot; blobs_lr: 1 blobs_lr: 2 convolution_param &#123; num_output: 50 kernel_size: 5 stride: 1 weight_filler &#123; type: &quot;xavier&quot; &#125; bias_filler &#123; type: &quot;constant&quot; &#125; &#125;&#125;layers &#123; name: &quot;pool2&quot; type: POOLING bottom: &quot;conv2&quot; top: &quot;pool2&quot; pooling_param &#123; pool: MAX kernel_size: 2 stride: 2 &#125;&#125;layers &#123; name: &quot;ip1&quot; type: INNER_PRODUCT bottom: &quot;pool2&quot; top: &quot;ip1&quot; blobs_lr: 1 blobs_lr: 2 inner\\_product\\_param &#123; num_output: 500 weight_filler &#123; type: &quot;xavier&quot; &#125; bias_filler &#123; type: &quot;constant&quot; &#125; &#125;&#125; conv2 的输入图像是256*27*27经过了卷积操作，输出50*22*22同样作为了pool2的输入，进行池化，pool2的输出50*11*11，下一层全连接层，输出500*1*1的向量，是如何进行计算的呢？要把所有通道全部展开做卷积，首先要把pool2输出的特征图展开为一维向量，共需要500*50*11*11个参数，进行卷积，输出500*1*1的一维向量。","tags":[{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"},{"name":"caffe","slug":"caffe","permalink":"http://abumaster.com/tags/caffe/"}]},{"title":"Conditional Random Fields as Recurrent Neural Networks","date":"2017-03-21T08:00:18.000Z","path":"2017/03/21/CRFs-as-RNN/","text":"2015 年 ICCV 会议文章 Conditional Random Fields as Recurrent Neural Networks[1] 的阅读笔记。 关键词图像语义分割CRF as RNN摘要像素级别的标注任务，例如图像语义分割在图像理解方面占据着重要的作用。最近的方法开始利用深度学习技术在图像识别任务上的能力来解决像素级别的标注任务。现在的核心问题是深度学习方法在描绘可视化物体具有限制性。为了解决这个问题，我们提出了一个新形式的卷积网络，它结合了卷积网络的优势和条件随机场的概率图模型。为此，我们制定了使用高斯对模型和中值近似的条件随机场作为循环神经网络。这个网路就是 CRF-RNN 被嵌入到 CNN 中，最为一个集 CNNs 和 CRFs 优点于一体的深度网络。更重要的是，我们的系统完全在 CNNs 中集成了 CRF 模型，让使用传统的反向传播算法训练端对端的系统成为了可能，不需要额外的后期处理物体的边界。MarkDown 中使用公式 加入脚本定义，现在用到的是 MathJax 引擎12&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt; 使用Tex公式 $$行间公式；\\\\行内公式，参考MathJax basic tutorial and quick reference 示例$$x=\\frac{-b\\pm\\sqrt{b^2-4ac}}{2a}$$ 引言低层次计算机视觉问题，为图像中的像素分配标签。特征表示在个体像素分类中占有重要的作用。同样要考虑到图像的边界和特征、空间关系，以此来获得较为准确地分割结果。设计出一个强大的特征表示器是像素级别标记的关键挑战。传统的方法不再讨论，现在深度学习的方法利用大尺度的卷积网络，在高层次视觉上取得了非常大的成果。这激励着利用卷积网络去解决低层次的问题。主要利用卷积网络提取特征替代以前的手工标注特征。将用于高层视觉的分类网络转换成低层次视觉的任务依然存在着一些问题提出了几个问题： 传统的卷积网络有大接受域的卷积过滤器，会产生比较粗糙的输出图。最大池化层的出现，过滤掉一些特征，导致了输出的分割图不够精细。 缺少了平滑度约束，没有考虑到相似的像素，空间或者外形相似的约束，导致了输出图的边界不明确，或者出现杂散区域。尤其是马尔科夫随机场（MRFs）和它的变体条件随机场（CRFs）已经成为应用到计算机视觉领域中一个成功的模型。用于像素标记的CRFs推理主要的思想是将语义标签分配问题转换成概率推理问题，包括了相似像素之间一致性并入假设。CRFs可以微调分割图的细节，优化边界问题，克服了单纯利用CNNs的缺点。用CRFs作为后期的处理，无法发挥出CRF的优势，卷积网络在训练的阶段也无法根据CRF的表现来调整权重。本文将CNN与CRF结合为一个统一的框架，可以共同训练。相关工作许多方法用深度学习来解决图像语义分割问题，可以归为以下两个类别： 特征提取和分割分离开的策略。使用CNN提取有意义的图像特征，利用超像素去构造图像的模式。首先从图像中获得超像素，再用特征提取器提取特征。存在着一个致命的缺点，前期如果有误差，后面误差越来越大。与他们的方案不同，此文用典型的图模型CRF可以被作为RNN，指定为深度网络的一部分。结合CNN实现端对端的训练。 直接学习从原始图像到标记图像的非线性模型。例如FCN等网络，去掉了最后的全连接层变为卷积层。全连接条件随机场 条件随机场进行图像语义分割的能量函数：定义隐变量Xi为像素点i的分类标签，取值范围为分类语义标签L={l1,l2,l3,…,ln}；Yi为每个随机变量Xi的观测值，即是每个像素的颜色值。条件随机场的目标就是通过观测变量Yi，推理出潜变量Xi的标签。对于一张图像，可以看成图模型G=(V,E)，每个顶点对应了V={X1,X2,...,Xn}，对于边来说，全连接的条件随机场，顶点与所有的点都有连线。条件随机场的目标函数：能量函数有一元势函数和二元势函数，分别表示了当像素点i的观测值是yi时，该像素点属于标签xi的概率。可以直接从cnn中计算出。二元是函数是两个像素值相似或者相邻则两个像素属于同一类的概率很大。实现 参考文献[1] Zheng S, Jayasumana S, Romera-Paredes B, et al. Conditional random fields as recurrent neural networks[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 1529-1537.","tags":[{"name":"论文","slug":"lunwen","permalink":"http://abumaster.com/tags/lunwen/"},{"name":"深度学习","slug":"deeplearn","permalink":"http://abumaster.com/tags/deeplearn/"}]},{"title":"柔性数组","date":"2017-03-12T13:59:48.000Z","path":"2017/03/12/柔性数组/","text":"C/C++中的0长数组 定义：柔性数组（Flexible Array）也叫伸缩性数组、变长数组。 作用 ：放入结构体中，可以存放动态长度的字符串、数组等。 用法举例： 放在结构体的最后，长度为0的数组。长度为0不占用任何空间，数组名只是一个符号，代表了一个不可改变的地址。 1234struct package &#123; int len; char data[0];&#125;; 用途：根据变长数组的特性很容易构造出一些数据结构，缓冲区、数据包等。不会浪费多余的空间，用多少申请多少。 使用: 假设用上面的结构来发送1024字节大小的数据包，首先要构造一个数据包：1234char *pMsg = (char *)malloc(sizeof(package)+1024); package *pPack = (package*)pMsg;pPack-&gt;len = 1024;memcpy(pPack-&gt;data, source, 1024); 强制类型转换，将package类型的指针指向了申请的内存的开始，分为两个部分：前一部分表示字符串的长度，后一部分表示实际的内容。将整个数据包发出去，不会浪费一点额外的空间，在网络中传输节省了流量，提升了速度。","tags":[{"name":"C++","slug":"C","permalink":"http://abumaster.com/tags/C/"}]}]