<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张国丰</title>
  <subtitle>张国丰的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://abumaster.com/"/>
  <updated>2017-04-18T13:20:27.571Z</updated>
  <id>http://abumaster.com/</id>
  
  <author>
    <name>abumaster</name>
    <email>1902819397@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Caffe的C++接口调用</title>
    <link href="http://abumaster.com/2017/04/18/Caffe%E7%9A%84C-%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"/>
    <id>http://abumaster.com/2017/04/18/Caffe的C-接口调用/</id>
    <published>2017-04-18T12:25:06.000Z</published>
    <updated>2017-04-18T13:20:27.571Z</updated>
    
    <content type="html"><![CDATA[<p>Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。<br><a id="more"></a></p>
<h2 id="1-配置第三方库"><a href="#1-配置第三方库" class="headerlink" title="1.配置第三方库"></a>1.配置第三方库</h2><p>Windows上运行的是官方的 Caffe-Windows 项目，第三方库是从别人打包好的下载，主要分为几大类：boost、gflags、glog、hdf5、LevelDB、lmdb、OpenBLAS、OpenCV、protobuf。配置内容包括（调试器最好配置Release版本的x64平台）：<br><strong>头文件</strong><br>新建一个工程，打开项目-&gt;工程属性页，C/C++ -&gt; 常规 -&gt; 附加包含目录，添加caffe相关的头文件,caffe及第三方依赖库，我的如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">D:\caffeDev\caffe-master\include;D:\caffeDev\NugetPackages\boost.1.59.0.0\lib\native\include;D:\caffeDev\NugetPackages\OpenCV.2.4.10\build\native\include;D:\caffeDev\NugetPackages\gflags.2.1.2.1\build\native\include;D:\caffeDev\NugetPackages\glog.0.3.3.0\build\native\include;D:\caffeDev\NugetPackages\hdf5-v120-complete.1.8.15.2\lib\native\include;D:\caffeDev\NugetPackages\lmdb-v120-clean.0.9.14.0\lib\native\include;D:\caffeDev\NugetPackages\protobuf-v120.2.6.1\build\native\include;D:\caffeDev\NugetPackages\OpenBLAS.0.2.14.1\lib\native\include;</div></pre></td></tr></table></figure></p>
<p><strong>附加库目录</strong><br>链接器 -&gt; 常规 -&gt; 附加库目录 ，添加内容为lib库所在的目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;AdditionalLibraryDirectories&gt;D:\caffeDev\NugetPackages\glog.0.3.3.0\build\native\lib\x64\v120\Release\dynamic;D:\caffeDev\caffe-master\Build\x64\Release;D:\caffeDev\NugetPackages\OpenCV.2.4.10\build\native\lib\x64\v120\Release;D:\caffeDev\NugetPackages\boost_date_time-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_filesystem-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_system-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\protobuf-v120.2.6.1\build\native\lib\x64\v120\Release;D:\caffeDev\NugetPackages\boost_thread-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_chrono-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\hdf5-v120-complete.1.8.15.2\lib\native\lib\x64;D:\caffeDev\NugetPackages\gflags.2.1.2.1\build\native\x64\v120\dynamic\Lib;D:\caffeDev\NugetPackages\OpenBLAS.0.2.14.1\lib\native\lib\x64;%(AdditionalLibraryDirectories)&lt;/AdditionalLibraryDirectories&gt;</div></pre></td></tr></table></figure></p>
<p><strong>依赖项</strong><br>输入 -&gt; 附加依赖项，中填写需要的链接库，为上述目录中的链接库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;AdditionalDependencies&gt;</div><div class="line">opencv_calib3d2410.lib;</div><div class="line">opencv_contrib2410.lib;</div><div class="line">opencv_core2410.lib;</div><div class="line">opencv_features2d2410.lib;</div><div class="line">opencv_flann2410.lib;</div><div class="line">opencv_gpu2410.lib;</div><div class="line">opencv_highgui2410.lib;</div><div class="line">opencv_imgproc2410.lib;</div><div class="line">opencv_legacy2410.lib;</div><div class="line">opencv_ml2410.lib;</div><div class="line">opencv_nonfree2410.lib;</div><div class="line">opencv_objdetect2410.lib;</div><div class="line">opencv_ocl2410.lib;</div><div class="line">opencv_photo2410.lib;</div><div class="line">opencv_stitching2410.lib;</div><div class="line">opencv_superres2410.lib;</div><div class="line">opencv_ts2410.lib;</div><div class="line">opencv_video2410.lib;</div><div class="line">opencv_videostab2410.lib;</div><div class="line">libglog.lib;</div><div class="line">caffe.lib;</div><div class="line">libprotobuf.lib;</div><div class="line">libcaffe.lib;</div><div class="line">gflags.lib;</div><div class="line">gflags_nothreads.lib;</div><div class="line">hdf5.lib;</div><div class="line">hdf5_cpp.lib;</div><div class="line">hdf5_f90cstub.lib;</div><div class="line">hdf5_fortran.lib;</div><div class="line">hdf5_hl.lib;</div><div class="line">hdf5_hl_cpp.lib;</div><div class="line">hdf5_hl_f90cstub.lib;</div><div class="line">hdf5_hl_fortran.lib;</div><div class="line">hdf5_tools.lib;</div><div class="line">szip.lib;</div><div class="line">zlib.lib;</div><div class="line">libopenblas.dll.a;</div><div class="line">%(AdditionalDependencies)</div><div class="line">&lt;/AdditionalDependencies&gt;</div></pre></td></tr></table></figure></p>
<h2 id="2-运行时问题"><a href="#2-运行时问题" class="headerlink" title="2.运行时问题"></a>2.运行时问题</h2><p>实际新建一个项目（从caffe工程中拷的源码，配置好一切环境），可以编译成功，但是运行时出现问题：<br><strong>F0519 14:54:12.494139 14504 layer_factory.hpp:77] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Input (known types: Input )</strong><br>一者说，只有在caffe解决方案中新建项目，才可以正常运行<a href="https://github.com/Microsoft/caffe/issues/45">问题</a>。还有利用别人改进的caffe来减少外部的依赖关系，<a href="https://github.com/dtmoodie/caffe">dtmoodie</a>。<br>另外一种，<a href="http://blog.csdn.net/fangjin_kl/article/details/50936952#0-tsina-1-63793-397232819ff9a47a7b7e80a40613cfe1">解决方法</a>主要解决方案是将caffe中的各层都放进一个头文件中包含进工程中，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/common.hpp"</span>  </span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/input_layer.hpp"</span></span></div><div class="line"><span class="function"><span class="keyword">extern</span> <span class="title">INSTANTIATE_CLASS</span><span class="params">(InputLayer)</span></span>;<span class="comment">//添加层信息</span></div><div class="line">REGISTER_LAYER_CLASS(Input);<span class="comment">//注册层信息</span></div></pre></td></tr></table></figure></p>
<p>可以完美运行了。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>高效分片训练结构化模型用于图像语义分割</title>
    <link href="http://abumaster.com/2017/04/17/%E9%AB%98%E6%95%88%E5%88%86%E7%89%87%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%84%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/17/高效分片训练结构化模型用于图像语义分割/</id>
    <published>2017-04-17T08:58:15.000Z</published>
    <updated>2017-04-18T02:13:45.979Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic<br>Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。  </p>
</blockquote>
<a id="more"></a>
<p><strong>特点：</strong>  </p>
<ol>
<li>制定了基于CNN的在CRFs上总体分段潜在函数模型用于衡量语义图像片之间的关系；  </li>
<li>分段训练CRFs，避免重复推导，提高速度；  </li>
<li>多尺度图像输入，用于探索图像背景和前景上下文信息；  </li>
</ol>
<hr>
<p><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/28980161-file_1492432013053_14485.png" alt=""><br>Featmap-Net是一个卷积网络，用于输出特征图，低分辨率的特征图；<br>创建CRF图，首先对于卷积网络生成的特征图，创建一些边界框，在边界框内被认为空间近似，顶点才会全连接，不同空间会创建不同的边界框。  </p>
<p><strong>上下文深度CRFs</strong><br>分为一元组的图的顶点和二元组的图的边，分别对应一个能量函数，通过一元和二元网络对应生成了类别的预测。<br><strong>利用背景上下文</strong><br>产生特征图的网络：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-18/67947492-file_1492479486028_4096.png" alt=""></p>
<p>首先将输入图像缩放为三个不同的大小，放入网络，共享权重。图像缩放大小为1.2,0.8,0.4，再经过一层独立的卷积产生多尺度特征图，然后经过滑动金字塔池化产生了组合的特征图，金字塔池化如下图所示：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-18/81267394-file_1492479935056_11ffe.png" alt=""><br>使用双线性上采样和简单的边界优化对粗糙的预测结果进行后期处理，可能又更复杂的优化方式，比如：训练反卷积网络，训练复杂的从粗糙到精细的网络，利用中间特征图到高分辨率的预测。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic&lt;br&gt;Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>拉普拉斯重建和细化用于图像语义分割</title>
    <link href="http://abumaster.com/2017/04/16/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%8D%E5%BB%BA%E5%92%8C%E7%BB%86%E5%8C%96%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/16/拉普拉斯重建和细化用于图像语义分割/</id>
    <published>2017-04-16T08:05:56.000Z</published>
    <updated>2017-04-17T07:21:41.177Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。  </p>
</blockquote>
<a id="more"></a>
<p><em>空间语义不确定性原则</em>，探索在CNN特征层次结构中的空间和语义正确性。网络的顶层图像语义预测准确，但是带来的缺陷是在低分辨率下的图像空间上的定位，边界清晰但是标签有噪声。提出了一种重建模型在给定层次上提高空间定位的准确性，和一种细化技术用来融合多层的信息来优化图像的语义分割结果。<br>与传统FCN的区别：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-16/29818085-file_1492332368566_59f2.png" alt=""><br>不同之处在于，上采样和重建。<br><strong>CNN 特征图固有的缺少空间细节信息</strong>用一些不同的方法可以解决，如条件随机场、超像素、边界检测。还有一些成对的特征映射，可以进行反向传播进行训练。此论文的方法是<strong>直接提高输出激活图空间分辨率</strong>。<br><strong>双线性上采样是从低分辨率特征图中计算出高分辨率分割图的一种标准方法</strong>，首先卷积网络从特征图中计算出低分辨率的得分图，然后使用线性过滤器上采样为高分辨率的得分图。这种方法<em>可能会从多通道低分辨率特征图中丢失定位信息</em>。为了保留更多的空间信息，论文避免了将高维特征图折叠成低分辨率的类别预测。取而代之的是利用高分辨率基函数的线性组合对高分辨率的分类得分图的空间模式进行编码，这些函数的权重被高维特征图预测得到。实现：将高分辨率的特征图分成不重叠的图像块，大小取决于网络中池化层的个数次幂，通过一个卷积网络预测从高纬度低分辨率到特征图像块的映射。这些特征图像块和类别系数与一个基本函数集合相乘，再与一个基本的去卷积层相加，得到期望的全分辨率类别图。<br><strong>连接样条插值</strong><br>更高阶的样条插值替代上采样。<br><strong>学习基本函数</strong><br><strong>基本结构</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/25758666-file_1492397377051_a8d3.png" alt=""><br>首先，网络从上到下，分辨率越来越小。在每一次缩小时，特征图重建，再进行组合，产生对应倍数特征图的分割得分图，上图的水平方向，通过组合不同倍数的得分图。<br>一种从高分辨率中减去低频成分的方法，边界masking，孤立出边界成分。<br>金字塔的应用：<br>下层分割图得分上采样作为上一层采样的参考，用于得分图和像素对的产生。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/99567344-file_1492411678446_ecd2.png" alt=""><br><strong>Conclusion</strong>  </p>
<ul>
<li>以特定类重建为基础作为上采样；  </li>
<li>合成低分辨率的语义丰富的特征图和拥有更多空间特性的高分辨率特征图，多层拉普拉斯金字塔重建结构。  </li>
<li>最后可以加上CRF进行后期处理，优化结果。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>网易2017春招笔试编程题</title>
    <link href="http://abumaster.com/2017/04/14/%E7%BD%91%E6%98%932017%E6%98%A5%E6%8B%9B%E7%AC%94%E8%AF%95%E7%BC%96%E7%A8%8B%E9%A2%98/"/>
    <id>http://abumaster.com/2017/04/14/网易2017春招笔试编程题/</id>
    <published>2017-04-14T06:14:18.000Z</published>
    <updated>2017-04-14T06:45:55.647Z</updated>
    
    <content type="html"><![CDATA[<p><strong>感悟</strong>：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。<br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;感悟&lt;/strong&gt;：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="算法" scheme="http://abumaster.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>FCN图像语义分割计算的细节问题</title>
    <link href="http://abumaster.com/2017/04/11/FCN%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AE%A1%E7%AE%97%E7%9A%84%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/04/11/FCN图像语义分割计算的细节问题/</id>
    <published>2017-04-11T08:59:57.000Z</published>
    <updated>2017-04-12T01:09:31.691Z</updated>
    
    <content type="html"><![CDATA[<p>Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。<br><a id="more"></a><br>从论文中地址中，下载<a href="https://github.com/shelhamer/fcn.berkeleyvision.org">FCN</a>源码到本地。<br><strong>1.使用现有模型进行图像语义分割</strong><br>解压源代码，在根目录下，有一个infer.py的文件，打开，配置自己的模型路径，运行即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="comment"># load image, switch to BGR, subtract mean, and make dims C x H x W for Caffe</span></div><div class="line">im = Image.open(<span class="string">'voc-fcn8s/21.jpg'</span>)</div><div class="line">in_ = np.array(im, dtype=np.float32)</div><div class="line">in_ = in_[:,:,::<span class="number">-1</span>]</div><div class="line"><span class="comment">#in_ -= np.array((104.00698793,116.66876762,122.67891434))</span></div><div class="line">in_ -= np.array((<span class="number">106.08069</span>,<span class="number">103.75618</span>,<span class="number">100.05657</span>))</div><div class="line">in_ = in_.transpose((<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</div><div class="line"><span class="comment"># load net</span></div><div class="line">net = caffe.Net(<span class="string">'voc-fcn8s/deploy.prototxt'</span>, <span class="string">'voc-fcn8s/fcn8s-heavy-pascal.caffemodel'</span>, caffe.TEST)</div><div class="line"><span class="comment"># shape for input (data blob is N x C x H x W), set data</span></div><div class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">1</span>, *in_.shape)</div><div class="line">net.blobs[<span class="string">'data'</span>].data[...] = in_</div><div class="line"><span class="comment"># run net and take argmax for prediction</span></div><div class="line">net.forward()</div><div class="line">out = net.blobs[<span class="string">'score'</span>].data[<span class="number">0</span>].argmax(axis=<span class="number">0</span>)</div><div class="line"><span class="comment">#print out</span></div><div class="line">plt.imshow(out,cmap=<span class="string">'gray'</span>);</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.savefig(<span class="string">'test1.png'</span>)</div></pre></td></tr></table></figure></p>
<p><strong>2.源码阅读</strong><br>在源码的voc-fcn32s问价夹下，net.py用于生成网络的配置文件：train.prototxt、val.prototxt，solve.py用来运行训练网络，solver.prototxt是训练的配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">train_net: &quot;train.prototxt&quot;</div><div class="line">test_net: &quot;val.prototxt&quot;</div><div class="line">test_iter: 736</div><div class="line"># make test net, but don&apos;t invoke it from the solver itself</div><div class="line">test_interval: 999999999</div><div class="line">display: 20</div><div class="line">average_loss: 20</div><div class="line">lr_policy: &quot;fixed&quot;</div><div class="line"># lr for unnormalized softmax</div><div class="line">base_lr: 1e-10</div><div class="line"># high momentum</div><div class="line">momentum: 0.99</div><div class="line"># no gradient accumulation</div><div class="line">iter_size: 1</div><div class="line">max_iter: 100000</div><div class="line">weight_decay: 0.0005</div><div class="line">snapshot: 4000</div><div class="line">snapshot_prefix: &quot;snapshot/train&quot;</div><div class="line">test_initialization: false</div></pre></td></tr></table></figure></p>
<p><strong>solve.py 文件解读</strong><br>它调用了根目录下的 surgery.py 和 score.py 文件，后面再介绍。<br>主要作用：  </p>
<ul>
<li>用现有的分类网络模型初始化网络；  </li>
<li>自定义上采样层的卷积核；  </li>
<li>加载验证图片，自定义最后的得分输出。<br>初始化网络：  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">weights = <span class="string">'../ilsvrc-nets/vgg16-fcn.caffemodel'</span> <span class="comment">#加载训练好的分类模型</span></div><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)<span class="comment">#加载网络配置文件</span></div><div class="line">solver.net.copy_from(weights)<span class="comment">#从模型中复制权重</span></div><div class="line"><span class="comment">#也可以写为如下方式：</span></div><div class="line"><span class="comment">#solver = caffe.SGDSolver('solver.prototxt')</span></div><div class="line"><span class="comment">#vgg_net = caffe.Net('solver.prototxt', weights, caffe.TRAIN)</span></div><div class="line"><span class="comment">#surgery.transplant(solver.net, vgg_net)</span></div><div class="line"><span class="comment">#del vgg_net</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>调用surgery.py中的上采样层，双线性插值，将图像变为原始大小。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">interp_layers = [k <span class="keyword">for</span> k <span class="keyword">in</span> solver.net.params.keys() <span class="keyword">if</span> <span class="string">'up'</span> <span class="keyword">in</span> k]</div><div class="line">surgery.interp(solver.net, interp_layers)</div></pre></td></tr></table></figure></p>
<p>得分层<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># scoring</span></div><div class="line">val = np.loadtxt(<span class="string">'../data/segvalid11.txt'</span>, dtype=str)<span class="comment">#加载验证图片</span></div><div class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">25</span>):</div><div class="line">    solver.step(<span class="number">4000</span>)</div><div class="line">    score.seg_tests(solver, <span class="keyword">False</span>, val, layer=<span class="string">'score'</span>)<span class="comment">#测试网络的得分情况</span></div></pre></td></tr></table></figure></p>
<p><strong>surgery.py 文件解读</strong><br>主要作用是制作适用于给定长宽的双线性插值内核，用于上采样。主要函数为:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample_filt</span><span class="params">(size)</span>:</span></div><div class="line">    <span class="string">"""</div><div class="line">    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.</div><div class="line">    """</span></div><div class="line">    factor = (size + <span class="number">1</span>) // <span class="number">2</span></div><div class="line">    <span class="keyword">if</span> size % <span class="number">2</span> == <span class="number">1</span>:</div><div class="line">        center = factor - <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        center = factor - <span class="number">0.5</span></div><div class="line">    og = np.ogrid[:size, :size]</div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> - abs(og[<span class="number">0</span>] - center) / factor) * \</div><div class="line">           (<span class="number">1</span> - abs(og[<span class="number">1</span>] - center) / factor)</div></pre></td></tr></table></figure></p>
<p><strong>score.py 文件解读</strong><br>主要作用：计算当前网络分割图的准确性。主要有以下几个标准：mean loss, overall accuracy, per-class accuracy, per-class IU。如何计算的呢？<br>首先理解两个函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#计算a和b对应相同的就在矩阵中对应坐标加1。a和b保存着各个像素的分的类别0-20共21类</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_hist</span><span class="params">(a, b, n)</span>:</span></div><div class="line">    k = (a &gt;= <span class="number">0</span>) &amp; (a &lt; n)<span class="comment">#过滤掉多余的分类</span></div><div class="line">    <span class="comment">#bincount用于统计在范围内出现的个数，即直方图，如果不够n^2个，</span></div><div class="line">    <span class="comment">#那就填充到n^2，这样可以reshpe为n*n的矩阵，正好表示分割图和正确标记图在相同</span></div><div class="line">    <span class="comment">#类别上像素出现的个数</span></div><div class="line">    <span class="keyword">return</span> np.bincount(n * a[k].astype(int) + b[k], minlength=n**<span class="number">2</span>).reshape(n, n)</div><div class="line"><span class="comment">#调用计算直方图函数，指定了数据来源</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_hist</span><span class="params">(net, save_dir, dataset, layer=<span class="string">'score'</span>, gt=<span class="string">'label'</span>)</span>:</span></div><div class="line">    n_cl = net.blobs[layer].channels<span class="comment">#得到score层的通道数，fcn中为21通道，21类物体</span></div><div class="line">    <span class="keyword">if</span> save_dir:<span class="comment">#是否将分割图保存为文件</span></div><div class="line">        os.mkdir(save_dir)</div><div class="line">    <span class="comment">#hist表示：分割图中21类和标记图21类出现的像素数</span></div><div class="line">    <span class="comment">#如：在i,j像素位置上分割图标记为2类物体，而实际标记为3那么在hist（2,3）+=1</span></div><div class="line">    <span class="comment">#    在i,j+1像素位置分割图标记2类物体，实际标记图也为2类，则hist(2,2)+=1</span></div><div class="line">    <span class="comment">#    可以看出hist对角矩阵是正确的分割；</span></div><div class="line">    hist = np.zeros((n_cl, n_cl))<span class="comment">#初始化21*21的二维矩阵</span></div><div class="line">    loss = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> dataset:</div><div class="line">        net.forward()<span class="comment">#网络向前传播</span></div><div class="line">        <span class="comment">#展开为一维数组</span></div><div class="line">        hist += fast_hist(net.blobs[gt].data[<span class="number">0</span>, <span class="number">0</span>].flatten(),</div><div class="line">                          net.blobs[layer].data[<span class="number">0</span>].argmax(<span class="number">0</span>).flatten(),n_cl)</div><div class="line">        <span class="keyword">if</span> save_dir:</div><div class="line">            im = Image.fromarray(net.blobs[layer].data[<span class="number">0</span>].argmax(<span class="number">0</span>).astype(np.uint8), mode=<span class="string">'P'</span>)</div><div class="line">            im.save(os.path.join(save_dir, idx + <span class="string">'.png'</span>))</div><div class="line">        <span class="comment"># compute the loss as well 计算网络的损失</span></div><div class="line">        loss += net.blobs[<span class="string">'loss'</span>].data.flat[<span class="number">0</span>]<span class="comment">#flat[0]取第一个数</span></div><div class="line">    <span class="keyword">return</span> hist, loss / len(dataset)</div></pre></td></tr></table></figure></p>
<p>计算几个分割效果指标：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#mean loss</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'loss'</span>, loss</div><div class="line">   <span class="comment"># overall accuracy</span></div><div class="line">   acc = np.diag(hist).sum() / hist.sum()<span class="comment">#对角线正确像素/总像素</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'overall accuracy'</span>, acc</div><div class="line">   <span class="comment"># per-class accuracy</span></div><div class="line">   acc = np.diag(hist) / hist.sum(<span class="number">1</span>)<span class="comment">#每一类的</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'mean accuracy'</span>, np.nanmean(acc)</div><div class="line">   <span class="comment"># per-class IU</span></div><div class="line">   iu = np.diag(hist) / (hist.sum(<span class="number">1</span>) + hist.sum(<span class="number">0</span>) - np.diag(hist))</div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'mean IU'</span>, np.nanmean(iu)</div><div class="line">   freq = hist.sum(<span class="number">1</span>) / hist.sum()</div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'fwavacc'</span>, \</div><div class="line">           (freq[freq &gt; <span class="number">0</span>] * iu[freq &gt; <span class="number">0</span>]).sum()</div></pre></td></tr></table></figure></p>
<p>其他文件：训练文件的输入层类型是Python，作者自定义了一个voc_layers.py的Python数据加载层。  </p>
<ul>
<li>setup函数，设置voc训练集的路径，及中值文件，挑选数据的随机数；</li>
<li>load_image和load_label函数，用于从数据集中加载图像和标记图像，并转换成数组形式，图像减去中值并转换成<code>chanl*height*weight</code>形式，label变为<code>1*height*weight</code>形式；</li>
<li>forward和backward函数，前向传播将图像、标签复制到top[0]和top[1]中，反向传播不需要任何操作。  </li>
</ul>
<p><strong>学习到的东西</strong><br>Python中numpy中的一些函数，诸如bincount、flatten、diag等。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="学习" scheme="http://abumaster.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Background Dataset介绍和使用</title>
    <link href="http://abumaster.com/2017/04/10/Stanford-Background-Dataset%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://abumaster.com/2017/04/10/Stanford-Background-Dataset介绍和使用/</id>
    <published>2017-04-10T06:35:07.000Z</published>
    <updated>2017-04-11T00:58:07.351Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dags.stanford.edu/projects/scenedataset.html">Stanford Background Dataset</a>是一个从各个数据库（LabelMe, MSRC, PASCAL<br>VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。</p>
<ul>
<li><p>images文件夹包含了715张图像；  </p>
</li>
<li><p>horizons.txt  图像名称、大小、水平线位置；  </p>
<a id="more"></a>
</li>
<li><p>labels/*.regions.txt 标识每个像素的语义，0-7代表八类语义；  </p>
</li>
<li><p>labels/*.surfaces.txt 标识每个像素的几何类别（天空，水平，垂直）； </p>
</li>
<li><p>labels/*.layers.txt    表示不同图像区域的整数矩阵。  </p>
</li>
</ul>
<p><strong>读取图像和分割图像</strong><br>1.首先读取标签文件<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">vector&lt;char&gt; vec;//保存像素标记</div><div class="line">void readlabel(string labelname)</div><div class="line">&#123;</div><div class="line">	ifstream infile(labelname.c_str(), std::ios::in);</div><div class="line">	char line[1024] = &#123; 0 &#125;;</div><div class="line">	while (infile.getline(line, sizeof(line)))</div><div class="line">	&#123;</div><div class="line">		stringstream word(line);</div><div class="line">		char ch;</div><div class="line">		while (word &gt;&gt; ch)</div><div class="line">		&#123;</div><div class="line">			vec.push_back(ch);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>2.显示分割图像，根据语义标签，设置不同的颜色以区别  </p>
<pre><code class="c++"><span class="comment">//显示分割图像</span>
    <span class="function">Mat <span class="title">colorim</span><span class="params">(im.rows, im.cols, CV_8UC3)</span></span>;
    <span class="keyword">int</span> index = <span class="number">0</span>;
    <span class="comment">//遍历所有像素，并设置像素值</span>
    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colorim.rows; ++i)
    {
        <span class="comment">//获取第 i 行首像素指针</span>
        Vec3b * p = colorim.ptr&lt;Vec3b&gt;(i);
        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; colorim.cols; ++j)
        {
            <span class="keyword">int</span> lab = vec[index++];
            <span class="keyword">switch</span> (lab)
            {
            <span class="keyword">case</span> <span class="string">'0'</span>:<span class="comment">//sky</span>
                p[j][<span class="number">0</span>] = <span class="number">128</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">128</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">128</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'1'</span>:<span class="comment">//tree</span>
                p[j][<span class="number">0</span>] = <span class="number">84</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">230</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">80</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'2'</span>:<span class="comment">//road</span>
                p[j][<span class="number">0</span>] = <span class="number">115</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">100</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'3'</span>:<span class="comment">//grass</span>
                p[j][<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">255</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">0</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'4'</span>:<span class="comment">//water</span>
                p[j][<span class="number">0</span>] = <span class="number">255</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">0</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'5'</span>:<span class="comment">//building</span>
                p[j][<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">160</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'6'</span>:<span class="comment">//mountain</span>
                p[j][<span class="number">0</span>] = <span class="number">63</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">214</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">8</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'7'</span>:<span class="comment">//obj</span>
                p[j][<span class="number">0</span>] = <span class="number">37</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">159</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">230</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">default</span>:<span class="comment">//somthing else</span>
                p[j][<span class="number">0</span>] = <span class="number">255</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">255</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">255</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;

            }

        }
    }
    imshow(<span class="string">"分割图"</span>, colorim);
</code></pre>
<p><strong>结果</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-11/35996483-file_1491872210006_c82e.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dags.stanford.edu/projects/scenedataset.html&quot;&gt;Stanford Background Dataset&lt;/a&gt;是一个从各个数据库（LabelMe, MSRC, PASCAL&lt;br&gt;VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;images文件夹包含了715张图像；  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;horizons.txt  图像名称、大小、水平线位置；  &lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="dataset" scheme="http://abumaster.com/tags/dataset/"/>
    
  </entry>
  
  <entry>
    <title>caffe提取各层特征</title>
    <link href="http://abumaster.com/2017/04/09/caffe%E6%8F%90%E5%8F%96%E5%90%84%E5%B1%82%E7%89%B9%E5%BE%81/"/>
    <id>http://abumaster.com/2017/04/09/caffe提取各层特征/</id>
    <published>2017-04-09T12:07:29.000Z</published>
    <updated>2017-04-10T02:03:08.407Z</updated>
    
    <content type="html"><![CDATA[<p>根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：<br><strong>1.caffe创建分类器</strong><br>Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\python\caffe下。<br><a id="more"></a><br>初始化这个分类器的时候，出现了一个问题：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">net = caffe.Classifier(caffe_root + <span class="string">'models/bvlc_reference_caffenet/deploy.prototxt'</span>,</div><div class="line">caffe_root + <span class="string">'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span>)</div><div class="line"></div><div class="line">net.set_phase_test()</div><div class="line">net.set_mode_cpu()</div><div class="line">net.set_mean(<span class="string">'data'</span>, caffe_root + <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)</div><div class="line">net.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>)) </div><div class="line">net.set_input_scale(<span class="string">'data'</span>, <span class="number">255</span>)</div></pre></td></tr></table></figure></p>
<p>就是在网络设置时，一直提示没有<code>set_phase_test(*)</code>的成员函数，试了几个平台都是如此提示，后来在网上找到了一点<a href="http://www.programcreek.com/python/example/83400/caffe.set_phase_test">信息</a>其中提到了，可以直接创建的时候初始化，对应于函数的声明所需的参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">net = caffe.Classifier(MODEL_FILE, PRETRAINED,</div><div class="line">                        mean=np.load(os.path.join(CAFFE_DIR, <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)),</div><div class="line">                        channel_swap=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>),</div><div class="line">                        raw_scale=<span class="number">255</span>,</div><div class="line">                        image_dims=(<span class="number">256</span>, <span class="number">256</span>))</div></pre></td></tr></table></figure></p>
<p><strong>维度不匹配问题</strong>代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"> File &quot;one.py&quot;, line 14, in &lt;module&gt;</div><div class="line">    image_dims=(256, 256))</div><div class="line">  File &quot;/home/zgf/caffe-master/python/caffe/classifier.py&quot;, line 34, in __init__</div><div class="line">    self.transformer.set_mean(in_, mean)</div><div class="line">  File &quot;/home/zgf/caffe-master/python/caffe/io.py&quot;, line 259, in set_mean</div><div class="line">    raise ValueError(&apos;Mean shape incompatible with input shape.&apos;)</div><div class="line">ValueError: Mean shape incompatible with input shape.</div></pre></td></tr></table></figure></p>
<p>中值文件读取的错误，在网络上找到了解决<a href="http://stackoverflow.com/questions/30808735/error-when-using-classify-in-caffe">方案</a>，将读取中值文件改为：<code>mean=np.load(&#39;/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy&#39;).mean(1).mean(1)</code>可以解决。  </p>
<p><strong>2.显示特征图像问题</strong><br>按照文档描述依次往下进行，文档使用的工具为ipython，显示图片用：<code>ipt.show()</code>，而我用的工具是jupyter，所以一直找不到这个命令，无法查看图像，从网上查到，可以在代码前面加上一句<code>%matplotlib inline</code>然后用<code>import matplotlib as plt plt.imshow(img)</code>实现。  </p>
<p><strong>3.结果</strong><br>加载网络<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">caffe_root=<span class="string">'/home/zgf/caffe-master/'</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> os</div><div class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">'python/caffe'</span>)</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"></div><div class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10</span>, <span class="number">10</span>)</div><div class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></div><div class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></div><div class="line"></div><div class="line">ref_model_file = caffe_root+<span class="string">'/models/bvlc_reference_caffenet/deploy.prototxt'</span></div><div class="line">ref_pretrained = caffe_root+<span class="string">'/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span></div><div class="line"></div><div class="line">net = caffe.Classifier(ref_model_file, ref_pretrained,</div><div class="line">       mean=np.load(<span class="string">'/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>).mean(<span class="number">1</span>).mean(<span class="number">1</span>),</div><div class="line">       channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),</div><div class="line">       raw_scale=<span class="number">255</span>,</div><div class="line">       image_dims=(<span class="number">256</span>, <span class="number">256</span>))</div><div class="line"></div><div class="line">scores = net.predict([caffe.io.load_image(caffe_root + <span class="string">'examples/images/cat.jpg'</span>)])</div><div class="line"><span class="comment">#显示网络的结构信息</span></div><div class="line">[(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.blobs.items()]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[(&apos;data&apos;, (10, 3, 227, 227)),</div><div class="line"> (&apos;conv1&apos;, (10, 96, 55, 55)),</div><div class="line"> (&apos;pool1&apos;, (10, 96, 27, 27)),</div><div class="line"> (&apos;norm1&apos;, (10, 96, 27, 27)),</div><div class="line"> (&apos;conv2&apos;, (10, 256, 27, 27)),</div><div class="line"> (&apos;pool2&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;norm2&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;conv3&apos;, (10, 384, 13, 13)),</div><div class="line"> (&apos;conv4&apos;, (10, 384, 13, 13)),</div><div class="line"> (&apos;conv5&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;pool5&apos;, (10, 256, 6, 6)),</div><div class="line"> (&apos;fc6&apos;, (10, 4096)),</div><div class="line"> (&apos;fc7&apos;, (10, 4096)),</div><div class="line"> (&apos;fc8&apos;, (10, 1000)),</div><div class="line"> (&apos;prob&apos;, (10, 1000))]</div></pre></td></tr></table></figure></p>
<p>显示参数信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.params.items()]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[(&apos;conv1&apos;, (96, 3, 11, 11)),</div><div class="line"> (&apos;conv2&apos;, (256, 48, 5, 5)),</div><div class="line"> (&apos;conv3&apos;, (384, 256, 3, 3)),</div><div class="line"> (&apos;conv4&apos;, (384, 192, 3, 3)),</div><div class="line"> (&apos;conv5&apos;, (256, 192, 3, 3)),</div><div class="line"> (&apos;fc6&apos;, (4096, 9216)),</div><div class="line"> (&apos;fc7&apos;, (4096, 4096)),</div><div class="line"> (&apos;fc8&apos;, (1000, 4096))]</div></pre></td></tr></table></figure></p>
<p><strong>输入层</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">showimage</span><span class="params">(im)</span>:</span></div><div class="line">    <span class="keyword">if</span> im.ndim == <span class="number">3</span>:</div><div class="line">        m = im[:, :, ::<span class="number">-1</span>]</div><div class="line">    plt.imshow(im)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span><span class="params">(data, padsize=<span class="number">1</span>, padval=<span class="number">0</span>)</span>:</span></div><div class="line">    data -= data.min()</div><div class="line">    data /= data.max()</div><div class="line">    <span class="comment"># force the number of filters to be square</span></div><div class="line">    n = int(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</div><div class="line">    padding = ((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]), (<span class="number">0</span>, padsize), (<span class="number">0</span>, padsize)) + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>)</div><div class="line">    data = np.pad(data, padding, mode=<span class="string">'constant'</span>, constant_values=(padval, padval))</div><div class="line">    <span class="comment"># 对图像使用滤波器</span></div><div class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + tuple(range(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</div><div class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</div><div class="line">    showimage(data)</div><div class="line">    <span class="comment">#plt.imshow(data)</span></div><div class="line"><span class="comment"># index four is the center crop</span></div><div class="line"><span class="comment"># 输出输入的图像</span></div><div class="line">image = net.blobs[<span class="string">'data'</span>].data[<span class="number">4</span>].copy()</div><div class="line">image -= image.min()</div><div class="line">image /= image.max()</div><div class="line">showimage(image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</div><div class="line"><span class="comment">#plt.imshow(image.transpose(1,2,0))</span></div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i4.buimg.com/567571/2d78079157ce4c40.png" alt=""><br>第一个卷积层，参数有[weight, biases]对应索引0,1。的96个过滤器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">filters = net.params[<span class="string">'conv1'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</div><div class="line"><span class="comment">#96 feature map</span></div><div class="line">feat = net.blobs[<span class="string">'conv1'</span>].data[<span class="number">4</span>, :<span class="number">96</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i4.buimg.com/567571/64897ccff6d61745.jpg" alt=""><br>第二卷积层的过滤器，每个尺寸5*5*48，显示前48个，机器对应的输出只显示36张。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">filters = net.params[<span class="string">'conv2'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters[:<span class="number">48</span>].reshape(<span class="number">48</span>**<span class="number">2</span>, <span class="number">5</span>, <span class="number">5</span>))</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv2'</span>].data[<span class="number">4</span>, :<span class="number">36</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i2.muimg.com/567571/441dcc7e494e611a.jpg" alt=""><br>接下来的卷积层的提取和输出一样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'conv3'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.5</span>)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv4'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.5</span>)</div><div class="line"><span class="comment">#第5卷积层</span></div><div class="line">feat = net.blobs[<span class="string">'conv5'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.2</span>)</div><div class="line"><span class="comment">#池化层</span></div><div class="line">feat = net.blobs[<span class="string">'pool5'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>最后的全连接层fc6和fc7，输出直方图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'fc6'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'fc7'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://i1.piimg.com/567571/44bbc67d60e82537.jpg" alt="fc"><br>最后的输出层，显示1000类概率的直方图信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'prob'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div></pre></td></tr></table></figure></p>
<p><img src="http://i1.piimg.com/567571/c9d3333a6724e4d0.jpg" alt="prob"><br>显示最后的类别信息top5：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">imagenet_labels_filename = caffe_root + <span class="string">'data/ilsvrc12/synset_words.txt'</span></div><div class="line"><span class="keyword">try</span>:</div><div class="line">    labels = np.loadtxt(imagenet_labels_filename, str, delimiter=<span class="string">'\t'</span>)</div><div class="line"><span class="keyword">except</span>:</div><div class="line">    !../data/ilsvrc12/get_ilsvrc_aux.sh</div><div class="line">labels = np.loadtxt(imagenet_labels_filename, str, delimiter=<span class="string">'\t'</span>)</div><div class="line">top_k = net.blobs[<span class="string">'prob'</span>].data[<span class="number">4</span>].flatten().argsort()[<span class="number">-1</span>:<span class="number">-6</span>:<span class="number">-1</span>]</div><div class="line"><span class="keyword">print</span> labels[top_k]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[&apos;n02123045 tabby, tabby cat&apos; </div><div class="line"> &apos;n02123159 tiger cat&apos;</div><div class="line"> &apos;n02124075 Egyptian cat&apos; </div><div class="line"> &apos;n02119022 red fox, Vulpes vulpes&apos;</div><div class="line"> &apos;n02127052 lynx, catamount&apos;]</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：&lt;br&gt;&lt;strong&gt;1.caffe创建分类器&lt;/strong&gt;&lt;br&gt;Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\python\caffe下。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>结合特定任务边缘检测的图像语义分割</title>
    <link href="http://abumaster.com/2017/04/07/%E7%BB%93%E5%90%88%E7%89%B9%E5%AE%9A%E4%BB%BB%E5%8A%A1%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/07/结合特定任务边缘检测的图像语义分割/</id>
    <published>2017-04-07T07:38:22.000Z</published>
    <updated>2017-04-08T02:30:39.618Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。  </p>
</blockquote>
<a id="more"></a>
<p><strong>主要思想</strong><br>取代最后的全连接条件随机场和与其关联的双向过滤器，变为域变换（DT）一种边缘感知过滤器。域变换的递归公式等于信号的自适应递归滤波，其中信息不允许在某些参考信号中跨越边缘传播。速度快。<br><strong>前期工作</strong>  </p>
<ul>
<li>图像语义分割<br>网络中最大池化和下采样的出现，使稠密网络最后的输出图无法精准定位物体的边界信息，为了解决这个问题，出现了很多解决方案：组合中间特征图信息；反卷积和上采样；超像素等底层的分割方法；条件随机场，利用像素之间的依赖关系。  </li>
<li>边缘检测<br>学习物体的边界直接优化图像语义分割的表现。  </li>
<li>长距离依赖（Long range dependency）<br>通过DT输入进行反向传播，以共同学习端对端可训练系统中的分割图得分和边缘图。<br><strong>提出模型</strong><br>论文中提出的模型图：<br><img src="http://i4.buimg.com/567571/1043df45dae88c0c.png" alt=""><br>分为三个部分：<br>1.语义分割预测，得出一个大致的分割图，与全卷积网络输出图类似；<br>2.边缘预测网络，生成一个边缘预测图；<br>3.域转换，使用物体边界限制分割图。<br><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>x表示需要过滤的原始信号量，y表示域转换密度信号d。使用递归公式计算，初始化y1=x1，然后递归计算<code>i=2,...,N</code>：<br>$$y_i=(1-w_i)x_i+w_iy_{i-1}$$<br>其中权重wi的计算依赖di：<br>$$w_i=exp(-\sqrt2d_i/{\sigma_{s}})$$<br>一维计算树，前向和反向传播的计算：<br><img src="http://i2.muimg.com/567571/08cbd87d8bbbe172.png" alt=""><br>$$\frac{\partial L}{\partial x_i}\leftarrow (1-w_i)\frac{\partial L}{\partial y_i}$$<br>$$\frac{\partial L}{\partial w_i}\leftarrow \frac{\partial L}{\partial w_i}+(y_{i-1}-x_i)\frac{\partial L}{\partial y_i}$$<br>$$\frac{\partial L}{\partial y_{i-1}}\leftarrow \frac{\partial L}{\partial y_{i-1}}+w_i\frac{\partial L}{\partial y_i}$$<br>源码和模型<a href="http://liangchiehchen.com/projects/DeepLab.html">地址</a>。接下来学习。</li>
</ul>
<p><strong>参考文献</strong><br>[1] “Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform”<br>Liang-Chieh Chen, Jonathan T. Barron, George Papandreou, Kevin Murphy, and Alan L. Yuille<br>In Conference on Computer Vision and Pattern Recognition (CVPR), 2016</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
  </entry>
  
  <entry>
    <title>进制转换</title>
    <link href="http://abumaster.com/2017/04/06/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
    <id>http://abumaster.com/2017/04/06/进制转换/</id>
    <published>2017-04-06T13:16:07.000Z</published>
    <updated>2017-04-06T14:09:19.093Z</updated>
    
    <content type="html"><![CDATA[<p><strong>题目描述</strong><br>将任意长度的二进制转换成十进制。<br>要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：<em>数字的n次方</em>、<em>大数相加</em>、<em>大数相乘</em>。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。<br><a id="more"></a><br><strong>解法</strong><br>二进制转换成十进制<br>观察：<code>10001000</code>的计算过程，转换成十进制为：<code>2^7+0+0+0+2^3+0+0+0</code>。<br>因此问题分为两个部分：计算二进制位置上为1时对应的十进制数是多少；对所有的位置得到的数字求和。<br>代码如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</div><div class="line"> * bin2dec 二进制转换成十进制</div><div class="line"> * @param decnum 十进制数字串</div><div class="line"> * @param n      二进制1后面的0的个数</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bin2dec</span><span class="params">(<span class="keyword">int</span> *decnum, <span class="keyword">int</span> n)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> index = LEN<span class="number">-1</span>;</div><div class="line">	decnum[index] = <span class="number">1</span>;</div><div class="line">	<span class="keyword">int</span> jinwei = <span class="number">0</span>;</div><div class="line">	<span class="keyword">while</span> (n--) <span class="comment">//总共几个0</span></div><div class="line">	&#123;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i = LEN<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> nowtemp = <span class="number">2</span>*decnum[i]+jinwei;</div><div class="line">			<span class="keyword">if</span>(nowtemp&gt;=<span class="number">10</span>)<span class="comment">//需要进位</span></div><div class="line">			&#123;</div><div class="line">				decnum[i] = nowtemp%<span class="number">10</span>; <span class="comment">//改变当前的数值</span></div><div class="line">				jinwei = nowtemp/<span class="number">10</span>; <span class="comment">//进位的多少</span></div><div class="line">			&#125;</div><div class="line">			<span class="keyword">else</span></div><div class="line">			&#123;</div><div class="line">				decnum[i] = nowtemp;</div><div class="line">				jinwei=<span class="number">0</span>;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</div><div class="line"> * 将两个大数合并，放入左边数组</div><div class="line"> * @param left  相加结果放入此</div><div class="line"> * @param right 数组</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">sumbignum</span><span class="params">(<span class="keyword">int</span> *left, <span class="keyword">int</span> *right, <span class="keyword">int</span> n=LEN)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> jinwei = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=n<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> temp = left[i]+right[i]+jinwei;<span class="comment">//俩数之和加上进位标志</span></div><div class="line">		<span class="keyword">if</span>(temp &gt;= <span class="number">10</span>)<span class="comment">//需要进位的</span></div><div class="line">		&#123;</div><div class="line">			left[i] = temp%<span class="number">10</span>;</div><div class="line">			jinwei = temp/<span class="number">10</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> <span class="comment">//不用进位</span></div><div class="line">		&#123;</div><div class="line">			left[i] = temp;</div><div class="line">			jinwei = <span class="number">0</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>十进制转换成二进制</strong><br>同理，位数少的十进制转换成二进制一般应用除2求余，然后直到商为0。<a href="http://baike.baidu.com/link?url=QHeUym9N6IWCVV6zLmIHIX6Y6CMPOfthTCyDRkfsq9TAxCjewlxrfhHYUw2sarVURML8-Oyz0bCASXtMqHqUWYGGRieuENcGHN30Qzmx6Ef_XdJSIaiBCn0vfvUrrILr4t15XLZWOj6RIdcgit792Vn5iQGGQYVyOfQF4R2ggfm">参考</a>。<br>对于大数，可以保存在一个数组中，用前一位的余数与当前的位数拼成一个数，除以2，商替换原数字对应的位数上，余数更新，直到把数字的位数计算完，算作得出二进制的一位（最后得出的余数）。直到商为0结束。代码如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> LEN = <span class="number">100</span>;</div><div class="line"><span class="comment">/**</div><div class="line"> * 检查数组代表的数字是否为空</div><div class="line"> * @param  arr [description]</div><div class="line"> * @param  len [description]</div><div class="line"> * @return     [description]</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsZero</span><span class="params">(<span class="keyword">int</span> *arr, <span class="keyword">int</span> len)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">bool</span> ret = <span class="literal">true</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">if</span>(arr[i] != <span class="number">0</span>)</div><div class="line">		&#123;</div><div class="line">			ret = <span class="literal">false</span>;</div><div class="line">			<span class="keyword">break</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> ret;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</div><div class="line"> * 十进制转换成二进制的核心函数</div><div class="line"> * @param decnum 十进制保存位置</div><div class="line"> * @param binnum 二进制字符串</div><div class="line"> * @param len    十进制长度</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">dec2binCore</span><span class="params">(<span class="keyword">int</span> *decnum, <span class="keyword">int</span> *binnum, <span class="keyword">int</span> len)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> mod;</div><div class="line">	<span class="keyword">int</span> index = LEN<span class="number">-1</span>;</div><div class="line">	<span class="keyword">while</span>(!IsZero(decnum, len))<span class="comment">//十进制表示的数字不为0</span></div><div class="line">	&#123;</div><div class="line">		mod = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i =<span class="number">0</span>; i&lt;len; i++)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> tempnum = <span class="number">10</span>*mod+decnum[i];</div><div class="line">			<span class="keyword">int</span> sang = tempnum/<span class="number">2</span>;</div><div class="line">			mod = tempnum%<span class="number">2</span>;</div><div class="line">			decnum[i] = sang; <span class="comment">//更新商</span></div><div class="line">		&#125;</div><div class="line">		binnum[index--] = mod;<span class="comment">//最后的余数是二进制</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">PrintInt</span><span class="params">(<span class="keyword">int</span> *arr, <span class="keyword">int</span> n)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> start = <span class="number">0</span>;<span class="comment">//bug</span></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n<span class="number">-1</span>; i++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> j = i+<span class="number">1</span>;</div><div class="line">		<span class="keyword">if</span>(arr[i]==<span class="number">0</span> &amp;&amp; arr[j]!=<span class="number">0</span> &amp;&amp; !start)</div><div class="line">		&#123;</div><div class="line">			start = <span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (start)</div><div class="line">			<span class="built_in">cout</span> &lt;&lt; arr[j];</div><div class="line">	&#125;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">testdec2bin</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">string</span> strnum;</div><div class="line">	<span class="keyword">while</span>(<span class="built_in">cin</span> &gt;&gt; strnum)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> len = strnum.size();</div><div class="line">		<span class="keyword">int</span> *decnum = <span class="keyword">new</span> <span class="keyword">int</span>[len];</div><div class="line">		<span class="built_in">memset</span>(decnum, <span class="number">0</span>, len*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)</div><div class="line">			decnum[i]= strnum[i]-<span class="string">'0'</span>;</div><div class="line">		<span class="keyword">int</span> *binnum = <span class="keyword">new</span> <span class="keyword">int</span>[LEN];</div><div class="line">		<span class="built_in">memset</span>(binnum, <span class="number">0</span>, LEN*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line">		dec2binCore(decnum, binnum, len);</div><div class="line">		PrintInt(binnum, LEN);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	testdec2bin();</div><div class="line"></div><div class="line">	system(<span class="string">"pause"</span>);</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>感悟</strong><br>看似简单的问题，还要细思量。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;题目描述&lt;/strong&gt;&lt;br&gt;将任意长度的二进制转换成十进制。&lt;br&gt;要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：&lt;em&gt;数字的n次方&lt;/em&gt;、&lt;em&gt;大数相加&lt;/em&gt;、&lt;em&gt;大数相乘&lt;/em&gt;。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>全卷积网络和全连接条件随机场</title>
    <link href="http://abumaster.com/2017/04/05/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"/>
    <id>http://abumaster.com/2017/04/05/全卷积网络和全连接条件随机场/</id>
    <published>2017-04-05T07:08:55.000Z</published>
    <updated>2017-04-06T13:10:41.589Z</updated>
    
    <content type="html"><![CDATA[<p>来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015.  主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。<br><a id="more"></a><br><strong>主要创新点：</strong><br>1.带孔卷积<br>在最后两个池化层后，跳过子采样，修改之后的卷积过滤器，变为卷积层。命名为孔算法，解释如图：<br><img src="http://i1.piimg.com/567571/ceb8871164ae116c.png" alt="">  </p>
<ul>
<li>高效的特征提取算法，有效的稠密滑动窗口特征提取器  </li>
<li>控制接受域大小，加速卷积网络的计算  </li>
</ul>
<p>2.边界恢复问题<br>目前定位物体边界的挑战主要从两个方面：  </p>
<ul>
<li>利用融合不同层特征图的相关信息，估计物体边界  </li>
<li>利用超像素表征，将任务委托给低层次的分割任务  </li>
</ul>
<p>模型：<br><img src="http://i1.piimg.com/567571/17c50f02e9958365.png" alt="">  </p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>$$E(x)=\sum_i\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)$$<br>有一元项和二元项。<br>3.多尺度预测<br>为了增加边界定位的准确性，用了多尺度预测。具体是，为输入图像和第一个四层最大池化层附加一个双层MLP（第一层：<code>128 个3*3的卷积核</code>，第二层：<code>128个1*1的卷积核</code>）与最后一层的特征图连接。汇总的特征图，放入softmax层，产生<code>5*128=640</code>通道。  </p>
<p><strong>系统实现</strong><br>DeepLab：使用深度卷积网络，atrous卷积和全连接crfs的图像语义分割模型。<br>针对传统方法的不足：  </p>
<ul>
<li>减少特征解析度（重复的最大池化和下采样）  </li>
<li>存在多个尺度的对象  </li>
<li>由于深度网络的稳定性导致定位精度下降<br>提出的优化方案：  </li>
<li>不采样  </li>
<li>atrous spatial pyramid pooling 空间金字塔池化  </li>
<li>结合条件随机场<br><strong>细节</strong><br>atrous卷积的计算，一维信号量示例如图：<br><img src="http://i1.piimg.com/567571/e4d2c7eb9eaa6b1e.png" alt=""><br>$$y[i]=\sum_{k=1}^Kx[i+r\cdot{k}]w[k]$$<br>全连接条件随机场：<br>关于能量函数，第一项由预测网络给出的预测值；第二项：<br><img src="http://i1.piimg.com/567571/c38b63130a578629.png" alt=""><br>公式分为两项，第一项是节点值不相等时为1，相等时为0，为了表示不同的标签将要受到惩罚。第二项，有两个高斯核组成，第一个是用像素的位置和像素的值表示，第二个是用像素之间的位置表示，他们是不同空间的特征。<br><img src="http://i2.muimg.com/567571/020f15b2235a3483.png" alt=""></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015.  主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
  </entry>
  
  <entry>
    <title>Linux配置OpenCV</title>
    <link href="http://abumaster.com/2017/04/03/Linux%E9%85%8D%E7%BD%AEOpenCV/"/>
    <id>http://abumaster.com/2017/04/03/Linux配置OpenCV/</id>
    <published>2017-04-03T08:23:00.000Z</published>
    <updated>2017-04-03T12:11:57.398Z</updated>
    
    <content type="html"><![CDATA[<p><strong>源码安装OpenCV</strong><br>从<a href="http://opencv.org/">OpenCV官网</a>下载，最新版的OpenCV（opencv-3.2.0）。<br>解压文件，得到文件夹（opencv-3.2.0），并进入；<br>进行源码编译：<br><a id="more"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mkdir release  </div><div class="line">cd release  </div><div class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..  </div><div class="line">make  </div><div class="line">sudo make install</div></pre></td></tr></table></figure>
<p><strong>配置依赖库</strong><br>安装完成后，编译完成，运行时会出现找不到依赖库的情况如：<br><code>error while loading shared libraries: libopencv_core.so.2.4: cannot open shared object file: No such file or directory</code><br>这是因为没有把共享库放在加载器可以找到的位置，解决方法：<br>首先定位到Opencv动态库所在的目录，一般在<code>/usr/local/lib/</code>或者<code>/usr/lib/x86_64-linux-gun/</code>中，在<code>/etc/ld.so.conf.d/</code>目录下创建一个opencv.conf的文件，并把上述的路径写入文件，然后执行<code>sudo ldconfig -v</code><br><strong>编译</strong><br><strong>1.第一种方式</strong><br><code>g++ DisplayImage.cpp -o DisplayImage &#39;pkg-config opencv --cflags --libs&#39;</code><br>在上面的编译命令中我们其实用到了一个工具“pkg-config”，它主要有以下几个功能：</p>
<ul>
<li><p>检查库的版本号。如果所需要的库的版本不满足要求，它会打印出错误信息，避免链接错误版本的库文件。  </p>
</li>
<li><p>获得编译预处理参数，如宏定义，头文件的位置。  </p>
</li>
<li><p>获得链接参数，如库及依赖的其它库的位置，文件名及其它一些连接参数。  </p>
</li>
<li><p>自动加入所依赖的其它库的设置</p>
</li>
</ul>
<p><strong>2.cmake工具</strong><br>CMake工具，需要一个CMakeLists.txt文件，然后输入命令<code>cmake .</code>会生成Makefile文件，然后make就行了。<br>CMakeLists.txt文件书写（opencv源码中带的例子example_cmake文件夹）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"># CMakeLists.txt</div><div class="line"># 必须的信息</div><div class="line">cmake_minimum_required(VERSION 2.8)</div><div class="line"></div><div class="line"># 工程的名称</div><div class="line">project(opencv_example_project)</div><div class="line"></div><div class="line"># 查找opencv的包</div><div class="line">find_package(OpenCV REQUIRED)</div><div class="line"></div><div class="line"># 打印库的状态信息</div><div class="line">message(STATUS &quot;OpenCV library status:&quot;)</div><div class="line">message(STATUS &quot;    version: $&#123;OpenCV_VERSION&#125;&quot;)</div><div class="line">message(STATUS &quot;    libraries: $&#123;OpenCV_LIBS&#125;&quot;)</div><div class="line">message(STATUS &quot;    include path: $&#123;OpenCV_INCLUDE_DIRS&#125;&quot;)</div><div class="line"></div><div class="line">if(CMAKE_VERSION VERSION_LESS &quot;2.8.11&quot;)</div><div class="line">  # Add OpenCV headers location to your include paths</div><div class="line">  include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)</div><div class="line">endif()</div><div class="line"></div><div class="line"># 生成的目标以及源文件</div><div class="line">add_executable(opencv_example example.cpp)</div><div class="line"></div><div class="line"># 程序与opencv动态库连接</div><div class="line">target_link_libraries(opencv_example $&#123;OpenCV_LIBS&#125;)</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;源码安装OpenCV&lt;/strong&gt;&lt;br&gt;从&lt;a href=&quot;http://opencv.org/&quot;&gt;OpenCV官网&lt;/a&gt;下载，最新版的OpenCV（opencv-3.2.0）。&lt;br&gt;解压文件，得到文件夹（opencv-3.2.0），并进入；&lt;br&gt;进行源码编译：&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>C++类构造函数</title>
    <link href="http://abumaster.com/2017/04/02/C-%E7%B1%BB%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"/>
    <id>http://abumaster.com/2017/04/02/C-类构造函数/</id>
    <published>2017-04-02T06:45:54.000Z</published>
    <updated>2017-04-02T13:48:05.088Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-中构造函数和析构函数应该注意的问题"><a href="#C-中构造函数和析构函数应该注意的问题" class="headerlink" title="C++中构造函数和析构函数应该注意的问题"></a>C++中构造函数和析构函数应该注意的问题</h3><p>构造方法用来初始化类的对象，与父类的其它成员不同，它不能被子类继承（子类可以继承父类所有的成员变量和成员方法，但不继承父类的构造方法）。因此，在创建子类对象时，为了初始化从父类继承来的数据成员，系统需要调用其父类的构造方法。C++11新标准中，派生类可以重用其直接基类定义的构造函数，类不能继承默认、拷贝、移动构造函数，如果派生类没有指定，则编译器会自动合成。<br><a id="more"></a></p>
<p>构造原则如下：  </p>
<ol>
<li><p>如果子类没有定义构造方法，则调用父类的无参数的构造方法。  </p>
</li>
<li><p>如果子类定义了构造方法，不论是无参数还是带参数，在创建子类的对象的时候,首先执行父类无参数的构造方法，然后执行自己的构造方法。 </p>
</li>
<li><p>在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数，则会调用父类的默认无参构造函数。  </p>
</li>
<li><p>在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数且父类自己提供了无参构造函数，则会调用父类自己的无参构造函数。  </p>
</li>
<li><p>在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数且父类只定义了自己的有参构造函数，则会出错（如果父类只有有参数的构造方法，则子类必须显示调用此带参构造方法）。  </p>
</li>
<li><p>如果子类调用父类带参数的构造方法，需要用初始化父类成员对象的方式</p>
</li>
</ol>
<p>析构函数<br>基类的析构函数声明为虚函数，这样销毁对象时子类会调用子类的析构函数，防止内存泄漏。如果没有定义为虚析构函数，销毁一个子类或者父类对象时，都会调用父类析构函数。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;C-中构造函数和析构函数应该注意的问题&quot;&gt;&lt;a href=&quot;#C-中构造函数和析构函数应该注意的问题&quot; class=&quot;headerlink&quot; title=&quot;C++中构造函数和析构函数应该注意的问题&quot;&gt;&lt;/a&gt;C++中构造函数和析构函数应该注意的问题&lt;/h3&gt;&lt;p&gt;构造方法用来初始化类的对象，与父类的其它成员不同，它不能被子类继承（子类可以继承父类所有的成员变量和成员方法，但不继承父类的构造方法）。因此，在创建子类对象时，为了初始化从父类继承来的数据成员，系统需要调用其父类的构造方法。C++11新标准中，派生类可以重用其直接基类定义的构造函数，类不能继承默认、拷贝、移动构造函数，如果派生类没有指定，则编译器会自动合成。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>数据结构-红黑二叉树</title>
    <link href="http://abumaster.com/2017/04/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    <id>http://abumaster.com/2017/04/01/数据结构-红黑二叉树/</id>
    <published>2017-04-01T04:25:53.000Z</published>
    <updated>2017-04-01T06:16:33.910Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://baike.baidu.com/link?url=mBopTNvEQOoavVU5s3cuRGbnLKZpEqoY3bjObubuenp_uCcLmyRAwh1PuuWb_GG-uLYrHyVtzC1h4hVP6pOO87s2UyvehOgd136FgM3x8IcRcaXalJMpEG1KfjIbmCcA">红黑树（Red Black Tree）</a>是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。<br>它是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。<br>红黑树和<a href="http://baike.baidu.com/item/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91">AVL树（平衡二叉树）</a>类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能，而统计性能要优于AVL树，广泛应用到各种程序库中。<br><a id="more"></a><br>它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n是树中元素的数目。<br><strong>性质</strong><br>红黑树是每个节点都带有黑色或者红色的二叉查找树。具有二叉树的性质，并且具有以下几个性质：  </p>
<ul>
<li>根节点是黑色   </li>
<li>叶子节点（空节点）是黑色的  </li>
<li>每个红色节点的两个子节点都是黑色的，叶子到根的路径上不能有连续的红色节点  </li>
<li>从任一节点开始到其每个叶子节点的所有路径包含相同数目的黑色节点<br><strong>基本操作</strong><br>左旋、右旋、重新着色三个操作。<br><img src="http://i2.muimg.com/567571/b5b8879e1ac59d7d.jpg" alt="左旋"><br>右旋操作类似，左旋就是将旋转的节点变为左子树，提取右节点上来，右旋是将右旋节点变为右子树，提取左节点上来。  </li>
</ul>
<p><strong>插入</strong>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://baike.baidu.com/link?url=mBopTNvEQOoavVU5s3cuRGbnLKZpEqoY3bjObubuenp_uCcLmyRAwh1PuuWb_GG-uLYrHyVtzC1h4hVP6pOO87s2UyvehOgd136FgM3x8IcRcaXalJMpEG1KfjIbmCcA&quot;&gt;红黑树（Red Black Tree）&lt;/a&gt;是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。&lt;br&gt;它是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。&lt;br&gt;红黑树和&lt;a href=&quot;http://baike.baidu.com/item/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91&quot;&gt;AVL树（平衡二叉树）&lt;/a&gt;类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能，而统计性能要优于AVL树，广泛应用到各种程序库中。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>动态规划-背包问题</title>
    <link href="http://abumaster.com/2017/03/31/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/03/31/动态规划-背包问题/</id>
    <published>2017-03-31T00:41:50.000Z</published>
    <updated>2017-03-31T01:46:12.686Z</updated>
    
    <content type="html"><![CDATA[<p><strong>题目描述</strong><br>有 a，b，c 三个物体，<br>重量记为 W 5，4，3<br>价值记为 V 20 10 12<br>有一个背包容量 C = 10 ，问：可以装的最大价值为多少？  </p>
<a id="more"></a>
<p>解决动态规划问题的主要方法是找到<strong>状态转移方程</strong>，动态规划全局最优包含了局部最优解。<br>分析上述问题：<br>背包容量10，首先，第一个物品有装入和不装入两种情况，转入的话状态变为：容量5，物品重量4,3物品价值10,12；不装入则变为：容量10，物品质量4,3，价值10,12。因此可以定义：<code>dp[i][j]表示前i个物品装到剩余容量为j的背包中的价值 dp[3][10]即为所求的结果</code>，有了状态，这个状态是如何转移的呢？由上面的分析，可知，第i个物品有装入和不装入两种情况，因此状态转移方程可以表示如下：<code>dp[i][j] = Max(dp[i-1][j], dp[i-1][j-w[i]]+v[i])</code>。容易写出代码：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</div><div class="line">&#123;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;=C; j++)</div><div class="line">	&#123;</div><div class="line">		dp[i][j] = (i==<span class="number">0</span>?<span class="number">0</span>:dp[i<span class="number">-1</span>][j]);</div><div class="line">		<span class="keyword">if</span>(i&gt;<span class="number">0</span> &amp;&amp; j&gt;=W[i]) </div><div class="line">			dp[i][j] = Max(dp[i<span class="number">-1</span>][j], dp[i<span class="number">-1</span>][j-w[i]]+v[i]);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>关于优化空间复杂度</strong><br>上述存储状态方程为二维数组，可以压缩为一维数组，<code>dp[i][j]变为dp[j]</code>避免了重复的计算。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">memeset(dp, <span class="number">0</span>, <span class="keyword">sizeof</span>(dp));</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</div><div class="line">&#123;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> j=C; j&gt;=<span class="number">0</span>; j++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">if</span>(i&gt;<span class="number">0</span>  &amp;&amp; j&gt;=W[i]) </div><div class="line">			dp[j] = Max(dp[j], dp[j-W[i]]+V[i]);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>[网易2017实习笔试题-双核处理]</strong><br>题目描述：<br>一种双核CPU的两个核能够同时的处理任务，现在有n个已知数据量的任务需要交给CPU处理，假设已知CPU的每个核1秒可以处理1kb，每个核同时只能处理一项任务。n个任务可以按照任意顺序放入CPU进行处理，现在需要设计一个方案让CPU处理完这批任务所需的时间最少，求这个最小的时间。<br>输入描述：  </p>
<blockquote>
<p>输入包括两行：<br>第一行为整数n(1 ≤ n ≤ 50)<br>第二行为n个整数length<a href="1024 ≤ length[i] ≤ 4194304">i</a>，表示每个任务的长度为length[i]kb，每个数均为1024的倍数。</p>
</blockquote>
<p>输出描述：</p>
<blockquote>
<p>输出一个整数，表示最少需要处理的时间</p>
</blockquote>
<p>输入输出例子：  </p>
<blockquote>
<p>5<br>3072 3072 7168 3072 1024<br>9216  </p>
</blockquote>
<p><em>解题思路:</em><br>双核可以同时运行，故可以把任务分成两组，交由两个核顺序执行，最短执行时间取决于最后一个执行完成的时间，因此，两个数组长度相差越小，执行的时间也是越短的，换句话说，使其中一个数组无限接近输入数据总长度的一半sum/2即可。执行的时间为sum-sum/2。可以变为简单的背包问题：<strong>背包容量sum/2，物体重量为输入数据的长度，尽可能装满背包</strong>。状态转移方程可以记为：<code>dp[i][j] = max(dp[i-1][j], dp[i-1][j-w[i]]+w[i]), dp[i][j]表示前i个物品在体积为j时可以填充的重量。</code>  同样可以压缩数组变为一维，如上。<br>代码：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;  </span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;  </div><div class="line"><span class="keyword">int</span> dp[<span class="number">210000</span>];  </div><div class="line"><span class="keyword">int</span> n,arr[<span class="number">51</span>];  </div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </div><div class="line"></span>&#123;  </div><div class="line">    <span class="keyword">int</span> n;  </div><div class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;n);  </div><div class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;  </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; n ; i ++)&#123;  </div><div class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;arr[i]);  </div><div class="line">        arr[i] /= <span class="number">1024</span>;  </div><div class="line">        sum += arr[i];  </div><div class="line">    &#125;</div><div class="line">    <span class="built_in">memset</span>(dp, <span class="number">0</span>, <span class="keyword">sizeof</span>(dp));  </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; n ; i ++)  </div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = sum/<span class="number">2</span> ; j &gt;= arr[i] ; --j)  </div><div class="line">            dp[j] = max(dp[j],dp[j-arr[i]]+arr[i]);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,(sum-dp[sum/<span class="number">2</span>])*<span class="number">1024</span>);  </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;题目描述&lt;/strong&gt;&lt;br&gt;有 a，b，c 三个物体，&lt;br&gt;重量记为 W 5，4，3&lt;br&gt;价值记为 V 20 10 12&lt;br&gt;有一个背包容量 C = 10 ，问：可以装的最大价值为多少？  &lt;/p&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>深度解析网络用于图像语义分割</title>
    <link href="http://abumaster.com/2017/03/30/%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/03/30/深度解析网络用于图像语义分割/</id>
    <published>2017-03-30T02:20:52.000Z</published>
    <updated>2017-04-01T12:04:37.492Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>2015 年 ICCV 论文：Semantic Image Segmentation via Deep Parsing Network <sup>[1]</sup>，针对图像语义分割将丰富信息（上下文关系）并入马尔科夫随机场（MRF），取代用迭代法去优化 MRFs 提出了一种卷积网络，被称为深度解析网络（DPN），可以通过一次前向传递决定端对端的计算。</p>
</blockquote>
<a id="more"></a>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>$$E(y)=\sum_{\forall{i}\in \upsilon}\Phi({y_i^u})+\sum_{\forall{i,j}\in\varepsilon}\Psi(y_i^u,y_j^v)$$<br>主要贡献：<br>使用DPN交叉训练VGG16网络，通过一次迭代近似MF，减少计算量并且保证性能。<br><strong>MRF</strong><br>对于一副图片，看成一个无向图。边代表像素之间的联系，顶点是一个二值隐变量可以看成像素<code>i</code>是否分到标签<code>u</code>。如公式所示：<br><a href="https://www.codecogs.com/eqnedit.php?latex=$$y_u^i\in&space;\left\{0,1\right\};$$&space;$$\forall&space;u&space;\in&space;L=\left\{1,2,\dots&space;,l\right\}" target="_blank"><img src="https://latex.codecogs.com/gif.latex?$$y_u^i\in&space;\left\{0,1\right\};$$&space;$$\forall&space;u&space;\in&space;L=\left\{1,2,\dots&space;,l\right\}" title="$$y_u^i\in \left\{0,1\right\};$$ $$\forall u \in L=\left\{1,2,\dots ,l\right\}" /></a><br>能量函数可以写为：<br><a href="https://www.codecogs.com/eqnedit.php?latex=$$E(y)=\sum_{\forall{i}\in&space;\upsilon}\Phi({y_i^u})&plus;\sum_{\forall{i,j}\in\varepsilon}\Psi(y_i^u,y_j^v)$$" target="_blank"><img src="https://latex.codecogs.com/png.latex?$$E(y)=\sum_{\forall{i}\in&space;\upsilon}\Phi({y_i^u})&plus;\sum_{\forall{i,j}\in\varepsilon}\Psi(y_i^u,y_j^v)$$" title="$$E(y)=\sum_{\forall{i}\in \upsilon}\Phi({y_i^u})+\sum_{\forall{i,j}\in\varepsilon}\Psi(y_i^u,y_j^v)$$" /></a><br>\y ,\upsilon ,\varepsilon\分别代表了潜变量、顶点和边。上述能量函数分为一元项和二元项，很明显，一元项是一个预测值，表示预测像素是某一个标签，二元项则是代表一组平滑约束。<br>$$\Phi{(y_i^u)}=-\ln{p\left(y_i^u=1|I\right)}$$<br>像素i用标签u表示的可能性。<br>对于二元项是距离和共存性的乘积决定的。不可能共存，则值很大。如果两个像素临近并且相似，那么将会被鼓励分配相同的标签。这种衡量方法有两个主要的缺点：1.第一项是从训练数据中获得两个标签同时发生的频率来衡量，忽略了两个标签的空间上下文信息，比如人可以出现在桌子旁边，但是不太可能在桌子下面或者上面。<em>空间上下文是一个混合模式，不同物体的形态可能出现在不同的图片中</em>。2.只在像素间定义了成对的关系，没有考虑到高阶的相互作用。<br><img src="http://i4.buimg.com/567571/8efb4635a6ff1245.png" alt=""><br><img src="http://i2.muimg.com/567571/701622fcb0be647a.png" alt="DPN"><br><img src="http://i2.muimg.com/567571/5dd2e039380d9fbc.png" alt=""><br>不理解，先放着。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;2015 年 ICCV 论文：Semantic Image Segmentation via Deep Parsing Network &lt;sup&gt;[1]&lt;/sup&gt;，针对图像语义分割将丰富信息（上下文关系）并入马尔科夫随机场（MRF），取代用迭代法去优化 MRFs 提出了一种卷积网络，被称为深度解析网络（DPN），可以通过一次前向传递决定端对端的计算。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
  </entry>
  
  <entry>
    <title>公式专辑</title>
    <link href="http://abumaster.com/2017/03/29/%E5%85%AC%E5%BC%8F%E4%B8%93%E8%BE%91/"/>
    <id>http://abumaster.com/2017/03/29/公式专辑/</id>
    <published>2017-03-29T07:53:21.000Z</published>
    <updated>2017-04-05T07:26:41.854Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>公式的使用，论文中经常用到公式，在本地编写文章时常有 word 自带的基本上可以解决问题，当用 Markdown 书写时，又不想贴图，只好用在线的公式编辑器，一般有两种方法，一是在线生成公式，并引出外链，直接嵌入到文章中；另外一种用Mathjax引擎，引入一个脚本，在文章中编辑。</p>
</blockquote>
<a id="more"></a>
<p>###1.MathJax 引擎<br>参考<a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference">stackexchange</a>，很简单引入一个脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;</div></pre></td></tr></table></figure></p>
<p>然后编写公式一个栗子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$$\sum_&#123;i=0&#125;^n i^2 = \frac&#123;(n^2+n)(2n+1)&#125;&#123;6&#125;$$</div></pre></td></tr></table></figure></p>
<p>就生成了：<br>$$\sum_{i=0}^n i^2 = \frac{(n^2+n)(2n+1)}{6}$$<br>注意：想要在浏览器上预览，需要更改markdown priview的配置文件，运行mathjax运行。 </p>
<p>###2.在线 LaTeX 公式编辑器<br><a href="https://www.codecogs.com/latex/eqneditor.php?lang=zh-cn">在线LaTeX公式编辑器</a>，使用<a href="http://baike.baidu.com/link?url=F3CVHlrVTZL-RRSnSK6kpx0TA2a3gLRmwxiZapagZeYpTSAT9od_rx14ufa0Bvgabs3xNyrUCs1irgp5Lufui_">LaTeX</a>公式。在其中编写好公式后，直接生成了一段html代码，直接复制到 Markdown 文本中。<br>如代码:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;a href=&quot;https://www.codecogs.com/eqnedit.php?latex=$$f(x)=\sum_&#123;i=1&#125;^n&amp;space;a_i$$&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://latex.codecogs.com/gif.latex?$$f(x)=\sum_&#123;i=1&#125;^n&amp;space;a_i$$&quot; title=&quot;$$f(x)=\sum_&#123;i=1&#125;^n a_i$$&quot; /&gt;&lt;/a&gt;</div></pre></td></tr></table></figure></p>
<p>生成：<br><a href="https://www.codecogs.com/eqnedit.php?latex=$$f(x)=\sum_{i=1}^n&space;a_i$$" target="_blank"><img src="https://latex.codecogs.com/gif.latex?$$f(x)=\sum_{i=1}^n&space;a_i$$" title="$$f(x)=\sum_{i=1}^n a_i$$" /></a><br>优点：可以本地预览；缺点：只是引用的图片，右键不可操作，公式大的话可能加载慢，图片不清晰。  </p>
<p>###3.基本语法  </p>
<blockquote>
<p>无论使用哪种方式，公式的基本语法是相同的。常用的总结如下。</p>
</blockquote>
<ul>
<li><strong>公式样式</strong><br>行内公式<code>\\(公式\\)</code>，行间公式<code>$$公式$$</code>**<br>空格的表示：`\quad’表示一个quad空格  </li>
<li><strong>字符</strong><br><code>\</code>为转义符，特殊字符前要加。  </li>
<li><strong>上下标</strong><br>用<code>^</code>表示上标，用<code>_</code>表示下标  </li>
<li>字母上下标记<br>用<code>\overline{}</code>表示上划线，用<code>\underline{}</code>表示下划线；<br>用<code>\hat{}</code>表示字母上面有一个小尖角，而<code>\widehat{}</code>表示有一个大尖角;<br>用<code>\bar{} \acute{} \check{} \grave{}</code>分别表示四个声调：一声平，二声扬，三声拐弯，四声降；<br><code>\tilde{}</code>波浪线, <code>\vec{}</code>向量,<code>\dot{}</code>点。  </li>
<li>希腊字符<br><code>\alpha</code>, <code>\beta</code>, …, <code>\omega</code>: α,β,…ω；<br><code>\Gamma</code>, <code>\Delta</code>, …, <code>\Omega</code>: Γ,Δ,…,Ω。</li>
<li>数学函数<br>例如<code>sin x</code>要表示成<code>\sin x</code>；<code>log x</code>要表示成<code>\log x</code>；<code>lim x</code>表示成<code>\lim_{x\to0}</code>。</li>
<li>分数开方<br><code>\frac{ }{ }</code>分数；<code>\sqrt{n}{r}</code>表示开n次方。  </li>
<li>括号和分割符<br><code>() [] |</code>是不变的；<br><code>{}</code>要转义，写为<code>\{\}</code><br>用<code>\left 和 \right</code>调整大小。  </li>
<li>数学公式<br>求和：<code>\sum_{i=0}^n{a_i}</code><br>积分：<code>\int</code><br>例子参见<a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference">stackexchange</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;公式的使用，论文中经常用到公式，在本地编写文章时常有 word 自带的基本上可以解决问题，当用 Markdown 书写时，又不想贴图，只好用在线的公式编辑器，一般有两种方法，一是在线生成公式，并引出外链，直接嵌入到文章中；另外一种用Mathjax引擎，引入一个脚本，在文章中编辑。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>图床测试</title>
    <link href="http://abumaster.com/2017/03/29/%E5%9B%BE%E5%BA%8A%E6%B5%8B%E8%AF%95/"/>
    <id>http://abumaster.com/2017/03/29/图床测试/</id>
    <published>2017-03-29T06:20:44.000Z</published>
    <updated>2017-03-29T06:54:39.333Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p><strong>图床</strong>一般是专门用来存储图片的服务器，同时向外提供链接。国内和国外之分，本次测试的是<strong><a href="http://jiantuku.com/">极简图床</a></strong>。<br>优点：不必把图片上传到博客服务器，节省服务器的空间。<br>缺点：不能上传大于5M的图片，稳定性待测。  </p>
</blockquote>
<a id="more"></a>
<p>来一波从<a href="https://alpha.wallhaven.cc/">wallhaven</a>下载的图片<br><img src="http://i2.muimg.com/567571/45e54958a190cbaa.jpg" alt=""></p>
<hr>
<p><img src="http://i2.muimg.com/567571/792c48bc4d5f4151.jpg" alt=""></p>
<hr>
<p><img src="http://i1.piimg.com/567571/914a377ed5b3d41f.jpg" alt=""></p>
<hr>
<p><img src="http://i2.muimg.com/567571/8354836d59a379b8.jpg" alt=""></p>
<hr>
<p><img src="https://wallpapers.wallhaven.cc/wallpapers/full/wallhaven-497846.jpg" alt=""></p>
<hr>
<p><img src="http://i4.buimg.com/567571/2f18c12c56375cef.jpg" alt=""></p>
<hr>
<p><img src="http://i1.piimg.com/567571/72f7171b31ced0f7.jpg" alt=""></p>
<hr>
<p><img src="http://i2.muimg.com/567571/174cfe3e37e396fc.jpg" alt=""></p>
<hr>
<p><img src="http://i4.buimg.com/567571/83e0a892aa71f6b5.png" alt=""></p>
<hr>
<p><img src="http://i2.muimg.com/567571/5cce81a18b11621c.jpg" alt=""></p>
<hr>
<p><img src="http://i2.muimg.com/567571/8e60e0d9e66b9b6d.png" alt=""></p>
<hr>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;图床&lt;/strong&gt;一般是专门用来存储图片的服务器，同时向外提供链接。国内和国外之分，本次测试的是&lt;strong&gt;&lt;a href=&quot;http://jiantuku.com/&quot;&gt;极简图床&lt;/a&gt;&lt;/strong&gt;。&lt;br&gt;优点：不必把图片上传到博客服务器，节省服务器的空间。&lt;br&gt;缺点：不能上传大于5M的图片，稳定性待测。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>Feedforward semantic segmentation with zoom-out features</title>
    <link href="http://abumaster.com/2017/03/27/Feedforward-semantic-segmentation-with-zoom-out-features/"/>
    <id>http://abumaster.com/2017/03/27/Feedforward-semantic-segmentation-with-zoom-out-features/</id>
    <published>2017-03-27T06:21:29.000Z</published>
    <updated>2017-03-29T02:49:47.429Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>使用缩小特征的前馈语义分割 Feedforward semantic segmentation with zoom-out features 2015年CVPR论文，在PASCAL VOC 2012测试集上达到了69.9%的正确率。将小的图像元素（超像素）映射到丰富的特征表示中，这些特征是从嵌套的增加区域中获得。这些区域通过从超像素一直缩小到场景级别的分辨率获得。这种方法充分利用了图像和隐藏空间中的统计结构，而不显式设置结构化预测机制，从而避免了复杂、昂贵的推论。从而超像素是由多层前馈网络进行分类。  </p>
</blockquote>
<a id="more"></a>
<p>从大量的现代分割著作中，得到了一种被广泛接受的知识，<strong>分割可以看成一个结构化预测的任务</strong>，可以用条件随机场和结构化支持向量机模型。作者脱离传统，提出<strong>图像语义分割看作单阶段的分类任务，其中每个像素元素（超像素）被标记为一个标签，使用一个前馈模型，依据从图像计算的证据</strong>。用在前馈分类中的证据不是从孤立的局部区域中获得，而是从序列中获得，序列是怎么组成的呢？首先得到一个超像素，再向外扩展，获得一个更大的闭合区域，直到扩展到整张图片。计算每一个层次的丰富特征，结合所有特征，放入分类网络中。<br><img src="/photos/zoom-out.jpg" alt="zoom-out">  </p>
<p>###缩小的特征融合<br>将图像的类别分割转换成对一组超像素分类。由于我们期望为每个超级像素应用相同的分类机，我们希望超像素的性质是相似的，特别是它们的大小。使用了SLIC。<br><strong>本地</strong><br>超像素本身有很窄的范围，我们希望特征提取器可以捕获更多的本地信息：颜色，上下文，其他一些属性，在临近的超像素之间这些属性有很大的不同。<br><strong>近似</strong><br><strong>距离</strong><br><strong>场景</strong>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;使用缩小特征的前馈语义分割 Feedforward semantic segmentation with zoom-out features 2015年CVPR论文，在PASCAL VOC 2012测试集上达到了69.9%的正确率。将小的图像元素（超像素）映射到丰富的特征表示中，这些特征是从嵌套的增加区域中获得。这些区域通过从超像素一直缩小到场景级别的分辨率获得。这种方法充分利用了图像和隐藏空间中的统计结构，而不显式设置结构化预测机制，从而避免了复杂、昂贵的推论。从而超像素是由多层前馈网络进行分类。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
  </entry>
  
  <entry>
    <title>全卷积网络用于图像语义分割</title>
    <link href="http://abumaster.com/2017/03/25/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/03/25/全卷积网络用于图像语义分割/</id>
    <published>2017-03-25T07:31:02.000Z</published>
    <updated>2017-03-26T08:52:35.544Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>全卷积网络用于图像语义分割 (Fully Convolutional Networks for Semantic Segmentation)<sup>[1]</sup>  </p>
</blockquote>
<p>全卷积网络实际上就是把普通卷积网络的最后的全连接层变为卷积层，因为全连接层会把空间信息隐藏，全部展开为一维向量，换为卷积可以保留空间信息。如VGG-16网络在处理ImageNet数据集时，最后的1000个输出，是1000维向量，来表示1000类事物的概率，当换为卷积层时，输出了1000个1*1大小的输出，对此上采样，可以输出对应的heat-map。这是分类网络作为稠密输出的关键。<br><a id="more"></a></p>
<p><strong>文章解决的问题是如何生成稠密的预测即dense prediction</strong>  </p>
<ol>
<li><del>Shift-and-stitch</del><br>假设原图和FCN输出图之间的降采样因子<code>f</code>，对于原图的每个<code>f*f</code>区域，对于<code>0 &lt;= x,y &lt;f</code>处理这 f<sup>2</sup> 个输入，并且交替输出，使得预测在接受域的中心像素。每个像素对应一个中心像素，因此为稠密输出。缺点：感受野没变，但是原图被划分为了<code>f*f</code>大小的图像片作为输入图像，使得网络无法感受更加精细的信息。   </li>
<li>稀疏过滤器<br>调整下采样过程中的步长，变为1，可以保证下采样不会损失图像的大小。缺点：下采样的功能被减弱，同时保留了更多信息，接受域相对变小，可能损失全局信息，同样为卷积层带来了更多的运算。  </li>
<li>上采样<br>上采样（Upsampling）也称反卷积（Deconvolution），参数和卷积一样可以在训练中学习。运算也和卷积类似，为逆过程。<br>设输入大小<code>w0*h0</code>，经过卷积后的大小为<code>w1*h1</code>，计算公式如下：<br><em>卷积运算：</em><br><code>w1 = (w0 + 2*pad - kernelsize)/stride + 1</code><br><code>h1 = (h0 + 2*pad - kernelsize)/stride + 1</code><br><em>反卷积运算：</em><br><code>w0 = (w1 - 1)*stride + kernelsize - 2*pad</code><br><code>h0 = (h1 - 1)*stride + kernelsize - 2*pad</code><br>经过上采样后的图像可能会比原图大，需要裁剪为原图像大小，caffe中的crop层，提供了很好的算法。  </li>
</ol>
<p><strong>语义分割的框架结构</strong><br>文中提出的框架结构如图所示：<br><img src="/photos/fcn.png" alt="fcn"><br>作者发现32倍率的上采样导致输出图非常粗糙，因此想出了利用上层的一些特征来优化输出图像，就有了FCN-16s和FCN-8s的方案，其主要思想是利用上层的池化层的信息，减少上采样的倍率，保留了更多的特征。 </p>
<p><strong>具体的实践</strong><br>针对传统网络的全连接层变为卷积层，如VGG-16网络中第一个卷积层是<code>25088*4096</code>，将之解释为<code>512*7*7*4096</code>。产生端对端的训练模型。在论文提供的源码中，FCN-32s的配置文件，第一个卷积层为：  </p>
<pre><code>layer {
  name: &quot;conv1_1&quot;
  type: &quot;Convolution&quot;
  bottom: &quot;data&quot;
  top: &quot;conv1_1&quot;
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 100 #填充100
    kernel_size: 3
    stride: 1
  }
}
</code></pre><p>填充100的原因为：在VGG-16网络中卷积的参数，kernersize=3，stride=1，pad=1，所以卷积层不会改变图像的大小，所以图像只有在池化层改变大小，且变为原大小的一半。为了方便将图像看为一维的，设原图像大小h，经过了5层池化后，图像缩小了32倍，变为<code>h5 = h/32</code>，紧接着全连接层，可以看成是卷积层，卷积参数为：<code>kernelsize=7 pad=0 stride=1</code>，根据卷积计算公式，经过卷积层fc6后的输出图像大小为<code>h6 = (h5-7)/1 + 1 = (h-192)/32</code> 因此，图像小于192的就无法往下计算了，所以要<code>pad=100</code>，解决了网络输入图像固定大小的弊端，全卷积网络可以输入任意大小的图像。  </p>
<hr>
<p><strong>例子</strong><br>根据FCN-32s的配置文件<br>如果输入图像大小为<code>3*320*320</code><br>经过了卷积conv1的输出为：<code>64*518*518</code><br>经过了池化pool1的输出为：<code>64*259*259</code><br>经过了卷积conv2的输出为：<code>128*259*259</code><br>经过了池化pool2的输出为：<code>128*130*130</code><br>经过了卷积conv3的输出为：<code>256*130*130</code><br>经过了池化pool3的输出为：<code>256*65*65</code><br>经过了卷积conv4的输出为：<code>512*65*65</code><br>进过了池化pool4的输出为：<code>512*32*32</code><br>经过了卷积conv5的输出为：<code>512*32*32</code><br>经过了池化pool5的输出为：<code>512*16*16</code><br>经过了fc6的卷积后输出为：<code>4096*10*10</code><br>经过了fc7的卷积后输出为：<code>4096*10*10</code><br>经过score_fr的卷积输出：<code>21*10*10</code><br>上采样（反卷积）输出为：<code>21*352*352</code><br>score层裁剪后输出为：<code>21*320*320</code>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;全卷积网络用于图像语义分割 (Fully Convolutional Networks for Semantic Segmentation)&lt;sup&gt;[1]&lt;/sup&gt;  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;全卷积网络实际上就是把普通卷积网络的最后的全连接层变为卷积层，因为全连接层会把空间信息隐藏，全部展开为一维向量，换为卷积可以保留空间信息。如VGG-16网络在处理ImageNet数据集时，最后的1000个输出，是1000维向量，来表示1000类事物的概率，当换为卷积层时，输出了1000个1*1大小的输出，对此上采样，可以输出对应的heat-map。这是分类网络作为稠密输出的关键。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
  </entry>
  
  <entry>
    <title>卷积网络应该注意的问题</title>
    <link href="http://abumaster.com/2017/03/24/%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%BA%94%E8%AF%A5%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/03/24/卷积网络应该注意的问题/</id>
    <published>2017-03-24T06:28:18.000Z</published>
    <updated>2017-03-25T07:05:46.835Z</updated>
    
    <content type="html"><![CDATA[<p>卷积神经网络简介，由于其出色的特征提取特性，使得在计算机视觉方面有了很好的应用，并取得了出色的成绩。<br><strong>卷积</strong><br>卷积操作是卷积网络中的核心操作，其主要目的是为了提取图像的显著特征，降低特征维数，进而来减少计算量。在 caffe 代码中的主要参数如下：<br><a id="more"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;conv1&quot;</div><div class="line">  type: &quot;Convolution&quot;</div><div class="line">  bottom: &quot;data&quot; #上层是数据层</div><div class="line">  top: &quot;conv1&quot;</div><div class="line">  param &#123; #权重学习参数</div><div class="line">    lr_mult: 1 #权重学习率 需要乘以基础学习率base\_lr</div><div class="line">    decay_mult: 1</div><div class="line">  &#125;</div><div class="line">  param &#123; #偏置学习参数</div><div class="line">    lr_mult: 2</div><div class="line">    decay_mult: 0</div><div class="line">  &#125;</div><div class="line">  convolution_param &#123; #卷积参数</div><div class="line">    num_output: 96 #卷积操作后的输出特征图</div><div class="line">    kernel_size: 11 #卷积核大小</div><div class="line">    stride: 4 #步长 #可能也有pad为扩充边缘 </div><div class="line">    weight_filler &#123; #权值初始化</div><div class="line">      type: &quot;gaussian&quot; #类型为weight-filter 或xavier算法等，默认constant，全部0</div><div class="line">      std: 0.01</div><div class="line">    &#125;</div><div class="line">    bias_filler &#123; #偏置的初始化</div><div class="line">      type: &quot;constant&quot;</div><div class="line">      value: 0</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>输入：<code>n*c0*w0*h0</code><br>输出：<code>n*c1*w1*h2</code><br>c1对应num_output，输出对应的大小计算:<br><code>w1 = (w0 + 2*pad - kernersize)/stride + 1</code><br><code>h1 = (h0 + 2*pad - kernelsize)/stride + 1</code><br>在 <strong>caffe</strong> 源码中的计算是将图像和卷积核通过 im2col 转换成矩阵，再对两矩阵内积。 </p>
<p><strong>池化</strong><br>池化也称下采样，为了减少运算和数据维度的一种方式，被分为：  </p>
<ul>
<li>最大池化（Max Pooling），取最大值；  </li>
<li>均值池化（Mean Pooling），取均值；  </li>
<li>高斯池化。<br><strong>caffe</strong> 中的配置代码：  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;pool1&quot;</div><div class="line">  type: &quot;Pooling&quot;</div><div class="line">  bottom: &quot;norm1&quot;</div><div class="line">  top: &quot;pool1&quot;</div><div class="line">  pooling_param &#123; #池化参数</div><div class="line">    pool: MAX #池化类型</div><div class="line">    kernel_size: 3 #池化核大小</div><div class="line">    stride: 2 #步长，重叠</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>池化的计算公式与卷积操作类似：<br>输入：<code>n*c0*w0*h0</code><br>输出：<code>n*c1*w1*h2</code><br>c1对应num_output，输出对应的大小计算:<br><code>w1 = (w0 + 2*pad - kernersize)/stride + 1</code><br><code>h1 = (h0 + 2*pad - kernelsize)/stride + 1</code>  </p>
<p><strong>LRN层</strong><br>LRN全称为Local Response Normalization，即局部响应归一化层，没什么用，有一些网络中加入了这一层，对局部区域进行归一化，配置信息和参数说明如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;norm1&quot;</div><div class="line">  type: &quot;LRN&quot;</div><div class="line">  bottom: &quot;conv1&quot;</div><div class="line">  top: &quot;norm1&quot;</div><div class="line">  lrn_param &#123; #参数</div><div class="line">    local_size: 5 #（1）通道间归一化时表示求和的通道数；</div><div class="line">    #（2）通道内归一化时表示求和区间的边长；</div><div class="line">    alpha: 0.0001 #缩放因子</div><div class="line">    beta: 0.75 #指数项</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>激活函数</strong></p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>激活函数需要具有以下特性：  </p>
<ul>
<li>非线性；  </li>
<li>单调、连续可微分；  </li>
<li>范围不饱和，避免梯度为0；  </li>
<li>原点近似线性。<br>常用的激活函数有：<strong>Sigmoid 函数</strong>、<strong>Tanh 函数</strong>、<strong>ReLU 函数</strong>等。<br>如 <strong>AlexNet</strong> 中用到的ReLU激活函数：<br>$$f(x)=max(0,x)$$<br>这种激活函数的特点是：无梯度损耗，收敛速度快，网络稀疏性大，计算量小。缺点是，梯度大的话，导致权重更新以后变大，输出0，使得神经元不再更新。因此要注意学习率的设置。  </li>
</ul>
<p><strong>全连接层</strong><br>全连接层又称内积层（Inner-Product），是将特征图像全部展开为一维向量。<br><strong>caffe</strong> 中的文档显示：  </p>
<ul>
<li>Input<br><code>n * c_i * h_i * w_i</code>  </li>
<li>Output<br><code>n * c_o * 1 * 1</code><br>这里引用了<a href="http://www.cnblogs.com/dupuleng/articles/4312149.html">dupuleng</a>的例子。<br>lenet 网络配置文件中的一段：  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">layers &#123;</div><div class="line">  name: &quot;conv2&quot;</div><div class="line">  type: CONVOLUTION</div><div class="line">  bottom: &quot;pool1&quot;</div><div class="line">  top: &quot;conv2&quot;</div><div class="line">  blobs_lr: 1</div><div class="line">  blobs_lr: 2</div><div class="line">  convolution_param &#123;</div><div class="line">    num_output: 50</div><div class="line">    kernel_size: 5</div><div class="line">    stride: 1</div><div class="line">    weight_filler &#123;</div><div class="line">      type: &quot;xavier&quot;</div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: &quot;constant&quot;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">layers &#123;</div><div class="line">  name: &quot;pool2&quot;</div><div class="line">  type: POOLING</div><div class="line">  bottom: &quot;conv2&quot;</div><div class="line">  top: &quot;pool2&quot;</div><div class="line">  pooling_param &#123;</div><div class="line">    pool: MAX</div><div class="line">    kernel_size: 2</div><div class="line">    stride: 2</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">layers &#123;</div><div class="line">  name: &quot;ip1&quot;</div><div class="line">  type: INNER_PRODUCT</div><div class="line">  bottom: &quot;pool2&quot;</div><div class="line">  top: &quot;ip1&quot;</div><div class="line">  blobs_lr: 1</div><div class="line">  blobs_lr: 2</div><div class="line">  inner\_product\_param &#123;</div><div class="line">    num_output: 500</div><div class="line">    weight_filler &#123;</div><div class="line">      type: &quot;xavier&quot;</div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: &quot;constant&quot;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>conv2 的输入图像是<code>256*27*27</code>经过了卷积操作，输出<code>50*22*22</code>同样作为了pool2的输入，进行池化，pool2的输出<code>50*11*11</code>，下一层全连接层，输出<code>500*1*1</code>的向量，是如何进行计算的呢？要把所有通道全部展开做卷积，首先要把pool2输出的特征图展开为一维向量，共需要<code>500*50*11*11</code>个参数，进行卷积，输出<code>500*1*1</code>的一维向量。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;卷积神经网络简介，由于其出色的特征提取特性，使得在计算机视觉方面有了很好的应用，并取得了出色的成绩。&lt;br&gt;&lt;strong&gt;卷积&lt;/strong&gt;&lt;br&gt;卷积操作是卷积网络中的核心操作，其主要目的是为了提取图像的显著特征，降低特征维数，进而来减少计算量。在 caffe 代码中的主要参数如下：&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
</feed>
