<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张国丰</title>
  <subtitle>张国丰的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://abumaster.com/"/>
  <updated>2017-05-10T12:15:35.669Z</updated>
  <id>http://abumaster.com/</id>
  
  <author>
    <name>abumaster</name>
    <email>1902819397@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>High-performance Semantic Segmentation using VDFC</title>
    <link href="http://abumaster.com/2017/05/10/High-performance-Semantic-Segmentation-using-VDFC/"/>
    <id>http://abumaster.com/2017/05/10/High-performance-Semantic-Segmentation-using-VDFC/</id>
    <published>2017-05-10T07:37:56.000Z</published>
    <updated>2017-05-10T12:15:35.669Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>High-performance Semantic Segmentation Using Very Deep Fully Convolution [1] ，论文阅读笔记。</p>
</blockquote>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
</script>

<a id="more"></a>
<p>本文做的贡献：</p>
<ul>
<li>探索不同的<strong>全卷积残差网络</strong>找到更好的配置，诸如，网络的层数、特征图的分辨率、感受野的大小等，由于内存的限制等因素，提出了用低分辨率网络来模拟高分辨网络进行训练和测试；  </li>
<li>提出了<strong>在线引导（online booststrapping）</strong>的方法进行训练，已经论证可以达到更好的正确率；  </li>
<li>将传统的dropout应用到残差块中；  </li>
<li>达到了很好的结果。</li>
</ul>
<h4 id="1-低分辨率近似高分辨率的模型"><a href="#1-低分辨率近似高分辨率的模型" class="headerlink" title="1.低分辨率近似高分辨率的模型"></a>1.低分辨率近似高分辨率的模型</h4><p><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-10/90074102-file_1494405779021_148f4.png" alt=""><br>由于内存的限制，网络不允许输入过大分辨率的图像，但是分辨率大的图像往往可以保存更多的细节信息，可以达到更好的分割效果，所以，提出了这个低分辨率来近似高分辨率的模型。基本的做法是：如果输入一个图像，经过了中间的若干层，图像的分辨率会下降，假设缩小为原始的1/8，（1）产生了一个1/8的特征图，这时，（2）可以在上一层池化层提取出剩下1/8的图像，（3）分别获得两个1/8的得分图，（4）组合，得到1/4的得分图或者是标签。</p>
<h4 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="2.损失函数"></a>2.损失函数</h4><p>$$e=-\frac{1}{\sum _i^N \sum_j^K{1{y<em>i=j\ and\ p</em>{ij}&lt;t}}}(\sum_i^N\sum_j^K1{y<em>i=j \ and\ p</em>{ij}&lt;t}logp<em>{ij})$$<br>K表示语义标签，N表示像素的个数，$p</em>{ij}$表示像素$a_i$分到标签$c_j$的概率，$y_i$表示$a_i$的正确标签。符号$1{.}$表示满足括号里的条件为1，不满足为0。</p>
<p>[1] Wu Z, Shen C, Hengel A. High-performance semantic segmentation using very deep fully convolutional networks[J]. arXiv preprint arXiv:1604.04339, 2016.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;High-performance Semantic Segmentation Using Very Deep Fully Convolution [1] ，论文阅读笔记。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;
&lt;/script&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>宏定义</title>
    <link href="http://abumaster.com/2017/05/09/%E5%AE%8F%E5%AE%9A%E4%B9%89/"/>
    <id>http://abumaster.com/2017/05/09/宏定义/</id>
    <published>2017-05-09T12:36:26.000Z</published>
    <updated>2017-05-09T13:35:49.257Z</updated>
    
    <content type="html"><![CDATA[<p>宏定义进入编译器之前展开替换。<br><a id="more"></a><br><strong>宏常量</strong><br><code>#define MAX 100</code>用100替换符号MAX，c++中一般不推荐使用，通常用常量const定义；<br><strong>用于条件编译的宏</strong><br>如避免包含重复头文件的宏：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#ifdefine XXX </span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> XXX </span></div><div class="line"><span class="comment">//some include file</span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">`</div></pre></td></tr></table></figure></p>
<p><strong>宏函数</strong><br>避免函数调用，提高执行效率，以空间换取时间。<br>对于一些重复的函数可以声明为宏函数，就像内联函数一样…<br>例子：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(*Onefunction)</span><span class="params">()</span></span>;<span class="comment">//定义函数指针</span></div><div class="line"><span class="keyword">typedef</span> <span class="built_in">map</span>&lt;<span class="built_in">string</span>, Onefunction&gt; OneMap;<span class="comment">//名称，函数指针相关联的map</span></div><div class="line">OneMap g_one_map;<span class="comment">//全局变量保存</span></div><div class="line"></div><div class="line"><span class="comment">//注册函数的宏，其中展开为一个按名定义的类，</span></div><div class="line"><span class="comment">//构造函数,将函数地址和函数名称放入全局的map中</span></div><div class="line"><span class="comment">//最后一个简单的类对象声明，可以保证构造函数的执行，</span></div><div class="line"><span class="comment">//作用域可以保证在执行完后对象的销毁，用过即销毁。</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> RegisterOneFunction(func) \</div><div class="line">&#123; \</div><div class="line">class __Register_##func &#123; \</div><div class="line">public: \</div><div class="line">__Register_##func() &#123; \</div><div class="line">g_one_map[#func] = &amp;func; \</div><div class="line">&#125; \</div><div class="line">&#125;; \</div><div class="line">__Register_##func g_register_##func; \</div><div class="line">&#125;</span></div><div class="line"><span class="comment">//自定义的函数，无参，返回int</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">func1</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1 out...\n"</span>;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">func2</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"func2 out...222\n"</span>;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"><span class="comment">//调用宏，注册函数</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">WrapperRegisterFunction</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	RegisterOneFunction(func1);</div><div class="line">	RegisterOneFunction(func2);</div><div class="line">&#125;</div><div class="line"><span class="comment">//根据函数名称获得函数的指针</span></div><div class="line"><span class="function">Onefunction <span class="title">GetOneFunction</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; fname)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">if</span>(g_one_map.count(fname))</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">return</span> g_one_map[fname];</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">else</span></div><div class="line">	&#123;</div><div class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"not found"</span>&lt;&lt;<span class="built_in">endl</span>;</div><div class="line">		<span class="keyword">for</span>(OneMap::iterator it=g_one_map.begin();</div><div class="line">			it!=g_one_map.end(); it++)</div><div class="line">		&#123;</div><div class="line">			<span class="built_in">cout</span> &lt;&lt;it-&gt;first&lt;&lt;<span class="string">" "</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</div><div class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">string</span> funNmae;</div><div class="line"></div><div class="line">	WrapperRegisterFunction();</div><div class="line"></div><div class="line">	<span class="built_in">cin</span> &gt;&gt; funNmae;</div><div class="line">	<span class="comment">//以名称来使用函数</span></div><div class="line">	GetOneFunction(funNmae)();</div><div class="line"></div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>注意事项</strong>  </p>
<p>1.普通宏定义  </p>
<ul>
<li>宏名一般用大写  </li>
<li>使用宏可提高程序的通用性和易读性，减少不一致性，减少输入错误和便于修改  </li>
<li>预处理是在编译之前的处理，而编译工作的任务之一就是语法检查，预处理不做语法检查  </li>
<li>宏定义末尾不加分号  </li>
<li>宏定义写在函数的花括号外边，作用域为其后的程序，通常在文件的最开头  </li>
<li>可以用#undef命令终止宏定义的作用域  </li>
<li>宏定义可以嵌套   </li>
<li>字符串””中永远不包含宏  </li>
<li>宏定义不分配内存，变量定义分配内存<br>2.带参宏定义  </li>
<li>实参如果是表达式容易出问题  </li>
<li>宏名和参数的括号间不能有空格  </li>
<li>宏替换只作替换，不做计算，不做表达式求解  </li>
<li>函数调用在编译后程序运行时进行，并且分配内存。宏替换在编译前进行，不分配内存  </li>
<li>宏的哑实结合不存在类型，也没有类型转换  </li>
<li>函数只有一个返回值，利用宏则可以设法得到多个值  </li>
<li>宏展开使源程序变长，函数调用不会  </li>
<li>宏展开不占运行时间，只占编译时间，函数调用占运行时间（分配内存、保留现场、值传递、返回值）  </li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;宏定义进入编译器之前展开替换。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>caffe学习-分类</title>
    <link href="http://abumaster.com/2017/05/07/%E2%80%98caffe%E5%AD%A6%E4%B9%A0-%E5%88%86%E7%B1%BB/"/>
    <id>http://abumaster.com/2017/05/07/‘caffe学习-分类/</id>
    <published>2017-05-07T11:29:00.000Z</published>
    <updated>2017-05-08T12:39:47.386Z</updated>
    
    <content type="html"><![CDATA[<p>在用caffe的c++接口时，遇到了许多问题，学习源码中解决问题，熟悉一些细节。<br><a id="more"></a><br><strong>1.预测分类的流程图</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-8/16381803-file_1494210884331_288e.png" alt="预测流程图">  </p>
<p><strong>2.代码注释</strong><br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div></pre></td><td class="code"><pre><div class="line">//classification.cpp</div><div class="line">/*一些头文件*/</div><div class="line">#ifdef USE_OPENCV</div><div class="line">/* Pair (label, confidence) </div><div class="line"> * 代表一个预测结果，标签和概率的组合</div><div class="line"> */</div><div class="line">typedef std::pair&lt;string, float&gt; Prediction;</div><div class="line">//定义一个分类的类</div><div class="line">class Classifier &#123;</div><div class="line"> public:</div><div class="line">  Classifier(const string&amp; model_file,</div><div class="line">             const string&amp; trained_file,</div><div class="line">             const string&amp; mean_file,</div><div class="line">             const string&amp; label_file);</div><div class="line">//提供给外部的接口，返回一个预测。参数：需要预测的图像和概率最大的N个结果</div><div class="line">  std::vector&lt;Prediction&gt; Classify(const cv::Mat&amp; img, int N = 5);</div><div class="line"></div><div class="line"> private:</div><div class="line">  void SetMean(const string&amp; mean_file);//设置中值</div><div class="line">  std::vector&lt;float&gt; Predict(const cv::Mat&amp; img);</div><div class="line">  void WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels);</div><div class="line">  void Preprocess(const cv::Mat&amp; img,</div><div class="line">                  std::vector&lt;cv::Mat&gt;* input_channels);</div><div class="line"></div><div class="line"> private:</div><div class="line">  shared_ptr&lt;Net&lt;float&gt; &gt; net_;</div><div class="line">  cv::Size input_geometry_;</div><div class="line">  int num_channels_;</div><div class="line">  cv::Mat mean_;</div><div class="line">  std::vector&lt;string&gt; labels_;</div><div class="line">&#125;;</div><div class="line"></div><div class="line">Classifier::Classifier(const string&amp; model_file,</div><div class="line">                       const string&amp; trained_file,</div><div class="line">                       const string&amp; mean_file,</div><div class="line">                       const string&amp; label_file) &#123;</div><div class="line">#ifdef CPU_ONLY</div><div class="line">  Caffe::set_mode(Caffe::CPU);</div><div class="line">#else</div><div class="line">  Caffe::set_mode(Caffe::GPU);</div><div class="line">#endif</div><div class="line">  //加载网络配置并初始化</div><div class="line">  net_.reset(new Net&lt;float&gt;(model_file, TEST));</div><div class="line">  net_-&gt;CopyTrainedLayersFrom(trained_file);</div><div class="line">  CHECK_EQ(net_-&gt;num_inputs(), 1) &lt;&lt; "Network should have exactly one input.";</div><div class="line">  CHECK_EQ(net_-&gt;num_outputs(), 1) &lt;&lt; "Network should have exactly one output.";</div><div class="line">  //取出输入层的blob结构，可以提取出通道和输入图像的高宽</div><div class="line">  Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];</div><div class="line">  num_channels_ = input_layer-&gt;channels();</div><div class="line">  CHECK(num_channels_ == 3 || num_channels_ == 1)</div><div class="line">    &lt;&lt; "Input layer should have 1 or 3 channels.";</div><div class="line">  input_geometry_ = cv::Size(input_layer-&gt;width(), input_layer-&gt;height());</div><div class="line"></div><div class="line">  //加载中值文件</div><div class="line">  SetMean(mean_file);</div><div class="line"></div><div class="line">  //加载标签文件</div><div class="line">  std::ifstream labels(label_file.c_str());</div><div class="line">  CHECK(labels) &lt;&lt; "Unable to open labels file " &lt;&lt; label_file;</div><div class="line">  string line;</div><div class="line">  while (std::getline(labels, line))</div><div class="line">    labels_.push_back(string(line));</div><div class="line">  //检查标签数目和输出维度是否匹配</div><div class="line">  Blob&lt;float&gt;* output_layer = net_-&gt;output_blobs()[0];</div><div class="line">  CHECK_EQ(labels_.size(), output_layer-&gt;channels())</div><div class="line">    &lt;&lt; "Number of labels is different from the output layer dimension.";</div><div class="line">&#125;</div><div class="line">//自定义比较函数，用于排序预测结果</div><div class="line">static bool PairCompare(const std::pair&lt;float, int&gt;&amp; lhs,</div><div class="line">                        const std::pair&lt;float, int&gt;&amp; rhs) &#123;</div><div class="line">  return lhs.first &gt; rhs.first;</div><div class="line">&#125;</div><div class="line">//返回v中元素最大的N个数的下标索引</div><div class="line">static std::vector&lt;int&gt; Argmax(const std::vector&lt;float&gt;&amp; v, int N) &#123;</div><div class="line">  std::vector&lt;std::pair&lt;float, int&gt; &gt; pairs;</div><div class="line">  for (size_t i = 0; i &lt; v.size(); ++i)</div><div class="line">    pairs.push_back(std::make_pair(v[i], static_cast&lt;int&gt;(i)));</div><div class="line">  std::partial_sort(pairs.begin(), pairs.begin() + N, pairs.end(), PairCompare);</div><div class="line"></div><div class="line">  std::vector&lt;int&gt; result;</div><div class="line">  for (int i = 0; i &lt; N; ++i)</div><div class="line">    result.push_back(pairs[i].second);</div><div class="line">  return result;</div><div class="line">&#125;</div><div class="line">//输入图像，返回前N个概率最大的预测(标签，概率)</div><div class="line">std::vector&lt;Prediction&gt; Classifier::Classify(const cv::Mat&amp; img, int N) &#123;</div><div class="line">  std::vector&lt;float&gt; output = Predict(img);</div><div class="line"></div><div class="line">  N = std::min&lt;int&gt;(labels_.size(), N);</div><div class="line">  std::vector&lt;int&gt; maxN = Argmax(output, N);</div><div class="line">  std::vector&lt;Prediction&gt; predictions;</div><div class="line">  for (int i = 0; i &lt; N; ++i) &#123;</div><div class="line">    int idx = maxN[i];</div><div class="line">    predictions.push_back(std::make_pair(labels_[idx], output[idx]));</div><div class="line">  &#125;</div><div class="line">  return predictions;</div><div class="line">&#125;</div><div class="line"></div><div class="line">/* Load the mean file in binaryproto format. */</div><div class="line">void Classifier::SetMean(const string&amp; mean_file) &#123;</div><div class="line">  BlobProto blob_proto;</div><div class="line">  ReadProtoFromBinaryFileOrDie(mean_file.c_str(), &amp;blob_proto);</div><div class="line"></div><div class="line">  /* Convert from BlobProto to Blob&lt;float&gt; */</div><div class="line">  Blob&lt;float&gt; mean_blob;</div><div class="line">  mean_blob.FromProto(blob_proto);</div><div class="line">  CHECK_EQ(mean_blob.channels(), num_channels_)</div><div class="line">    &lt;&lt; "Number of channels of mean file doesn't match input layer.";</div><div class="line"></div><div class="line">  /* The format of the mean file is planar 32-bit float BGR or grayscale. */</div><div class="line">  std::vector&lt;cv::Mat&gt; channels;</div><div class="line">  float* data = mean_blob.mutable_cpu_data();</div><div class="line">  for (int i = 0; i &lt; num_channels_; ++i) &#123;</div><div class="line">    /* Extract an individual channel. */</div><div class="line">    cv::Mat channel(mean_blob.height(), mean_blob.width(), CV_32FC1, data);</div><div class="line">    channels.push_back(channel);</div><div class="line">    data += mean_blob.height() * mean_blob.width();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  /* Merge the separate channels into a single image. */</div><div class="line">  cv::Mat mean;</div><div class="line">  cv::merge(channels, mean);</div><div class="line"></div><div class="line">  /* Compute the global mean pixel value and create a mean image</div><div class="line">   * filled with this value. */</div><div class="line">  cv::Scalar channel_mean = cv::mean(mean);</div><div class="line">  mean_ = cv::Mat(input_geometry_, mean.type(), channel_mean);</div><div class="line">&#125;</div><div class="line">//预测函数，返回输出的概率</div><div class="line">std::vector&lt;float&gt; Classifier::Predict(const cv::Mat&amp; img) &#123;</div><div class="line">  Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];</div><div class="line">  input_layer-&gt;Reshape(1, num_channels_,</div><div class="line">                       input_geometry_.height, input_geometry_.width);</div><div class="line">  /* Forward dimension change to all layers. */</div><div class="line">  net_-&gt;Reshape();</div><div class="line"></div><div class="line">  std::vector&lt;cv::Mat&gt; input_channels;</div><div class="line">  WrapInputLayer(&amp;input_channels);</div><div class="line"></div><div class="line">  Preprocess(img, &amp;input_channels);</div><div class="line"></div><div class="line">  net_-&gt;Forward();</div><div class="line"></div><div class="line">  /* Copy the output layer to a std::vector */</div><div class="line">  Blob&lt;float&gt;* output_layer = net_-&gt;output_blobs()[0];</div><div class="line">  const float* begin = output_layer-&gt;cpu_data();</div><div class="line">  const float* end = begin + output_layer-&gt;channels();</div><div class="line">  return std::vector&lt;float&gt;(begin, end);</div><div class="line">&#125;</div><div class="line"> /* 包装网络的输入层，将每个通道保存为Mat对象，</div><div class="line">  * 最后直接将分割的通道写入到输入层中 */</div><div class="line">void Classifier::WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels) &#123;</div><div class="line">  Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];</div><div class="line"></div><div class="line">  int width = input_layer-&gt;width();</div><div class="line">  int height = input_layer-&gt;height();</div><div class="line">  //获取可更改的输入层数据指针</div><div class="line">  float* input_data = input_layer-&gt;mutable_cpu_data();</div><div class="line">  for (int i = 0; i &lt; input_layer-&gt;channels(); ++i) &#123;</div><div class="line">    cv::Mat channel(height, width, CV_32FC1, input_data);</div><div class="line">    input_channels-&gt;push_back(channel);</div><div class="line">    input_data += width * height;</div><div class="line">  &#125;//将各个通道变为Mat，依次放入vector中</div><div class="line">&#125;</div><div class="line">//图像拷贝入输入层中</div><div class="line">void Classifier::Preprocess(const cv::Mat&amp; img,</div><div class="line">                            std::vector&lt;cv::Mat&gt;* input_channels) &#123;</div><div class="line">  /* 将输入图像转换为网络要求的输入格式 */</div><div class="line">  //通道数</div><div class="line">  cv::Mat sample;</div><div class="line">  if (img.channels() == 3 &amp;&amp; num_channels_ == 1)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_BGR2GRAY);</div><div class="line">  else if (img.channels() == 4 &amp;&amp; num_channels_ == 1)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_BGRA2GRAY);</div><div class="line">  else if (img.channels() == 4 &amp;&amp; num_channels_ == 3)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_BGRA2BGR);</div><div class="line">  else if (img.channels() == 1 &amp;&amp; num_channels_ == 3)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_GRAY2BGR);</div><div class="line">  else</div><div class="line">    sample = img;</div><div class="line">  //大小</div><div class="line">  cv::Mat sample_resized;</div><div class="line">  if (sample.size() != input_geometry_)</div><div class="line">    cv::resize(sample, sample_resized, input_geometry_);</div><div class="line">  else</div><div class="line">    sample_resized = sample;</div><div class="line">  //浮点数</div><div class="line">  cv::Mat sample_float;</div><div class="line">  if (num_channels_ == 3)</div><div class="line">    sample_resized.convertTo(sample_float, CV_32FC3);</div><div class="line">  else</div><div class="line">    sample_resized.convertTo(sample_float, CV_32FC1);</div><div class="line">  //归一化处理：减去中值</div><div class="line">  cv::Mat sample_normalized;</div><div class="line">  cv::subtract(sample_float, mean_, sample_normalized);</div><div class="line">  //直接将mat拷贝到输入层，已经处理过输入层为Mat对象了</div><div class="line">  cv::split(sample_normalized, *input_channels);</div><div class="line">  CHECK(reinterpret_cast&lt;float*&gt;(input_channels-&gt;at(0).data)</div><div class="line">        == net_-&gt;input_blobs()[0]-&gt;cpu_data())</div><div class="line">    &lt;&lt; "Input channels are not wrapping the input layer of the network.";</div><div class="line">&#125;</div><div class="line">//主函数命令行调用</div><div class="line">int main(int argc, char** argv) &#123;</div><div class="line">  if (argc != 6) &#123;</div><div class="line">    std::cerr &lt;&lt; "Usage: " &lt;&lt; argv[0]</div><div class="line">              &lt;&lt; " deploy.prototxt network.caffemodel"</div><div class="line">              &lt;&lt; " mean.binaryproto labels.txt img.jpg" &lt;&lt; std::endl;</div><div class="line">    return 1;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  ::google::InitGoogleLogging(argv[0]);</div><div class="line"></div><div class="line">  string model_file   = argv[1];</div><div class="line">  string trained_file = argv[2];</div><div class="line">  string mean_file    = argv[3];</div><div class="line">  string label_file   = argv[4];</div><div class="line">  Classifier classifier(model_file, trained_file, mean_file, label_file);</div><div class="line"></div><div class="line">  string file = argv[5];</div><div class="line"></div><div class="line">  std::cout &lt;&lt; "---------- Prediction for "</div><div class="line">            &lt;&lt; file &lt;&lt; " ----------" &lt;&lt; std::endl;</div><div class="line"></div><div class="line">  cv::Mat img = cv::imread(file, -1);</div><div class="line">  CHECK(!img.empty()) &lt;&lt; "Unable to decode image " &lt;&lt; file;</div><div class="line">  std::vector&lt;Prediction&gt; predictions = classifier.Classify(img);</div><div class="line"></div><div class="line">  /* Print the top N predictions. */</div><div class="line">  for (size_t i = 0; i &lt; predictions.size(); ++i) &#123;</div><div class="line">    Prediction p = predictions[i];</div><div class="line">    std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(4) &lt;&lt; p.second &lt;&lt; " - \""</div><div class="line">              &lt;&lt; p.first &lt;&lt; "\"" &lt;&lt; std::endl;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">#else</div><div class="line">int main(int argc, char** argv) &#123;</div><div class="line">  LOG(FATAL) &lt;&lt; "This example requires OpenCV; compile with USE_OPENCV.";</div><div class="line">&#125;</div><div class="line">#endif  // USE_OPENCV</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在用caffe的c++接口时，遇到了许多问题，学习源码中解决问题，熟悉一些细节。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Caffe笔记</title>
    <link href="http://abumaster.com/2017/05/01/Caffe%E7%AC%94%E8%AE%B0/"/>
    <id>http://abumaster.com/2017/05/01/Caffe笔记/</id>
    <published>2017-05-01T06:41:52.000Z</published>
    <updated>2017-05-01T12:02:51.565Z</updated>
    
    <content type="html"><![CDATA[<p>Caffe学习中的遇到的一些问题拾遗。<br><a id="more"></a><br><strong>1..solverstate的使用</strong><br>在网络训练过程中当保存一个快照时，会保存两个文件：<code>**.caffemodel</code> 和 <code>**.solverstate</code> 第一个文件是训练过程中，迭代了N次，保存的模型，第二个文件是训练过程意外暂停，如<code>ctrl+C</code> 或者电脑死机，保存的网络状态，下一次网络可以接着训练，参考<a href="https://github.com/BVLC/caffe/wiki/Training-and-Resuming">Caffe Wiki - Training and Resuming</a>。<br>使用：  </p>
<ul>
<li>命令行<br>训练：<code>caffe train -solver solver.prototxt</code><br>状态中恢复训练：<code>caffe train -solver solver.prototxt -snapshot train_190000.solverstate</code>  </li>
<li>Python 接口<br>从模型中copy参数：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">weights = <span class="string">'../ilsvrc-nets/vgg16-fcn.caffemodel'</span></div><div class="line"><span class="comment"># init</span></div><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)</div><div class="line">solver.net.copy_from(weights)</div></pre></td></tr></table></figure>
</li>
</ul>
<p>从状态中恢复训练：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)</div><div class="line">solver.restore(<span class="string">'snapshot/train_iter_2000.solverstate'</span>)</div></pre></td></tr></table></figure></p>
<p>这时不需要copy参数了。  </p>
<p><strong>2.编写网络配置文件</strong><br>通常创建一个创建一个 solver 来表示网络的参数信息，包括：迭代次数，训练策略以及保存快照等。其中包含了一个训练网络模型定义和一个测试网络模型定义文件，也可以写在一个配置文件中，当写在一个文件中的时候，要在网络的不同之处加上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">include &#123;</div><div class="line">    phase: TEST (TRAIN)</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p><strong>3.网络运行过程</strong>  </p>
<ul>
<li>加载 solver 有两种方式（Python 接口）：<br><code>solver = caffe.get_solver(&#39;models/bvlc_reference_caffenet/solver.prototxt&#39;)</code> 和<br><code>solver = caffe.SGDSolver(&#39;models/bvlc_reference_caffenet/solver.prototxt&#39;)</code>  </li>
<li>开始训练：  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">solver.net.forward()  <span class="comment"># train net</span></div><div class="line">solver.test_nets[<span class="number">0</span>].forward()  <span class="comment"># test net (there can be more than one)</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>这是一次从输入层到损失层的计算过程，最后计算出loss，反向传播时，可以写为：<code>solver.net.backward()</code>，这是计算从损失层到输入层的梯度，并更新网络中各层的参数信息。前向传播和反向传播可以合并写，表示一次完整的计算：<code>solver.step(1)</code>。如果要按照配置文件中的最大迭代次数运行网络，则写为：<code>solver.solve()</code>。  </p>
<p><strong>4.验证模型正确率</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">accuracy = <span class="number">0</span></div><div class="line">batch_size = solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'data'</span>].num <span class="comment">#训练批次</span></div><div class="line">test_iters = int(len(Xt) / batch_size) <span class="comment">#迭代次数</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(test_iters):</div><div class="line">    solver.test_nets[<span class="number">0</span>].forward() <span class="comment">#测试网络</span></div><div class="line">    accuracy += solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'accuracy'</span>].data <span class="comment">#相加每次迭代的正确率</span></div><div class="line">accuracy /= test_iters <span class="comment">#平均正确率</span></div><div class="line">print(<span class="string">"Accuracy: &#123;:.3f&#125;"</span>.format(accuracy))</div></pre></td></tr></table></figure></p>
<p><strong>5.定义自己的Python层</strong><br>Python层通常用来对输入数据进行预处理，如在图像语义分割中，输入为Python层，用于读取训练图像和分割图像。<br>自定义Python层是，需在prototxt文件中指明层的类型为python并且指明需要的函数，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">'MyPythonLayer'</span></div><div class="line">  type: <span class="string">'Python'</span></div><div class="line">  top: <span class="string">'output'</span></div><div class="line">  bottom: <span class="string">'conv'</span></div><div class="line">  python_param &#123;</div><div class="line">    module: <span class="string">'mypythonlayer'</span></div><div class="line">    layer: <span class="string">'MyLayer'</span></div><div class="line">    param_str: <span class="string">"'num': 21"</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>然后，需要按以下格式定义自己的Python文件，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> yaml</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span><span class="params">(caffe.Layer)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup</span><span class="params">(self, bottom, top)</span>:</span></div><div class="line">        self.num = yaml.load(self.param_str)[<span class="string">"num"</span>]</div><div class="line">        <span class="keyword">print</span> <span class="string">"Parameter num : "</span>, self.num</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reshape</span><span class="params">(self, bottom, top)</span>:</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, bottom, top)</span>:</span> <span class="comment">#前传</span></div><div class="line">        top[<span class="number">0</span>].reshape(*bottom[<span class="number">0</span>].shape)</div><div class="line">        top[<span class="number">0</span>].data[...] = bottom[<span class="number">0</span>].data + self.num</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, top, propagate_down, bottom)</span>:</span></div><div class="line">        <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<p>使用时还与普通网络调用一样进行，只是会直接用python定义的层完成输入数据的重新组织，再进行传递。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Caffe学习中的遇到的一些问题拾遗。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>尺度感知模型</title>
    <link href="http://abumaster.com/2017/04/25/%E5%B0%BA%E5%BA%A6%E6%84%9F%E7%9F%A5%E6%A8%A1%E5%9E%8B/"/>
    <id>http://abumaster.com/2017/04/25/尺度感知模型/</id>
    <published>2017-04-25T07:02:25.000Z</published>
    <updated>2017-04-25T11:44:08.513Z</updated>
    
    <content type="html"><![CDATA[<p>来自 2016 年 ICCV 论文：Attention to Scale: Scale-aware Semantic Image Segmentation，注意尺度：尺度敏感图像语义分割。在全卷积网络中合并多尺度特征已经是提高图像语义分割效果的一个关键因素。通过不同图像尺寸的输入，提取出不同尺度的信息，通过一个注意力模型获得权重融合特征图，最终得到分割图像。<br><a id="more"></a><br><strong>1.注意力模型 Attention model</strong><br>Attention model(AM)最先在计算机视觉中被应用于图片识别的问题，之后在自然语言处理(NLP)和计算机视觉(CV)中经常结合递归神经网络结构RNN、GRU、LSTM等深度学习算法，被称之为Recurrent Attention Model(RAM)，其核心就是一个Encoder-Decoder的过程。图像识别中，经常把图像缩放成固定大小，引起信息的丢失，结合人看物体时，目光会沿着感兴趣的方向移动，甚至聚焦感兴趣的区域，Attention（注意力）就是在网络中加入关注区域的移动、缩放机制、连续部分信息序列化输入。<a href="https://www.zhihu.com/question/36591394">知乎问题回答</a>。可以分为两种模型：  </p>
<ul>
<li>hard：Attention 每次移动固定大小区域；  </li>
<li>soft：Attention 每次是所有区域的一个加权和。<br><strong>注意力</strong>，人看一副图像不是按像素点去看的，往往是一个区域一个区域看的，关注感兴趣区域（Region of Interest），Attention 可以自动寻找感兴趣的区域？强化学习。<br><strong>2.如何利用多尺度信息</strong><br>在 FCNs 场景下，有两种方式利用多尺度信息，如图所示：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-25/98403353-file_1493107872063_3e36.png" alt="">  </li>
<li>利用网络中间层信息，由于随着网络层数的增加，图像不断缩小，图像的特征也会不断地丢失，在经典的FCN-8s网络中提出了融合中间层的特征图，优化最后的分割结果；  </li>
<li>多尺度图像输入，网络共享权重，不同尺度会产生不同大小的特征图，每个尺度的特征图关注点也不同，通过在最后对不同尺度特征图的融合，产生最终的分割结果。<br><strong>3.模型介绍</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-25/24866344-file_1493107637433_24f2.png" alt="model"><br>模型如何运作？<br>不同尺度图像输入 FCNs 中会生成不同的热力图（得分图），然后，如何融合不同的得分图，论文中提出了一个<em>注意力模型</em>，对于每个尺度特征图输出一个权重图，权重是如何生成的呢，通过学习，对于大物体在褚略的特征图上置为较大的权重。有了权重图，结合特征图，很容易加权融合多个尺度特征图，得到最后的输出。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-25/73523202-file_1493108587550_a9.png" alt=""><br>每个尺度，对应着一个score map，这里乘以由尺度获得的权重图，得到最终的输出图。权重是由注意力模型产生的score map的所占比重决定的，表示摸个尺度的重要性。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;来自 2016 年 ICCV 论文：Attention to Scale: Scale-aware Semantic Image Segmentation，注意尺度：尺度敏感图像语义分割。在全卷积网络中合并多尺度特征已经是提高图像语义分割效果的一个关键因素。通过不同图像尺寸的输入，提取出不同尺度的信息，通过一个注意力模型获得权重融合特征图，最终得到分割图像。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>零散</title>
    <link href="http://abumaster.com/2017/04/19/%E9%9B%B6%E6%95%A3/"/>
    <id>http://abumaster.com/2017/04/19/零散/</id>
    <published>2017-04-19T06:25:45.000Z</published>
    <updated>2017-05-10T12:15:14.661Z</updated>
    
    <content type="html"><![CDATA[<a id="more"></a>
<p>图像分类：<br>Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.<br>Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.<br>Papandreou G, Kokkinos I, Savalle P A. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 390-399.  </p>
<p>物体检测：<br>Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 580-587.<br>Erhan D, Szegedy C, Toshev A, et al. Scalable object detection using deep neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014: 2147-2154.<br>Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems. 2015: 91-99.<br>He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 770-778.  </p>
<p><strong>CNN用于图像分割</strong><br>Schulz H, Behnke S. Learning Object-Class Segmentation with Convolutional Neural Networks[C]//ESANN. 2012.<br>Farabet C, Couprie C, Najman L, et al. Scene parsing with multiscale feature learning, purity trees, and optimal covers[J]. arXiv preprint arXiv:1202.2160, 2012.<br>Farabet C, Couprie C, Najman L, et al. Learning hierarchical features for scene labeling[J]. IEEE transactions on pattern analysis and machine intelligence, 2013, 35(8): 1915-1929.<br>Dai J, He K, Sun J. Convolutional feature masking for joint object and stuff segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3992-4000.</p>
<p>Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.  </p>
<p>刘丹,刘学军,王美珍. 一种多尺度CNN的图像语义分割算法[J]. 遥感信息,2017,(01):57-64.<br>蒋应锋,张桦,薛彦兵,周冕,徐光平,高赞. 一种新的多尺度深度学习图像语义理解方法研究[J]. 光电子·激光,2016,(02):224-230.  </p>
<p>Mostajabi M, Yadollahpour P, Shakhnarovich G. Feedforward semantic segmentation with zoom-out features[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3376-3385.<br>Lin G, Shen C, van den Hengel A, et al. Efficient piecewise training of deep structured models for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 3194-3203.  </p>
]]></content>
    
    <summary type="html">
    
      &lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;图像分类：&lt;br&gt;Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Adv
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>Caffe的C++接口调用</title>
    <link href="http://abumaster.com/2017/04/18/Caffe%E7%9A%84C-%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"/>
    <id>http://abumaster.com/2017/04/18/Caffe的C-接口调用/</id>
    <published>2017-04-18T12:25:06.000Z</published>
    <updated>2017-04-18T13:20:27.571Z</updated>
    
    <content type="html"><![CDATA[<p>Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。<br><a id="more"></a></p>
<h2 id="1-配置第三方库"><a href="#1-配置第三方库" class="headerlink" title="1.配置第三方库"></a>1.配置第三方库</h2><p>Windows上运行的是官方的 Caffe-Windows 项目，第三方库是从别人打包好的下载，主要分为几大类：boost、gflags、glog、hdf5、LevelDB、lmdb、OpenBLAS、OpenCV、protobuf。配置内容包括（调试器最好配置Release版本的x64平台）：<br><strong>头文件</strong><br>新建一个工程，打开项目-&gt;工程属性页，C/C++ -&gt; 常规 -&gt; 附加包含目录，添加caffe相关的头文件,caffe及第三方依赖库，我的如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">D:\caffeDev\caffe-master\include;D:\caffeDev\NugetPackages\boost.1.59.0.0\lib\native\include;D:\caffeDev\NugetPackages\OpenCV.2.4.10\build\native\include;D:\caffeDev\NugetPackages\gflags.2.1.2.1\build\native\include;D:\caffeDev\NugetPackages\glog.0.3.3.0\build\native\include;D:\caffeDev\NugetPackages\hdf5-v120-complete.1.8.15.2\lib\native\include;D:\caffeDev\NugetPackages\lmdb-v120-clean.0.9.14.0\lib\native\include;D:\caffeDev\NugetPackages\protobuf-v120.2.6.1\build\native\include;D:\caffeDev\NugetPackages\OpenBLAS.0.2.14.1\lib\native\include;</div></pre></td></tr></table></figure></p>
<p><strong>附加库目录</strong><br>链接器 -&gt; 常规 -&gt; 附加库目录 ，添加内容为lib库所在的目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;AdditionalLibraryDirectories&gt;D:\caffeDev\NugetPackages\glog.0.3.3.0\build\native\lib\x64\v120\Release\dynamic;D:\caffeDev\caffe-master\Build\x64\Release;D:\caffeDev\NugetPackages\OpenCV.2.4.10\build\native\lib\x64\v120\Release;D:\caffeDev\NugetPackages\boost_date_time-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_filesystem-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_system-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\protobuf-v120.2.6.1\build\native\lib\x64\v120\Release;D:\caffeDev\NugetPackages\boost_thread-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_chrono-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\hdf5-v120-complete.1.8.15.2\lib\native\lib\x64;D:\caffeDev\NugetPackages\gflags.2.1.2.1\build\native\x64\v120\dynamic\Lib;D:\caffeDev\NugetPackages\OpenBLAS.0.2.14.1\lib\native\lib\x64;%(AdditionalLibraryDirectories)&lt;/AdditionalLibraryDirectories&gt;</div></pre></td></tr></table></figure></p>
<p><strong>依赖项</strong><br>输入 -&gt; 附加依赖项，中填写需要的链接库，为上述目录中的链接库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;AdditionalDependencies&gt;</div><div class="line">opencv_calib3d2410.lib;</div><div class="line">opencv_contrib2410.lib;</div><div class="line">opencv_core2410.lib;</div><div class="line">opencv_features2d2410.lib;</div><div class="line">opencv_flann2410.lib;</div><div class="line">opencv_gpu2410.lib;</div><div class="line">opencv_highgui2410.lib;</div><div class="line">opencv_imgproc2410.lib;</div><div class="line">opencv_legacy2410.lib;</div><div class="line">opencv_ml2410.lib;</div><div class="line">opencv_nonfree2410.lib;</div><div class="line">opencv_objdetect2410.lib;</div><div class="line">opencv_ocl2410.lib;</div><div class="line">opencv_photo2410.lib;</div><div class="line">opencv_stitching2410.lib;</div><div class="line">opencv_superres2410.lib;</div><div class="line">opencv_ts2410.lib;</div><div class="line">opencv_video2410.lib;</div><div class="line">opencv_videostab2410.lib;</div><div class="line">libglog.lib;</div><div class="line">caffe.lib;</div><div class="line">libprotobuf.lib;</div><div class="line">libcaffe.lib;</div><div class="line">gflags.lib;</div><div class="line">gflags_nothreads.lib;</div><div class="line">hdf5.lib;</div><div class="line">hdf5_cpp.lib;</div><div class="line">hdf5_f90cstub.lib;</div><div class="line">hdf5_fortran.lib;</div><div class="line">hdf5_hl.lib;</div><div class="line">hdf5_hl_cpp.lib;</div><div class="line">hdf5_hl_f90cstub.lib;</div><div class="line">hdf5_hl_fortran.lib;</div><div class="line">hdf5_tools.lib;</div><div class="line">szip.lib;</div><div class="line">zlib.lib;</div><div class="line">libopenblas.dll.a;</div><div class="line">%(AdditionalDependencies)</div><div class="line">&lt;/AdditionalDependencies&gt;</div></pre></td></tr></table></figure></p>
<h2 id="2-运行时问题"><a href="#2-运行时问题" class="headerlink" title="2.运行时问题"></a>2.运行时问题</h2><p>实际新建一个项目（从caffe工程中拷的源码，配置好一切环境），可以编译成功，但是运行时出现问题：<br><strong>F0519 14:54:12.494139 14504 layer_factory.hpp:77] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Input (known types: Input )</strong><br>一者说，只有在caffe解决方案中新建项目，才可以正常运行<a href="https://github.com/Microsoft/caffe/issues/45">问题</a>。还有利用别人改进的caffe来减少外部的依赖关系，<a href="https://github.com/dtmoodie/caffe">dtmoodie</a>。<br>另外一种，<a href="http://blog.csdn.net/fangjin_kl/article/details/50936952#0-tsina-1-63793-397232819ff9a47a7b7e80a40613cfe1">解决方法</a>主要解决方案是将caffe中的各层都放进一个头文件中包含进工程中，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/common.hpp"</span>  </span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/input_layer.hpp"</span></span></div><div class="line"><span class="function"><span class="keyword">extern</span> <span class="title">INSTANTIATE_CLASS</span><span class="params">(InputLayer)</span></span>;<span class="comment">//添加层信息</span></div><div class="line">REGISTER_LAYER_CLASS(Input);<span class="comment">//注册层信息</span></div></pre></td></tr></table></figure></p>
<p>可以完美运行了。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>高效分片训练结构化模型用于图像语义分割</title>
    <link href="http://abumaster.com/2017/04/17/%E9%AB%98%E6%95%88%E5%88%86%E7%89%87%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%84%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/17/高效分片训练结构化模型用于图像语义分割/</id>
    <published>2017-04-17T08:58:15.000Z</published>
    <updated>2017-04-18T02:13:45.979Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic<br>Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。  </p>
</blockquote>
<a id="more"></a>
<p><strong>特点：</strong>  </p>
<ol>
<li>制定了基于CNN的在CRFs上总体分段潜在函数模型用于衡量语义图像片之间的关系；  </li>
<li>分段训练CRFs，避免重复推导，提高速度；  </li>
<li>多尺度图像输入，用于探索图像背景和前景上下文信息；  </li>
</ol>
<hr>
<p><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/28980161-file_1492432013053_14485.png" alt=""><br>Featmap-Net是一个卷积网络，用于输出特征图，低分辨率的特征图；<br>创建CRF图，首先对于卷积网络生成的特征图，创建一些边界框，在边界框内被认为空间近似，顶点才会全连接，不同空间会创建不同的边界框。  </p>
<p><strong>上下文深度CRFs</strong><br>分为一元组的图的顶点和二元组的图的边，分别对应一个能量函数，通过一元和二元网络对应生成了类别的预测。<br><strong>利用背景上下文</strong><br>产生特征图的网络：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-18/67947492-file_1492479486028_4096.png" alt=""></p>
<p>首先将输入图像缩放为三个不同的大小，放入网络，共享权重。图像缩放大小为1.2,0.8,0.4，再经过一层独立的卷积产生多尺度特征图，然后经过滑动金字塔池化产生了组合的特征图，金字塔池化如下图所示：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-18/81267394-file_1492479935056_11ffe.png" alt=""><br>使用双线性上采样和简单的边界优化对粗糙的预测结果进行后期处理，可能又更复杂的优化方式，比如：训练反卷积网络，训练复杂的从粗糙到精细的网络，利用中间特征图到高分辨率的预测。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic&lt;br&gt;Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>拉普拉斯重建和细化用于图像语义分割</title>
    <link href="http://abumaster.com/2017/04/16/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%8D%E5%BB%BA%E5%92%8C%E7%BB%86%E5%8C%96%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/16/拉普拉斯重建和细化用于图像语义分割/</id>
    <published>2017-04-16T08:05:56.000Z</published>
    <updated>2017-04-17T07:21:41.177Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。  </p>
</blockquote>
<a id="more"></a>
<p><em>空间语义不确定性原则</em>，探索在CNN特征层次结构中的空间和语义正确性。网络的顶层图像语义预测准确，但是带来的缺陷是在低分辨率下的图像空间上的定位，边界清晰但是标签有噪声。提出了一种重建模型在给定层次上提高空间定位的准确性，和一种细化技术用来融合多层的信息来优化图像的语义分割结果。<br>与传统FCN的区别：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-16/29818085-file_1492332368566_59f2.png" alt=""><br>不同之处在于，上采样和重建。<br><strong>CNN 特征图固有的缺少空间细节信息</strong>用一些不同的方法可以解决，如条件随机场、超像素、边界检测。还有一些成对的特征映射，可以进行反向传播进行训练。此论文的方法是<strong>直接提高输出激活图空间分辨率</strong>。<br><strong>双线性上采样是从低分辨率特征图中计算出高分辨率分割图的一种标准方法</strong>，首先卷积网络从特征图中计算出低分辨率的得分图，然后使用线性过滤器上采样为高分辨率的得分图。这种方法<em>可能会从多通道低分辨率特征图中丢失定位信息</em>。为了保留更多的空间信息，论文避免了将高维特征图折叠成低分辨率的类别预测。取而代之的是利用高分辨率基函数的线性组合对高分辨率的分类得分图的空间模式进行编码，这些函数的权重被高维特征图预测得到。实现：将高分辨率的特征图分成不重叠的图像块，大小取决于网络中池化层的个数次幂，通过一个卷积网络预测从高纬度低分辨率到特征图像块的映射。这些特征图像块和类别系数与一个基本函数集合相乘，再与一个基本的去卷积层相加，得到期望的全分辨率类别图。<br><strong>连接样条插值</strong><br>更高阶的样条插值替代上采样。<br><strong>学习基本函数</strong><br><strong>基本结构</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/25758666-file_1492397377051_a8d3.png" alt=""><br>首先，网络从上到下，分辨率越来越小。在每一次缩小时，特征图重建，再进行组合，产生对应倍数特征图的分割得分图，上图的水平方向，通过组合不同倍数的得分图。<br>一种从高分辨率中减去低频成分的方法，边界masking，孤立出边界成分。<br>金字塔的应用：<br>下层分割图得分上采样作为上一层采样的参考，用于得分图和像素对的产生。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/99567344-file_1492411678446_ecd2.png" alt=""><br><strong>Conclusion</strong>  </p>
<ul>
<li>以特定类重建为基础作为上采样；  </li>
<li>合成低分辨率的语义丰富的特征图和拥有更多空间特性的高分辨率特征图，多层拉普拉斯金字塔重建结构。  </li>
<li>最后可以加上CRF进行后期处理，优化结果。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>网易2017春招笔试编程题</title>
    <link href="http://abumaster.com/2017/04/14/%E7%BD%91%E6%98%932017%E6%98%A5%E6%8B%9B%E7%AC%94%E8%AF%95%E7%BC%96%E7%A8%8B%E9%A2%98/"/>
    <id>http://abumaster.com/2017/04/14/网易2017春招笔试编程题/</id>
    <published>2017-04-14T06:14:18.000Z</published>
    <updated>2017-04-14T06:45:55.647Z</updated>
    
    <content type="html"><![CDATA[<p><strong>感悟</strong>：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。<br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;感悟&lt;/strong&gt;：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="算法" scheme="http://abumaster.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>FCN图像语义分割计算的细节问题</title>
    <link href="http://abumaster.com/2017/04/11/FCN%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AE%A1%E7%AE%97%E7%9A%84%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/04/11/FCN图像语义分割计算的细节问题/</id>
    <published>2017-04-11T08:59:57.000Z</published>
    <updated>2017-04-12T01:09:31.691Z</updated>
    
    <content type="html"><![CDATA[<p>Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。<br><a id="more"></a><br>从论文中地址中，下载<a href="https://github.com/shelhamer/fcn.berkeleyvision.org">FCN</a>源码到本地。<br><strong>1.使用现有模型进行图像语义分割</strong><br>解压源代码，在根目录下，有一个infer.py的文件，打开，配置自己的模型路径，运行即可。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="comment"># load image, switch to BGR, subtract mean, and make dims C x H x W for Caffe</span></div><div class="line">im = Image.open(<span class="string">'voc-fcn8s/21.jpg'</span>)</div><div class="line">in_ = np.array(im, dtype=np.float32)</div><div class="line">in_ = in_[:,:,::<span class="number">-1</span>]</div><div class="line"><span class="comment">#in_ -= np.array((104.00698793,116.66876762,122.67891434))</span></div><div class="line">in_ -= np.array((<span class="number">106.08069</span>,<span class="number">103.75618</span>,<span class="number">100.05657</span>))</div><div class="line">in_ = in_.transpose((<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</div><div class="line"><span class="comment"># load net</span></div><div class="line">net = caffe.Net(<span class="string">'voc-fcn8s/deploy.prototxt'</span>, <span class="string">'voc-fcn8s/fcn8s-heavy-pascal.caffemodel'</span>, caffe.TEST)</div><div class="line"><span class="comment"># shape for input (data blob is N x C x H x W), set data</span></div><div class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">1</span>, *in_.shape)</div><div class="line">net.blobs[<span class="string">'data'</span>].data[...] = in_</div><div class="line"><span class="comment"># run net and take argmax for prediction</span></div><div class="line">net.forward()</div><div class="line">out = net.blobs[<span class="string">'score'</span>].data[<span class="number">0</span>].argmax(axis=<span class="number">0</span>)</div><div class="line"><span class="comment">#print out</span></div><div class="line">plt.imshow(out,cmap=<span class="string">'gray'</span>);</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.savefig(<span class="string">'test1.png'</span>)</div></pre></td></tr></table></figure></p>
<p><strong>2.源码阅读</strong><br>在源码的voc-fcn32s问价夹下，net.py用于生成网络的配置文件：train.prototxt、val.prototxt，solve.py用来运行训练网络，solver.prototxt是训练的配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">train_net: &quot;train.prototxt&quot;</div><div class="line">test_net: &quot;val.prototxt&quot;</div><div class="line">test_iter: 736</div><div class="line"># make test net, but don&apos;t invoke it from the solver itself</div><div class="line">test_interval: 999999999</div><div class="line">display: 20</div><div class="line">average_loss: 20</div><div class="line">lr_policy: &quot;fixed&quot;</div><div class="line"># lr for unnormalized softmax</div><div class="line">base_lr: 1e-10</div><div class="line"># high momentum</div><div class="line">momentum: 0.99</div><div class="line"># no gradient accumulation</div><div class="line">iter_size: 1</div><div class="line">max_iter: 100000</div><div class="line">weight_decay: 0.0005</div><div class="line">snapshot: 4000</div><div class="line">snapshot_prefix: &quot;snapshot/train&quot;</div><div class="line">test_initialization: false</div></pre></td></tr></table></figure></p>
<p><strong>solve.py 文件解读</strong><br>它调用了根目录下的 surgery.py 和 score.py 文件，后面再介绍。<br>主要作用：  </p>
<ul>
<li>用现有的分类网络模型初始化网络；  </li>
<li>自定义上采样层的卷积核；  </li>
<li>加载验证图片，自定义最后的得分输出。<br>初始化网络：  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">weights = <span class="string">'../ilsvrc-nets/vgg16-fcn.caffemodel'</span> <span class="comment">#加载训练好的分类模型</span></div><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)<span class="comment">#加载网络配置文件</span></div><div class="line">solver.net.copy_from(weights)<span class="comment">#从模型中复制权重</span></div><div class="line"><span class="comment">#也可以写为如下方式：</span></div><div class="line"><span class="comment">#solver = caffe.SGDSolver('solver.prototxt')</span></div><div class="line"><span class="comment">#vgg_net = caffe.Net('solver.prototxt', weights, caffe.TRAIN)</span></div><div class="line"><span class="comment">#surgery.transplant(solver.net, vgg_net)</span></div><div class="line"><span class="comment">#del vgg_net</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>调用surgery.py中的上采样层，双线性插值，将图像变为原始大小。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">interp_layers = [k <span class="keyword">for</span> k <span class="keyword">in</span> solver.net.params.keys() <span class="keyword">if</span> <span class="string">'up'</span> <span class="keyword">in</span> k]</div><div class="line">surgery.interp(solver.net, interp_layers)</div></pre></td></tr></table></figure></p>
<p>得分层<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># scoring</span></div><div class="line">val = np.loadtxt(<span class="string">'../data/segvalid11.txt'</span>, dtype=str)<span class="comment">#加载验证图片</span></div><div class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">25</span>):</div><div class="line">    solver.step(<span class="number">4000</span>)</div><div class="line">    score.seg_tests(solver, <span class="keyword">False</span>, val, layer=<span class="string">'score'</span>)<span class="comment">#测试网络的得分情况</span></div></pre></td></tr></table></figure></p>
<p><strong>surgery.py 文件解读</strong><br>主要作用是制作适用于给定长宽的双线性插值内核，用于上采样。主要函数为:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample_filt</span><span class="params">(size)</span>:</span></div><div class="line">    <span class="string">"""</div><div class="line">    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.</div><div class="line">    """</span></div><div class="line">    factor = (size + <span class="number">1</span>) // <span class="number">2</span></div><div class="line">    <span class="keyword">if</span> size % <span class="number">2</span> == <span class="number">1</span>:</div><div class="line">        center = factor - <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        center = factor - <span class="number">0.5</span></div><div class="line">    og = np.ogrid[:size, :size]</div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> - abs(og[<span class="number">0</span>] - center) / factor) * \</div><div class="line">           (<span class="number">1</span> - abs(og[<span class="number">1</span>] - center) / factor)</div></pre></td></tr></table></figure></p>
<p><strong>score.py 文件解读</strong><br>主要作用：计算当前网络分割图的准确性。主要有以下几个标准：mean loss, overall accuracy, per-class accuracy, per-class IU。如何计算的呢？<br>首先理解两个函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#计算a和b对应相同的就在矩阵中对应坐标加1。a和b保存着各个像素的分的类别0-20共21类</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_hist</span><span class="params">(a, b, n)</span>:</span></div><div class="line">    k = (a &gt;= <span class="number">0</span>) &amp; (a &lt; n)<span class="comment">#过滤掉多余的分类</span></div><div class="line">    <span class="comment">#bincount用于统计在范围内出现的个数，即直方图，如果不够n^2个，</span></div><div class="line">    <span class="comment">#那就填充到n^2，这样可以reshpe为n*n的矩阵，正好表示分割图和正确标记图在相同</span></div><div class="line">    <span class="comment">#类别上像素出现的个数</span></div><div class="line">    <span class="keyword">return</span> np.bincount(n * a[k].astype(int) + b[k], minlength=n**<span class="number">2</span>).reshape(n, n)</div><div class="line"><span class="comment">#调用计算直方图函数，指定了数据来源</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_hist</span><span class="params">(net, save_dir, dataset, layer=<span class="string">'score'</span>, gt=<span class="string">'label'</span>)</span>:</span></div><div class="line">    n_cl = net.blobs[layer].channels<span class="comment">#得到score层的通道数，fcn中为21通道，21类物体</span></div><div class="line">    <span class="keyword">if</span> save_dir:<span class="comment">#是否将分割图保存为文件</span></div><div class="line">        os.mkdir(save_dir)</div><div class="line">    <span class="comment">#hist表示：分割图中21类和标记图21类出现的像素数</span></div><div class="line">    <span class="comment">#如：在i,j像素位置上分割图标记为2类物体，而实际标记为3那么在hist（2,3）+=1</span></div><div class="line">    <span class="comment">#    在i,j+1像素位置分割图标记2类物体，实际标记图也为2类，则hist(2,2)+=1</span></div><div class="line">    <span class="comment">#    可以看出hist对角矩阵是正确的分割；</span></div><div class="line">    hist = np.zeros((n_cl, n_cl))<span class="comment">#初始化21*21的二维矩阵</span></div><div class="line">    loss = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> dataset:</div><div class="line">        net.forward()<span class="comment">#网络向前传播</span></div><div class="line">        <span class="comment">#展开为一维数组</span></div><div class="line">        hist += fast_hist(net.blobs[gt].data[<span class="number">0</span>, <span class="number">0</span>].flatten(),</div><div class="line">                          net.blobs[layer].data[<span class="number">0</span>].argmax(<span class="number">0</span>).flatten(),n_cl)</div><div class="line">        <span class="keyword">if</span> save_dir:</div><div class="line">            im = Image.fromarray(net.blobs[layer].data[<span class="number">0</span>].argmax(<span class="number">0</span>).astype(np.uint8), mode=<span class="string">'P'</span>)</div><div class="line">            im.save(os.path.join(save_dir, idx + <span class="string">'.png'</span>))</div><div class="line">        <span class="comment"># compute the loss as well 计算网络的损失</span></div><div class="line">        loss += net.blobs[<span class="string">'loss'</span>].data.flat[<span class="number">0</span>]<span class="comment">#flat[0]取第一个数</span></div><div class="line">    <span class="keyword">return</span> hist, loss / len(dataset)</div></pre></td></tr></table></figure></p>
<p>计算几个分割效果指标：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#mean loss</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'loss'</span>, loss</div><div class="line">   <span class="comment"># overall accuracy</span></div><div class="line">   acc = np.diag(hist).sum() / hist.sum()<span class="comment">#对角线正确像素/总像素</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'overall accuracy'</span>, acc</div><div class="line">   <span class="comment"># per-class accuracy</span></div><div class="line">   acc = np.diag(hist) / hist.sum(<span class="number">1</span>)<span class="comment">#每一类的</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'mean accuracy'</span>, np.nanmean(acc)</div><div class="line">   <span class="comment"># per-class IU</span></div><div class="line">   iu = np.diag(hist) / (hist.sum(<span class="number">1</span>) + hist.sum(<span class="number">0</span>) - np.diag(hist))</div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'mean IU'</span>, np.nanmean(iu)</div><div class="line">   freq = hist.sum(<span class="number">1</span>) / hist.sum()</div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'fwavacc'</span>, \</div><div class="line">           (freq[freq &gt; <span class="number">0</span>] * iu[freq &gt; <span class="number">0</span>]).sum()</div></pre></td></tr></table></figure></p>
<p>其他文件：训练文件的输入层类型是Python，作者自定义了一个voc_layers.py的Python数据加载层。  </p>
<ul>
<li>setup函数，设置voc训练集的路径，及中值文件，挑选数据的随机数；</li>
<li>load_image和load_label函数，用于从数据集中加载图像和标记图像，并转换成数组形式，图像减去中值并转换成<code>chanl*height*weight</code>形式，label变为<code>1*height*weight</code>形式；</li>
<li>forward和backward函数，前向传播将图像、标签复制到top[0]和top[1]中，反向传播不需要任何操作。  </li>
</ul>
<p><strong>学习到的东西</strong><br>Python中numpy中的一些函数，诸如bincount、flatten、diag等。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="学习" scheme="http://abumaster.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Background Dataset介绍和使用</title>
    <link href="http://abumaster.com/2017/04/10/Stanford-Background-Dataset%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://abumaster.com/2017/04/10/Stanford-Background-Dataset介绍和使用/</id>
    <published>2017-04-10T06:35:07.000Z</published>
    <updated>2017-04-11T00:58:07.351Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dags.stanford.edu/projects/scenedataset.html">Stanford Background Dataset</a>是一个从各个数据库（LabelMe, MSRC, PASCAL<br>VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。</p>
<ul>
<li><p>images文件夹包含了715张图像；  </p>
</li>
<li><p>horizons.txt  图像名称、大小、水平线位置；  </p>
<a id="more"></a>
</li>
<li><p>labels/*.regions.txt 标识每个像素的语义，0-7代表八类语义；  </p>
</li>
<li><p>labels/*.surfaces.txt 标识每个像素的几何类别（天空，水平，垂直）； </p>
</li>
<li><p>labels/*.layers.txt    表示不同图像区域的整数矩阵。  </p>
</li>
</ul>
<p><strong>读取图像和分割图像</strong><br>1.首先读取标签文件<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">vector&lt;char&gt; vec;//保存像素标记</div><div class="line">void readlabel(string labelname)</div><div class="line">&#123;</div><div class="line">	ifstream infile(labelname.c_str(), std::ios::in);</div><div class="line">	char line[1024] = &#123; 0 &#125;;</div><div class="line">	while (infile.getline(line, sizeof(line)))</div><div class="line">	&#123;</div><div class="line">		stringstream word(line);</div><div class="line">		char ch;</div><div class="line">		while (word &gt;&gt; ch)</div><div class="line">		&#123;</div><div class="line">			vec.push_back(ch);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>2.显示分割图像，根据语义标签，设置不同的颜色以区别  </p>
<pre><code class="c++"><span class="comment">//显示分割图像</span>
    <span class="function">Mat <span class="title">colorim</span><span class="params">(im.rows, im.cols, CV_8UC3)</span></span>;
    <span class="keyword">int</span> index = <span class="number">0</span>;
    <span class="comment">//遍历所有像素，并设置像素值</span>
    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colorim.rows; ++i)
    {
        <span class="comment">//获取第 i 行首像素指针</span>
        Vec3b * p = colorim.ptr&lt;Vec3b&gt;(i);
        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; colorim.cols; ++j)
        {
            <span class="keyword">int</span> lab = vec[index++];
            <span class="keyword">switch</span> (lab)
            {
            <span class="keyword">case</span> <span class="string">'0'</span>:<span class="comment">//sky</span>
                p[j][<span class="number">0</span>] = <span class="number">128</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">128</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">128</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'1'</span>:<span class="comment">//tree</span>
                p[j][<span class="number">0</span>] = <span class="number">84</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">230</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">80</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'2'</span>:<span class="comment">//road</span>
                p[j][<span class="number">0</span>] = <span class="number">115</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">100</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'3'</span>:<span class="comment">//grass</span>
                p[j][<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">255</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">0</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'4'</span>:<span class="comment">//water</span>
                p[j][<span class="number">0</span>] = <span class="number">255</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">0</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'5'</span>:<span class="comment">//building</span>
                p[j][<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">160</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'6'</span>:<span class="comment">//mountain</span>
                p[j][<span class="number">0</span>] = <span class="number">63</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">214</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">8</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'7'</span>:<span class="comment">//obj</span>
                p[j][<span class="number">0</span>] = <span class="number">37</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">159</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">230</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">default</span>:<span class="comment">//somthing else</span>
                p[j][<span class="number">0</span>] = <span class="number">255</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">255</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">255</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;

            }

        }
    }
    imshow(<span class="string">"分割图"</span>, colorim);
</code></pre>
<p><strong>结果</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-11/35996483-file_1491872210006_c82e.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dags.stanford.edu/projects/scenedataset.html&quot;&gt;Stanford Background Dataset&lt;/a&gt;是一个从各个数据库（LabelMe, MSRC, PASCAL&lt;br&gt;VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;images文件夹包含了715张图像；  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;horizons.txt  图像名称、大小、水平线位置；  &lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="dataset" scheme="http://abumaster.com/tags/dataset/"/>
    
  </entry>
  
  <entry>
    <title>caffe提取各层特征</title>
    <link href="http://abumaster.com/2017/04/09/caffe%E6%8F%90%E5%8F%96%E5%90%84%E5%B1%82%E7%89%B9%E5%BE%81/"/>
    <id>http://abumaster.com/2017/04/09/caffe提取各层特征/</id>
    <published>2017-04-09T12:07:29.000Z</published>
    <updated>2017-04-10T02:03:08.407Z</updated>
    
    <content type="html"><![CDATA[<p>根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：<br><strong>1.caffe创建分类器</strong><br>Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\python\caffe下。<br><a id="more"></a><br>初始化这个分类器的时候，出现了一个问题：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">net = caffe.Classifier(caffe_root + <span class="string">'models/bvlc_reference_caffenet/deploy.prototxt'</span>,</div><div class="line">caffe_root + <span class="string">'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span>)</div><div class="line"></div><div class="line">net.set_phase_test()</div><div class="line">net.set_mode_cpu()</div><div class="line">net.set_mean(<span class="string">'data'</span>, caffe_root + <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)</div><div class="line">net.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>)) </div><div class="line">net.set_input_scale(<span class="string">'data'</span>, <span class="number">255</span>)</div></pre></td></tr></table></figure></p>
<p>就是在网络设置时，一直提示没有<code>set_phase_test(*)</code>的成员函数，试了几个平台都是如此提示，后来在网上找到了一点<a href="http://www.programcreek.com/python/example/83400/caffe.set_phase_test">信息</a>其中提到了，可以直接创建的时候初始化，对应于函数的声明所需的参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">net = caffe.Classifier(MODEL_FILE, PRETRAINED,</div><div class="line">                        mean=np.load(os.path.join(CAFFE_DIR, <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)),</div><div class="line">                        channel_swap=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>),</div><div class="line">                        raw_scale=<span class="number">255</span>,</div><div class="line">                        image_dims=(<span class="number">256</span>, <span class="number">256</span>))</div></pre></td></tr></table></figure></p>
<p><strong>维度不匹配问题</strong>代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"> File &quot;one.py&quot;, line 14, in &lt;module&gt;</div><div class="line">    image_dims=(256, 256))</div><div class="line">  File &quot;/home/zgf/caffe-master/python/caffe/classifier.py&quot;, line 34, in __init__</div><div class="line">    self.transformer.set_mean(in_, mean)</div><div class="line">  File &quot;/home/zgf/caffe-master/python/caffe/io.py&quot;, line 259, in set_mean</div><div class="line">    raise ValueError(&apos;Mean shape incompatible with input shape.&apos;)</div><div class="line">ValueError: Mean shape incompatible with input shape.</div></pre></td></tr></table></figure></p>
<p>中值文件读取的错误，在网络上找到了解决<a href="http://stackoverflow.com/questions/30808735/error-when-using-classify-in-caffe">方案</a>，将读取中值文件改为：<code>mean=np.load(&#39;/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy&#39;).mean(1).mean(1)</code>可以解决。  </p>
<p><strong>2.显示特征图像问题</strong><br>按照文档描述依次往下进行，文档使用的工具为ipython，显示图片用：<code>ipt.show()</code>，而我用的工具是jupyter，所以一直找不到这个命令，无法查看图像，从网上查到，可以在代码前面加上一句<code>%matplotlib inline</code>然后用<code>import matplotlib as plt plt.imshow(img)</code>实现。  </p>
<p><strong>3.结果</strong><br>加载网络<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">caffe_root=<span class="string">'/home/zgf/caffe-master/'</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> os</div><div class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">'python/caffe'</span>)</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"></div><div class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10</span>, <span class="number">10</span>)</div><div class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></div><div class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></div><div class="line"></div><div class="line">ref_model_file = caffe_root+<span class="string">'/models/bvlc_reference_caffenet/deploy.prototxt'</span></div><div class="line">ref_pretrained = caffe_root+<span class="string">'/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span></div><div class="line"></div><div class="line">net = caffe.Classifier(ref_model_file, ref_pretrained,</div><div class="line">       mean=np.load(<span class="string">'/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>).mean(<span class="number">1</span>).mean(<span class="number">1</span>),</div><div class="line">       channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),</div><div class="line">       raw_scale=<span class="number">255</span>,</div><div class="line">       image_dims=(<span class="number">256</span>, <span class="number">256</span>))</div><div class="line"></div><div class="line">scores = net.predict([caffe.io.load_image(caffe_root + <span class="string">'examples/images/cat.jpg'</span>)])</div><div class="line"><span class="comment">#显示网络的结构信息</span></div><div class="line">[(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.blobs.items()]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[(&apos;data&apos;, (10, 3, 227, 227)),</div><div class="line"> (&apos;conv1&apos;, (10, 96, 55, 55)),</div><div class="line"> (&apos;pool1&apos;, (10, 96, 27, 27)),</div><div class="line"> (&apos;norm1&apos;, (10, 96, 27, 27)),</div><div class="line"> (&apos;conv2&apos;, (10, 256, 27, 27)),</div><div class="line"> (&apos;pool2&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;norm2&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;conv3&apos;, (10, 384, 13, 13)),</div><div class="line"> (&apos;conv4&apos;, (10, 384, 13, 13)),</div><div class="line"> (&apos;conv5&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;pool5&apos;, (10, 256, 6, 6)),</div><div class="line"> (&apos;fc6&apos;, (10, 4096)),</div><div class="line"> (&apos;fc7&apos;, (10, 4096)),</div><div class="line"> (&apos;fc8&apos;, (10, 1000)),</div><div class="line"> (&apos;prob&apos;, (10, 1000))]</div></pre></td></tr></table></figure></p>
<p>显示参数信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.params.items()]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[(&apos;conv1&apos;, (96, 3, 11, 11)),</div><div class="line"> (&apos;conv2&apos;, (256, 48, 5, 5)),</div><div class="line"> (&apos;conv3&apos;, (384, 256, 3, 3)),</div><div class="line"> (&apos;conv4&apos;, (384, 192, 3, 3)),</div><div class="line"> (&apos;conv5&apos;, (256, 192, 3, 3)),</div><div class="line"> (&apos;fc6&apos;, (4096, 9216)),</div><div class="line"> (&apos;fc7&apos;, (4096, 4096)),</div><div class="line"> (&apos;fc8&apos;, (1000, 4096))]</div></pre></td></tr></table></figure></p>
<p><strong>输入层</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">showimage</span><span class="params">(im)</span>:</span></div><div class="line">    <span class="keyword">if</span> im.ndim == <span class="number">3</span>:</div><div class="line">        m = im[:, :, ::<span class="number">-1</span>]</div><div class="line">    plt.imshow(im)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span><span class="params">(data, padsize=<span class="number">1</span>, padval=<span class="number">0</span>)</span>:</span></div><div class="line">    data -= data.min()</div><div class="line">    data /= data.max()</div><div class="line">    <span class="comment"># force the number of filters to be square</span></div><div class="line">    n = int(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</div><div class="line">    padding = ((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]), (<span class="number">0</span>, padsize), (<span class="number">0</span>, padsize)) + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>)</div><div class="line">    data = np.pad(data, padding, mode=<span class="string">'constant'</span>, constant_values=(padval, padval))</div><div class="line">    <span class="comment"># 对图像使用滤波器</span></div><div class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + tuple(range(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</div><div class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</div><div class="line">    showimage(data)</div><div class="line">    <span class="comment">#plt.imshow(data)</span></div><div class="line"><span class="comment"># index four is the center crop</span></div><div class="line"><span class="comment"># 输出输入的图像</span></div><div class="line">image = net.blobs[<span class="string">'data'</span>].data[<span class="number">4</span>].copy()</div><div class="line">image -= image.min()</div><div class="line">image /= image.max()</div><div class="line">showimage(image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</div><div class="line"><span class="comment">#plt.imshow(image.transpose(1,2,0))</span></div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i4.buimg.com/567571/2d78079157ce4c40.png" alt=""><br>第一个卷积层，参数有[weight, biases]对应索引0,1。的96个过滤器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">filters = net.params[<span class="string">'conv1'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</div><div class="line"><span class="comment">#96 feature map</span></div><div class="line">feat = net.blobs[<span class="string">'conv1'</span>].data[<span class="number">4</span>, :<span class="number">96</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i4.buimg.com/567571/64897ccff6d61745.jpg" alt=""><br>第二卷积层的过滤器，每个尺寸5*5*48，显示前48个，机器对应的输出只显示36张。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">filters = net.params[<span class="string">'conv2'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters[:<span class="number">48</span>].reshape(<span class="number">48</span>**<span class="number">2</span>, <span class="number">5</span>, <span class="number">5</span>))</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv2'</span>].data[<span class="number">4</span>, :<span class="number">36</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i2.muimg.com/567571/441dcc7e494e611a.jpg" alt=""><br>接下来的卷积层的提取和输出一样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'conv3'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.5</span>)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv4'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.5</span>)</div><div class="line"><span class="comment">#第5卷积层</span></div><div class="line">feat = net.blobs[<span class="string">'conv5'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.2</span>)</div><div class="line"><span class="comment">#池化层</span></div><div class="line">feat = net.blobs[<span class="string">'pool5'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>最后的全连接层fc6和fc7，输出直方图：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'fc6'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'fc7'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://i1.piimg.com/567571/44bbc67d60e82537.jpg" alt="fc"><br>最后的输出层，显示1000类概率的直方图信息：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'prob'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div></pre></td></tr></table></figure></p>
<p><img src="http://i1.piimg.com/567571/c9d3333a6724e4d0.jpg" alt="prob"><br>显示最后的类别信息top5：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">imagenet_labels_filename = caffe_root + <span class="string">'data/ilsvrc12/synset_words.txt'</span></div><div class="line"><span class="keyword">try</span>:</div><div class="line">    labels = np.loadtxt(imagenet_labels_filename, str, delimiter=<span class="string">'\t'</span>)</div><div class="line"><span class="keyword">except</span>:</div><div class="line">    !../data/ilsvrc12/get_ilsvrc_aux.sh</div><div class="line">labels = np.loadtxt(imagenet_labels_filename, str, delimiter=<span class="string">'\t'</span>)</div><div class="line">top_k = net.blobs[<span class="string">'prob'</span>].data[<span class="number">4</span>].flatten().argsort()[<span class="number">-1</span>:<span class="number">-6</span>:<span class="number">-1</span>]</div><div class="line"><span class="keyword">print</span> labels[top_k]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[&apos;n02123045 tabby, tabby cat&apos; </div><div class="line"> &apos;n02123159 tiger cat&apos;</div><div class="line"> &apos;n02124075 Egyptian cat&apos; </div><div class="line"> &apos;n02119022 red fox, Vulpes vulpes&apos;</div><div class="line"> &apos;n02127052 lynx, catamount&apos;]</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：&lt;br&gt;&lt;strong&gt;1.caffe创建分类器&lt;/strong&gt;&lt;br&gt;Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\python\caffe下。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>结合特定任务边缘检测的图像语义分割</title>
    <link href="http://abumaster.com/2017/04/07/%E7%BB%93%E5%90%88%E7%89%B9%E5%AE%9A%E4%BB%BB%E5%8A%A1%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/07/结合特定任务边缘检测的图像语义分割/</id>
    <published>2017-04-07T07:38:22.000Z</published>
    <updated>2017-04-08T02:30:39.618Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。  </p>
</blockquote>
<a id="more"></a>
<p><strong>主要思想</strong><br>取代最后的全连接条件随机场和与其关联的双向过滤器，变为域变换（DT）一种边缘感知过滤器。域变换的递归公式等于信号的自适应递归滤波，其中信息不允许在某些参考信号中跨越边缘传播。速度快。<br><strong>前期工作</strong>  </p>
<ul>
<li>图像语义分割<br>网络中最大池化和下采样的出现，使稠密网络最后的输出图无法精准定位物体的边界信息，为了解决这个问题，出现了很多解决方案：组合中间特征图信息；反卷积和上采样；超像素等底层的分割方法；条件随机场，利用像素之间的依赖关系。  </li>
<li>边缘检测<br>学习物体的边界直接优化图像语义分割的表现。  </li>
<li>长距离依赖（Long range dependency）<br>通过DT输入进行反向传播，以共同学习端对端可训练系统中的分割图得分和边缘图。<br><strong>提出模型</strong><br>论文中提出的模型图：<br><img src="http://i4.buimg.com/567571/1043df45dae88c0c.png" alt=""><br>分为三个部分：<br>1.语义分割预测，得出一个大致的分割图，与全卷积网络输出图类似；<br>2.边缘预测网络，生成一个边缘预测图；<br>3.域转换，使用物体边界限制分割图。<br><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>x表示需要过滤的原始信号量，y表示域转换密度信号d。使用递归公式计算，初始化y1=x1，然后递归计算<code>i=2,...,N</code>：<br>$$y_i=(1-w_i)x_i+w_iy_{i-1}$$<br>其中权重wi的计算依赖di：<br>$$w_i=exp(-\sqrt2d_i/{\sigma_{s}})$$<br>一维计算树，前向和反向传播的计算：<br><img src="http://i2.muimg.com/567571/08cbd87d8bbbe172.png" alt=""><br>$$\frac{\partial L}{\partial x_i}\leftarrow (1-w_i)\frac{\partial L}{\partial y_i}$$<br>$$\frac{\partial L}{\partial w_i}\leftarrow \frac{\partial L}{\partial w_i}+(y_{i-1}-x_i)\frac{\partial L}{\partial y_i}$$<br>$$\frac{\partial L}{\partial y_{i-1}}\leftarrow \frac{\partial L}{\partial y_{i-1}}+w_i\frac{\partial L}{\partial y_i}$$<br>源码和模型<a href="http://liangchiehchen.com/projects/DeepLab.html">地址</a>。接下来学习。</li>
</ul>
<p><strong>参考文献</strong><br>[1] “Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform”<br>Liang-Chieh Chen, Jonathan T. Barron, George Papandreou, Kevin Murphy, and Alan L. Yuille<br>In Conference on Computer Vision and Pattern Recognition (CVPR), 2016</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>进制转换</title>
    <link href="http://abumaster.com/2017/04/06/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
    <id>http://abumaster.com/2017/04/06/进制转换/</id>
    <published>2017-04-06T13:16:07.000Z</published>
    <updated>2017-04-06T14:09:19.093Z</updated>
    
    <content type="html"><![CDATA[<p><strong>题目描述</strong><br>将任意长度的二进制转换成十进制。<br>要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：<em>数字的n次方</em>、<em>大数相加</em>、<em>大数相乘</em>。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。<br><a id="more"></a><br><strong>解法</strong><br>二进制转换成十进制<br>观察：<code>10001000</code>的计算过程，转换成十进制为：<code>2^7+0+0+0+2^3+0+0+0</code>。<br>因此问题分为两个部分：计算二进制位置上为1时对应的十进制数是多少；对所有的位置得到的数字求和。<br>代码如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</div><div class="line"> * bin2dec 二进制转换成十进制</div><div class="line"> * @param decnum 十进制数字串</div><div class="line"> * @param n      二进制1后面的0的个数</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bin2dec</span><span class="params">(<span class="keyword">int</span> *decnum, <span class="keyword">int</span> n)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> index = LEN<span class="number">-1</span>;</div><div class="line">	decnum[index] = <span class="number">1</span>;</div><div class="line">	<span class="keyword">int</span> jinwei = <span class="number">0</span>;</div><div class="line">	<span class="keyword">while</span> (n--) <span class="comment">//总共几个0</span></div><div class="line">	&#123;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i = LEN<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> nowtemp = <span class="number">2</span>*decnum[i]+jinwei;</div><div class="line">			<span class="keyword">if</span>(nowtemp&gt;=<span class="number">10</span>)<span class="comment">//需要进位</span></div><div class="line">			&#123;</div><div class="line">				decnum[i] = nowtemp%<span class="number">10</span>; <span class="comment">//改变当前的数值</span></div><div class="line">				jinwei = nowtemp/<span class="number">10</span>; <span class="comment">//进位的多少</span></div><div class="line">			&#125;</div><div class="line">			<span class="keyword">else</span></div><div class="line">			&#123;</div><div class="line">				decnum[i] = nowtemp;</div><div class="line">				jinwei=<span class="number">0</span>;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</div><div class="line"> * 将两个大数合并，放入左边数组</div><div class="line"> * @param left  相加结果放入此</div><div class="line"> * @param right 数组</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">sumbignum</span><span class="params">(<span class="keyword">int</span> *left, <span class="keyword">int</span> *right, <span class="keyword">int</span> n=LEN)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> jinwei = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=n<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> temp = left[i]+right[i]+jinwei;<span class="comment">//俩数之和加上进位标志</span></div><div class="line">		<span class="keyword">if</span>(temp &gt;= <span class="number">10</span>)<span class="comment">//需要进位的</span></div><div class="line">		&#123;</div><div class="line">			left[i] = temp%<span class="number">10</span>;</div><div class="line">			jinwei = temp/<span class="number">10</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> <span class="comment">//不用进位</span></div><div class="line">		&#123;</div><div class="line">			left[i] = temp;</div><div class="line">			jinwei = <span class="number">0</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>十进制转换成二进制</strong><br>同理，位数少的十进制转换成二进制一般应用除2求余，然后直到商为0。<a href="http://baike.baidu.com/link?url=QHeUym9N6IWCVV6zLmIHIX6Y6CMPOfthTCyDRkfsq9TAxCjewlxrfhHYUw2sarVURML8-Oyz0bCASXtMqHqUWYGGRieuENcGHN30Qzmx6Ef_XdJSIaiBCn0vfvUrrILr4t15XLZWOj6RIdcgit792Vn5iQGGQYVyOfQF4R2ggfm">参考</a>。<br>对于大数，可以保存在一个数组中，用前一位的余数与当前的位数拼成一个数，除以2，商替换原数字对应的位数上，余数更新，直到把数字的位数计算完，算作得出二进制的一位（最后得出的余数）。直到商为0结束。代码如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> LEN = <span class="number">100</span>;</div><div class="line"><span class="comment">/**</div><div class="line"> * 检查数组代表的数字是否为空</div><div class="line"> * @param  arr [description]</div><div class="line"> * @param  len [description]</div><div class="line"> * @return     [description]</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsZero</span><span class="params">(<span class="keyword">int</span> *arr, <span class="keyword">int</span> len)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">bool</span> ret = <span class="literal">true</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">if</span>(arr[i] != <span class="number">0</span>)</div><div class="line">		&#123;</div><div class="line">			ret = <span class="literal">false</span>;</div><div class="line">			<span class="keyword">break</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> ret;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</div><div class="line"> * 十进制转换成二进制的核心函数</div><div class="line"> * @param decnum 十进制保存位置</div><div class="line"> * @param binnum 二进制字符串</div><div class="line"> * @param len    十进制长度</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">dec2binCore</span><span class="params">(<span class="keyword">int</span> *decnum, <span class="keyword">int</span> *binnum, <span class="keyword">int</span> len)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> mod;</div><div class="line">	<span class="keyword">int</span> index = LEN<span class="number">-1</span>;</div><div class="line">	<span class="keyword">while</span>(!IsZero(decnum, len))<span class="comment">//十进制表示的数字不为0</span></div><div class="line">	&#123;</div><div class="line">		mod = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i =<span class="number">0</span>; i&lt;len; i++)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> tempnum = <span class="number">10</span>*mod+decnum[i];</div><div class="line">			<span class="keyword">int</span> sang = tempnum/<span class="number">2</span>;</div><div class="line">			mod = tempnum%<span class="number">2</span>;</div><div class="line">			decnum[i] = sang; <span class="comment">//更新商</span></div><div class="line">		&#125;</div><div class="line">		binnum[index--] = mod;<span class="comment">//最后的余数是二进制</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">PrintInt</span><span class="params">(<span class="keyword">int</span> *arr, <span class="keyword">int</span> n)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> start = <span class="number">0</span>;<span class="comment">//bug</span></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n<span class="number">-1</span>; i++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> j = i+<span class="number">1</span>;</div><div class="line">		<span class="keyword">if</span>(arr[i]==<span class="number">0</span> &amp;&amp; arr[j]!=<span class="number">0</span> &amp;&amp; !start)</div><div class="line">		&#123;</div><div class="line">			start = <span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (start)</div><div class="line">			<span class="built_in">cout</span> &lt;&lt; arr[j];</div><div class="line">	&#125;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">testdec2bin</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">string</span> strnum;</div><div class="line">	<span class="keyword">while</span>(<span class="built_in">cin</span> &gt;&gt; strnum)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> len = strnum.size();</div><div class="line">		<span class="keyword">int</span> *decnum = <span class="keyword">new</span> <span class="keyword">int</span>[len];</div><div class="line">		<span class="built_in">memset</span>(decnum, <span class="number">0</span>, len*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)</div><div class="line">			decnum[i]= strnum[i]-<span class="string">'0'</span>;</div><div class="line">		<span class="keyword">int</span> *binnum = <span class="keyword">new</span> <span class="keyword">int</span>[LEN];</div><div class="line">		<span class="built_in">memset</span>(binnum, <span class="number">0</span>, LEN*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line">		dec2binCore(decnum, binnum, len);</div><div class="line">		PrintInt(binnum, LEN);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	testdec2bin();</div><div class="line"></div><div class="line">	system(<span class="string">"pause"</span>);</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>感悟</strong><br>看似简单的问题，还要细思量。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;题目描述&lt;/strong&gt;&lt;br&gt;将任意长度的二进制转换成十进制。&lt;br&gt;要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：&lt;em&gt;数字的n次方&lt;/em&gt;、&lt;em&gt;大数相加&lt;/em&gt;、&lt;em&gt;大数相乘&lt;/em&gt;。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>全卷积网络和全连接条件随机场</title>
    <link href="http://abumaster.com/2017/04/05/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"/>
    <id>http://abumaster.com/2017/04/05/全卷积网络和全连接条件随机场/</id>
    <published>2017-04-05T07:08:55.000Z</published>
    <updated>2017-04-06T13:10:41.589Z</updated>
    
    <content type="html"><![CDATA[<p>来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015.  主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。<br><a id="more"></a><br><strong>主要创新点：</strong><br>1.带孔卷积<br>在最后两个池化层后，跳过子采样，修改之后的卷积过滤器，变为卷积层。命名为孔算法，解释如图：<br><img src="http://i1.piimg.com/567571/ceb8871164ae116c.png" alt="">  </p>
<ul>
<li>高效的特征提取算法，有效的稠密滑动窗口特征提取器  </li>
<li>控制接受域大小，加速卷积网络的计算  </li>
</ul>
<p>2.边界恢复问题<br>目前定位物体边界的挑战主要从两个方面：  </p>
<ul>
<li>利用融合不同层特征图的相关信息，估计物体边界  </li>
<li>利用超像素表征，将任务委托给低层次的分割任务  </li>
</ul>
<p>模型：<br><img src="http://i1.piimg.com/567571/17c50f02e9958365.png" alt="">  </p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>$$E(x)=\sum_i\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)$$<br>有一元项和二元项。<br>3.多尺度预测<br>为了增加边界定位的准确性，用了多尺度预测。具体是，为输入图像和第一个四层最大池化层附加一个双层MLP（第一层：<code>128 个3*3的卷积核</code>，第二层：<code>128个1*1的卷积核</code>）与最后一层的特征图连接。汇总的特征图，放入softmax层，产生<code>5*128=640</code>通道。  </p>
<p><strong>系统实现</strong><br>DeepLab：使用深度卷积网络，atrous卷积和全连接crfs的图像语义分割模型。<br>针对传统方法的不足：  </p>
<ul>
<li>减少特征解析度（重复的最大池化和下采样）  </li>
<li>存在多个尺度的对象  </li>
<li>由于深度网络的稳定性导致定位精度下降<br>提出的优化方案：  </li>
<li>不采样  </li>
<li>atrous spatial pyramid pooling 空间金字塔池化  </li>
<li>结合条件随机场<br><strong>细节</strong><br>atrous卷积的计算，一维信号量示例如图：<br><img src="http://i1.piimg.com/567571/e4d2c7eb9eaa6b1e.png" alt=""><br>$$y[i]=\sum_{k=1}^Kx[i+r\cdot{k}]w[k]$$<br>全连接条件随机场：<br>关于能量函数，第一项由预测网络给出的预测值；第二项：<br><img src="http://i1.piimg.com/567571/c38b63130a578629.png" alt=""><br>公式分为两项，第一项是节点值不相等时为1，相等时为0，为了表示不同的标签将要受到惩罚。第二项，有两个高斯核组成，第一个是用像素的位置和像素的值表示，第二个是用像素之间的位置表示，他们是不同空间的特征。<br><img src="http://i2.muimg.com/567571/020f15b2235a3483.png" alt=""></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015.  主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>Linux配置OpenCV</title>
    <link href="http://abumaster.com/2017/04/03/Linux%E9%85%8D%E7%BD%AEOpenCV/"/>
    <id>http://abumaster.com/2017/04/03/Linux配置OpenCV/</id>
    <published>2017-04-03T08:23:00.000Z</published>
    <updated>2017-04-03T12:11:57.398Z</updated>
    
    <content type="html"><![CDATA[<p><strong>源码安装OpenCV</strong><br>从<a href="http://opencv.org/">OpenCV官网</a>下载，最新版的OpenCV（opencv-3.2.0）。<br>解压文件，得到文件夹（opencv-3.2.0），并进入；<br>进行源码编译：<br><a id="more"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mkdir release  </div><div class="line">cd release  </div><div class="line">cmake -D CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local ..  </div><div class="line">make  </div><div class="line">sudo make install</div></pre></td></tr></table></figure>
<p><strong>配置依赖库</strong><br>安装完成后，编译完成，运行时会出现找不到依赖库的情况如：<br><code>error while loading shared libraries: libopencv_core.so.2.4: cannot open shared object file: No such file or directory</code><br>这是因为没有把共享库放在加载器可以找到的位置，解决方法：<br>首先定位到Opencv动态库所在的目录，一般在<code>/usr/local/lib/</code>或者<code>/usr/lib/x86_64-linux-gun/</code>中，在<code>/etc/ld.so.conf.d/</code>目录下创建一个opencv.conf的文件，并把上述的路径写入文件，然后执行<code>sudo ldconfig -v</code><br><strong>编译</strong><br><strong>1.第一种方式</strong><br><code>g++ DisplayImage.cpp -o DisplayImage &#39;pkg-config opencv --cflags --libs&#39;</code><br>在上面的编译命令中我们其实用到了一个工具“pkg-config”，它主要有以下几个功能：</p>
<ul>
<li><p>检查库的版本号。如果所需要的库的版本不满足要求，它会打印出错误信息，避免链接错误版本的库文件。  </p>
</li>
<li><p>获得编译预处理参数，如宏定义，头文件的位置。  </p>
</li>
<li><p>获得链接参数，如库及依赖的其它库的位置，文件名及其它一些连接参数。  </p>
</li>
<li><p>自动加入所依赖的其它库的设置</p>
</li>
</ul>
<p><strong>2.cmake工具</strong><br>CMake工具，需要一个CMakeLists.txt文件，然后输入命令<code>cmake .</code>会生成Makefile文件，然后make就行了。<br>CMakeLists.txt文件书写（opencv源码中带的例子example_cmake文件夹）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"># CMakeLists.txt</div><div class="line"># 必须的信息</div><div class="line">cmake_minimum_required(VERSION 2.8)</div><div class="line"></div><div class="line"># 工程的名称</div><div class="line">project(opencv_example_project)</div><div class="line"></div><div class="line"># 查找opencv的包</div><div class="line">find_package(OpenCV REQUIRED)</div><div class="line"></div><div class="line"># 打印库的状态信息</div><div class="line">message(STATUS &quot;OpenCV library status:&quot;)</div><div class="line">message(STATUS &quot;    version: $&#123;OpenCV_VERSION&#125;&quot;)</div><div class="line">message(STATUS &quot;    libraries: $&#123;OpenCV_LIBS&#125;&quot;)</div><div class="line">message(STATUS &quot;    include path: $&#123;OpenCV_INCLUDE_DIRS&#125;&quot;)</div><div class="line"></div><div class="line">if(CMAKE_VERSION VERSION_LESS &quot;2.8.11&quot;)</div><div class="line">  # Add OpenCV headers location to your include paths</div><div class="line">  include_directories($&#123;OpenCV_INCLUDE_DIRS&#125;)</div><div class="line">endif()</div><div class="line"></div><div class="line"># 生成的目标以及源文件</div><div class="line">add_executable(opencv_example example.cpp)</div><div class="line"></div><div class="line"># 程序与opencv动态库连接</div><div class="line">target_link_libraries(opencv_example $&#123;OpenCV_LIBS&#125;)</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;源码安装OpenCV&lt;/strong&gt;&lt;br&gt;从&lt;a href=&quot;http://opencv.org/&quot;&gt;OpenCV官网&lt;/a&gt;下载，最新版的OpenCV（opencv-3.2.0）。&lt;br&gt;解压文件，得到文件夹（opencv-3.2.0），并进入；&lt;br&gt;进行源码编译：&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>C++类构造函数</title>
    <link href="http://abumaster.com/2017/04/02/C-%E7%B1%BB%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"/>
    <id>http://abumaster.com/2017/04/02/C-类构造函数/</id>
    <published>2017-04-02T06:45:54.000Z</published>
    <updated>2017-04-02T13:48:05.088Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-中构造函数和析构函数应该注意的问题"><a href="#C-中构造函数和析构函数应该注意的问题" class="headerlink" title="C++中构造函数和析构函数应该注意的问题"></a>C++中构造函数和析构函数应该注意的问题</h3><p>构造方法用来初始化类的对象，与父类的其它成员不同，它不能被子类继承（子类可以继承父类所有的成员变量和成员方法，但不继承父类的构造方法）。因此，在创建子类对象时，为了初始化从父类继承来的数据成员，系统需要调用其父类的构造方法。C++11新标准中，派生类可以重用其直接基类定义的构造函数，类不能继承默认、拷贝、移动构造函数，如果派生类没有指定，则编译器会自动合成。<br><a id="more"></a></p>
<p>构造原则如下：  </p>
<ol>
<li><p>如果子类没有定义构造方法，则调用父类的无参数的构造方法。  </p>
</li>
<li><p>如果子类定义了构造方法，不论是无参数还是带参数，在创建子类的对象的时候,首先执行父类无参数的构造方法，然后执行自己的构造方法。 </p>
</li>
<li><p>在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数，则会调用父类的默认无参构造函数。  </p>
</li>
<li><p>在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数且父类自己提供了无参构造函数，则会调用父类自己的无参构造函数。  </p>
</li>
<li><p>在创建子类对象时候，如果子类的构造函数没有显示调用父类的构造函数且父类只定义了自己的有参构造函数，则会出错（如果父类只有有参数的构造方法，则子类必须显示调用此带参构造方法）。  </p>
</li>
<li><p>如果子类调用父类带参数的构造方法，需要用初始化父类成员对象的方式</p>
</li>
</ol>
<p>析构函数<br>基类的析构函数声明为虚函数，这样销毁对象时子类会调用子类的析构函数，防止内存泄漏。如果没有定义为虚析构函数，销毁一个子类或者父类对象时，都会调用父类析构函数。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;C-中构造函数和析构函数应该注意的问题&quot;&gt;&lt;a href=&quot;#C-中构造函数和析构函数应该注意的问题&quot; class=&quot;headerlink&quot; title=&quot;C++中构造函数和析构函数应该注意的问题&quot;&gt;&lt;/a&gt;C++中构造函数和析构函数应该注意的问题&lt;/h3&gt;&lt;p&gt;构造方法用来初始化类的对象，与父类的其它成员不同，它不能被子类继承（子类可以继承父类所有的成员变量和成员方法，但不继承父类的构造方法）。因此，在创建子类对象时，为了初始化从父类继承来的数据成员，系统需要调用其父类的构造方法。C++11新标准中，派生类可以重用其直接基类定义的构造函数，类不能继承默认、拷贝、移动构造函数，如果派生类没有指定，则编译器会自动合成。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>数据结构-红黑二叉树</title>
    <link href="http://abumaster.com/2017/04/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E4%BA%8C%E5%8F%89%E6%A0%91/"/>
    <id>http://abumaster.com/2017/04/01/数据结构-红黑二叉树/</id>
    <published>2017-04-01T04:25:53.000Z</published>
    <updated>2017-04-01T06:16:33.910Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://baike.baidu.com/link?url=mBopTNvEQOoavVU5s3cuRGbnLKZpEqoY3bjObubuenp_uCcLmyRAwh1PuuWb_GG-uLYrHyVtzC1h4hVP6pOO87s2UyvehOgd136FgM3x8IcRcaXalJMpEG1KfjIbmCcA">红黑树（Red Black Tree）</a>是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。<br>它是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。<br>红黑树和<a href="http://baike.baidu.com/item/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91">AVL树（平衡二叉树）</a>类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能，而统计性能要优于AVL树，广泛应用到各种程序库中。<br><a id="more"></a><br>它虽然是复杂的，但它的最坏情况运行时间也是非常良好的，并且在实践中是高效的： 它可以在O(log n)时间内做查找，插入和删除，这里的n是树中元素的数目。<br><strong>性质</strong><br>红黑树是每个节点都带有黑色或者红色的二叉查找树。具有二叉树的性质，并且具有以下几个性质：  </p>
<ul>
<li>根节点是黑色   </li>
<li>叶子节点（空节点）是黑色的  </li>
<li>每个红色节点的两个子节点都是黑色的，叶子到根的路径上不能有连续的红色节点  </li>
<li>从任一节点开始到其每个叶子节点的所有路径包含相同数目的黑色节点<br><strong>基本操作</strong><br>左旋、右旋、重新着色三个操作。<br><img src="http://i2.muimg.com/567571/b5b8879e1ac59d7d.jpg" alt="左旋"><br>右旋操作类似，左旋就是将旋转的节点变为左子树，提取右节点上来，右旋是将右旋节点变为右子树，提取左节点上来。  </li>
</ul>
<p><strong>插入</strong>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://baike.baidu.com/link?url=mBopTNvEQOoavVU5s3cuRGbnLKZpEqoY3bjObubuenp_uCcLmyRAwh1PuuWb_GG-uLYrHyVtzC1h4hVP6pOO87s2UyvehOgd136FgM3x8IcRcaXalJMpEG1KfjIbmCcA&quot;&gt;红黑树（Red Black Tree）&lt;/a&gt;是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组。&lt;br&gt;它是在1972年由Rudolf Bayer发明的，当时被称为平衡二叉B树（symmetric binary B-trees）。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的“红黑树”。&lt;br&gt;红黑树和&lt;a href=&quot;http://baike.baidu.com/item/%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91&quot;&gt;AVL树（平衡二叉树）&lt;/a&gt;类似，都是在进行插入和删除操作时通过特定操作保持二叉查找树的平衡，从而获得较高的查找性能，而统计性能要优于AVL树，广泛应用到各种程序库中。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>动态规划-背包问题</title>
    <link href="http://abumaster.com/2017/03/31/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92-%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/03/31/动态规划-背包问题/</id>
    <published>2017-03-31T00:41:50.000Z</published>
    <updated>2017-03-31T01:46:12.686Z</updated>
    
    <content type="html"><![CDATA[<p><strong>题目描述</strong><br>有 a，b，c 三个物体，<br>重量记为 W 5，4，3<br>价值记为 V 20 10 12<br>有一个背包容量 C = 10 ，问：可以装的最大价值为多少？  </p>
<a id="more"></a>
<p>解决动态规划问题的主要方法是找到<strong>状态转移方程</strong>，动态规划全局最优包含了局部最优解。<br>分析上述问题：<br>背包容量10，首先，第一个物品有装入和不装入两种情况，转入的话状态变为：容量5，物品重量4,3物品价值10,12；不装入则变为：容量10，物品质量4,3，价值10,12。因此可以定义：<code>dp[i][j]表示前i个物品装到剩余容量为j的背包中的价值 dp[3][10]即为所求的结果</code>，有了状态，这个状态是如何转移的呢？由上面的分析，可知，第i个物品有装入和不装入两种情况，因此状态转移方程可以表示如下：<code>dp[i][j] = Max(dp[i-1][j], dp[i-1][j-w[i]]+v[i])</code>。容易写出代码：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</div><div class="line">&#123;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>; j&lt;=C; j++)</div><div class="line">	&#123;</div><div class="line">		dp[i][j] = (i==<span class="number">0</span>?<span class="number">0</span>:dp[i<span class="number">-1</span>][j]);</div><div class="line">		<span class="keyword">if</span>(i&gt;<span class="number">0</span> &amp;&amp; j&gt;=W[i]) </div><div class="line">			dp[i][j] = Max(dp[i<span class="number">-1</span>][j], dp[i<span class="number">-1</span>][j-w[i]]+v[i]);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>关于优化空间复杂度</strong><br>上述存储状态方程为二维数组，可以压缩为一维数组，<code>dp[i][j]变为dp[j]</code>避免了重复的计算。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">memeset(dp, <span class="number">0</span>, <span class="keyword">sizeof</span>(dp));</div><div class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</div><div class="line">&#123;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> j=C; j&gt;=<span class="number">0</span>; j++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">if</span>(i&gt;<span class="number">0</span>  &amp;&amp; j&gt;=W[i]) </div><div class="line">			dp[j] = Max(dp[j], dp[j-W[i]]+V[i]);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>[网易2017实习笔试题-双核处理]</strong><br>题目描述：<br>一种双核CPU的两个核能够同时的处理任务，现在有n个已知数据量的任务需要交给CPU处理，假设已知CPU的每个核1秒可以处理1kb，每个核同时只能处理一项任务。n个任务可以按照任意顺序放入CPU进行处理，现在需要设计一个方案让CPU处理完这批任务所需的时间最少，求这个最小的时间。<br>输入描述：  </p>
<blockquote>
<p>输入包括两行：<br>第一行为整数n(1 ≤ n ≤ 50)<br>第二行为n个整数length<a href="1024 ≤ length[i] ≤ 4194304">i</a>，表示每个任务的长度为length[i]kb，每个数均为1024的倍数。</p>
</blockquote>
<p>输出描述：</p>
<blockquote>
<p>输出一个整数，表示最少需要处理的时间</p>
</blockquote>
<p>输入输出例子：  </p>
<blockquote>
<p>5<br>3072 3072 7168 3072 1024<br>9216  </p>
</blockquote>
<p><em>解题思路:</em><br>双核可以同时运行，故可以把任务分成两组，交由两个核顺序执行，最短执行时间取决于最后一个执行完成的时间，因此，两个数组长度相差越小，执行的时间也是越短的，换句话说，使其中一个数组无限接近输入数据总长度的一半sum/2即可。执行的时间为sum-sum/2。可以变为简单的背包问题：<strong>背包容量sum/2，物体重量为输入数据的长度，尽可能装满背包</strong>。状态转移方程可以记为：<code>dp[i][j] = max(dp[i-1][j], dp[i-1][j-w[i]]+w[i]), dp[i][j]表示前i个物品在体积为j时可以填充的重量。</code>  同样可以压缩数组变为一维，如上。<br>代码：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;  </span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;  </div><div class="line"><span class="keyword">int</span> dp[<span class="number">210000</span>];  </div><div class="line"><span class="keyword">int</span> n,arr[<span class="number">51</span>];  </div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>  </div><div class="line"></span>&#123;  </div><div class="line">    <span class="keyword">int</span> n;  </div><div class="line">    <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;n);  </div><div class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;  </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; n ; i ++)&#123;  </div><div class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;arr[i]);  </div><div class="line">        arr[i] /= <span class="number">1024</span>;  </div><div class="line">        sum += arr[i];  </div><div class="line">    &#125;</div><div class="line">    <span class="built_in">memset</span>(dp, <span class="number">0</span>, <span class="keyword">sizeof</span>(dp));  </div><div class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span> ; i &lt; n ; i ++)  </div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = sum/<span class="number">2</span> ; j &gt;= arr[i] ; --j)  </div><div class="line">            dp[j] = max(dp[j],dp[j-arr[i]]+arr[i]);</div><div class="line">    <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,(sum-dp[sum/<span class="number">2</span>])*<span class="number">1024</span>);  </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;题目描述&lt;/strong&gt;&lt;br&gt;有 a，b，c 三个物体，&lt;br&gt;重量记为 W 5，4，3&lt;br&gt;价值记为 V 20 10 12&lt;br&gt;有一个背包容量 C = 10 ，问：可以装的最大价值为多少？  &lt;/p&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
</feed>
