<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张国丰</title>
  <subtitle>张国丰的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://abumaster.com/"/>
  <updated>2017-05-20T01:52:58.769Z</updated>
  <id>http://abumaster.com/</id>
  
  <author>
    <name>abumaster</name>
    <email>1902819397@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>UNIX环境高级编程-进程</title>
    <link href="http://abumaster.com/2017/05/19/UNIX%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E8%BF%9B%E7%A8%8B/"/>
    <id>http://abumaster.com/2017/05/19/UNIX环境高级编程-进程/</id>
    <published>2017-05-19T02:22:59.000Z</published>
    <updated>2017-05-20T01:52:58.769Z</updated>
    
    <content type="html"><![CDATA[<p>Unix环境高级编程，第7、8、9章有关进程的读书笔记。<br><a id="more"></a></p>
<h3 id="进程环境"><a href="#进程环境" class="headerlink" title="进程环境"></a>进程环境</h3><p>进程的启动和终止。一般c程序从入口函数<code>main</code>开始，调用一系列用户函数等；进程终止有正常终止和异常终止两种，其中，正常终止是程序从main函数返回(return)，或者正常调用退出函数<code>exit _exit _Exit</code>，或者线程的返回或退出，异常终止通常会调用<code>abort</code>或者信号中断。<br><strong>命令行参数和环境表</strong><br>它们都是有外界给程序的参数，就像标注的 ISO C 规定的主函数书写格式
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc,<span class="keyword">char</span> *argv[]</span></span></div></pre></td></tr></table></figure></p>
<p>将命令行参数保存，而环境变量表则被取消了，仍可以通过函数访问环境表。 
查看和设置环境变量，<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">char</span> *<span class="title">getenv</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* envname)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">putenv</span><span class="params">(<span class="keyword">char</span> *str)</span></span>;<span class="comment">//不会分配空间</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">setenv</span><span class="params">(<span class="keyword">char</span> *name, <span class="keyword">char</span> *value, <span class="keyword">int</span> rewrite)</span></span>;<span class="comment">//分配空间</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">unsetenv</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *name)</span></span>;</div></pre></td></tr></table></figure></p>
<p><strong>C 程序的存储空间分布</strong><br>如图：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-19/39758826-file_1495161867318_14f4a.png" alt="">   </p>
<ul>
<li>正文段，存放程序运行所需的机器指令部分，具有只读属性；  </li>
<li>初始化数据段，明确初始化的变量；</li>
<li>未初始化的数据；  </li>
<li>栈，存放自动变量或者临时变量；  </li>
<li>堆，动态分配的空间。  </li>
</ul>
<p><strong>非局部goto</strong><br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;setjmp.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">setjmp</span><span class="params">(jmp_buf env)</span></span>;<span class="comment">//设置返回的位置</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">longjmp</span><span class="params">(jmp_buf env, <span class="keyword">int</span> val)</span></span>;<span class="comment">//开始返回</span></div></pre></td></tr></table></figure></p>
<p>回滚一些变量的值，如果不想回滚到之前的值，可以将变量定义为：volatile，全局或静态变量的值也会保持不变。  </p>
<h3 id="进程控制"><a href="#进程控制" class="headerlink" title="进程控制"></a>进程控制</h3><p><strong>进程标识符</strong><br>非负整型来表示唯一进程ID，但是可以重用，通常ID=0表示交换进程或者调度进程，ID=1表示init进程，ID=2表示页守护进程。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="keyword">pid_t</span> getpid();<span class="comment">//进程ID</span></div><div class="line"><span class="keyword">pid_t</span> getppid();<span class="comment">//父进程ID</span></div></pre></td></tr></table></figure></p>
<p><strong>fork函数</strong><br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="keyword">pid_t</span> fork(<span class="keyword">void</span>);</div></pre></td></tr></table></figure></p>
<p>两个返回，子进程返回0，通过getppid获得父进程id，ID为0，是交换进程使用，父进程返回子进程的ID，因为，这是父进程获得子进程ID的唯一方式。<br><strong>exec函数</strong><br>fork创建新进程，exec可以执行新程序，exit处理终止，wait等待终止。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Unix环境高级编程，第7、8、9章有关进程的读书笔记。&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://abumaster.com/categories/linux/"/>
    
    
      <category term="Linux" scheme="http://abumaster.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>UNIX环境高级编程-标准IO库</title>
    <link href="http://abumaster.com/2017/05/18/UNIX%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E6%A0%87%E5%87%86IO%E5%BA%93/"/>
    <id>http://abumaster.com/2017/05/18/UNIX环境高级编程-标准IO库/</id>
    <published>2017-05-18T00:39:42.000Z</published>
    <updated>2017-05-18T02:11:33.522Z</updated>
    
    <content type="html"><![CDATA[<p>Unix环境高级编程读书笔记，第5章 标准I/O库。引入流的概念，并引入缓冲，减少read和write的调用次数。<br><a id="more"></a></p>
<p><strong>1.文件I/O和标准I/O区别</strong><br>标准I/O使用了缓冲机制，文件I/O不使用，而是直接调用内核中的一个系统调用完成。操作的对象不同，文件io操作的是文件描述符，标准io操作的是流，流与磁盘等外围设备关联。他们的函数对比。  </p>
<table>
<thead>
<tr>
<th>操作</th>
<th>标准I/O</th>
<th>文件I/O</th>
</tr>
</thead>
<tbody>
<tr>
<td>打开</td>
<td>fopen, froen, fdopen</td>
<td>open</td>
</tr>
<tr>
<td>关闭</td>
<td>fclose</td>
<td>close</td>
</tr>
<tr>
<td>读</td>
<td>getc, fgetc, getchar,<br>fgets, gets,<br>fread</td>
<td>read</td>
</tr>
<tr>
<td>写</td>
<td>putc, fputc, putchar,<br>fputs, puts,<br>fwrite</td>
<td>write</td>
</tr>
</tbody>
</table>
<p><strong>2.缓冲</strong>  </p>
<blockquote>
<p>标准I/O提供的几种缓冲及其区别。  </p>
</blockquote>
<ul>
<li>全缓冲，填满缓冲区后再进行实际的I/O操作，磁盘文件通常使用全缓冲。填满缓冲区后，调用fflush来刷新缓冲区，flush(冲洗)用来将缓冲区的内容写到磁盘上；flush(刷清)丢弃已经存储在缓冲区中的数据，用在终端驱动程序方面。  </li>
<li>行缓冲，用在终端的输入输出，遇到换行符的时候，或者缓冲区满。  </li>
<li>无缓冲，标准出错流，stderr，错误信息及时显示出来。  </li>
</ul>
<p>对于一个打开的流，设置更改缓冲区。
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">setbuf</span><span class="params">(FILE *<span class="keyword">restrict</span> fp, <span class="keyword">char</span> *<span class="keyword">restrict</span> buf)</span></span>;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">setvbuf</span><span class="params">(FILE *<span class="keyword">restrict</span> fp, <span class="keyword">char</span> *<span class="keyword">restrict</span> buf, <span class="keyword">int</span> mode, <span class="keyword">size_t</span> size)</span></span>;</div><div class="line"><span class="comment">/* 	mode 参数：</div><div class="line">	_IOFBF 全缓冲；_IOLBF 行缓冲；_IONBF 不带缓冲</div><div class="line"> */</span></div><div class="line"><span class="comment">//强制冲洗流</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">fflush</span><span class="params">(FILE *fp)</span></span>;</div></pre></td></tr></table></figure></p>
<p><strong>3.操作</strong><br><strong>打开关闭流</strong><br>打开关闭标准I/O流，如上表的函数所示。<br><strong>读写流</strong><br>打开了流，有三种类型的方式进行读写操作：  </p>
<ul>
<li>每次一个字符的I/O;  </li>
<li>每次一行的I/O;  </li>
<li>直接I/O。  </li>
</ul>
<p>每个流在FILE对象上维持了两个标志：出错标志，文件结束标志。<br><code>gets</code> 和<code>fgets</code>，不推荐使用前者，因为不能指定缓冲区大小，容易造成缓冲区溢出，另外，<code>gets</code>不保留换行符。<br><strong>4.临时文件</strong><br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">char</span>* <span class="title">tmpnam</span><span class="params">(<span class="keyword">char</span> *ptr)</span></span>;<span class="comment">//指向唯一路径的指针</span></div><div class="line"><span class="function"><span class="keyword">char</span> *<span class="title">tmpfile</span><span class="params">(<span class="keyword">void</span>)</span></span>; <span class="comment">//返回文件指针</span></div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Unix环境高级编程读书笔记，第5章 标准I/O库。引入流的概念，并引入缓冲，减少read和write的调用次数。&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://abumaster.com/categories/linux/"/>
    
    
      <category term="Linux" scheme="http://abumaster.com/tags/linux/"/>
    
      <category term="c" scheme="http://abumaster.com/tags/c/"/>
    
      <category term="编程" scheme="http://abumaster.com/tags/%E7%BC%96%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>UNIX环境高级编程-文件和目录</title>
    <link href="http://abumaster.com/2017/05/16/UNIX%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E6%96%87%E4%BB%B6%E5%92%8C%E7%9B%AE%E5%BD%95/"/>
    <id>http://abumaster.com/2017/05/16/UNIX环境高级编程-文件和目录/</id>
    <published>2017-05-16T11:39:00.000Z</published>
    <updated>2017-05-17T06:52:07.469Z</updated>
    
    <content type="html"><![CDATA[<p>UNIX环境高级编程读书笔记，第4章 文件和目录。<br><a id="more"></a></p>
<blockquote>
<p>I/O操作描述的是普通文件的读写等操作，本章介绍文件系统的其他特征和文件的性质。  </p>
</blockquote>
<p><strong>1.三个stat函数</strong><br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/stat.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">stat</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *<span class="keyword">restrict</span> pathname, <span class="keyword">struct</span> stat *<span class="keyword">restrict</span> buf)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">fstat</span><span class="params">(<span class="keyword">int</span> filedes, <span class="keyword">struct</span> stat *buf)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">lstat</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *<span class="keyword">restrict</span> pathname, <span class="keyword">struct</span> stat *<span class="keyword">restrict</span> buf)</span></span>;</div></pre></td></tr></table></figure></p>
<p>返回与此文件相关联的信息结构stat，关于stat的结构说明：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> stat &#123;</div><div class="line">	<span class="keyword">mode_t</span> st_mode;<span class="comment">//文件类型</span></div><div class="line">	<span class="keyword">ino_t</span> st_ino;<span class="comment">//i节点</span></div><div class="line">	<span class="keyword">dev_t</span> st_dev;<span class="comment">//设备号 文件系统</span></div><div class="line">	<span class="keyword">dev_t</span> st_rdev;</div><div class="line">	<span class="keyword">nlink_t</span> st_nlink;</div><div class="line">	<span class="keyword">uid_t</span> st_uid;</div><div class="line">	<span class="keyword">gid_t</span> st_gid;</div><div class="line">	<span class="keyword">off_t</span> st_size;<span class="comment">//大小</span></div><div class="line">	<span class="keyword">time_t</span> st_atime;<span class="comment">//访问时间</span></div><div class="line">	<span class="keyword">time_t</span> st_mtime;<span class="comment">//修改时间</span></div><div class="line">	<span class="keyword">time_t</span> st_ctime;<span class="comment">//改变时间</span></div><div class="line">	<span class="keyword">blksize_t</span> st_blksize;<span class="comment">//块大小</span></div><div class="line">	<span class="keyword">blkcnt_t</span> st_blocks;<span class="comment">//分配的磁盘块</span></div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>2.文件类型</strong>  </p>
<ul>
<li>普通文件；  </li>
<li>目录文件；  </li>
<li>块特殊文件；  </li>
<li>字符特殊文件；  </li>
<li>FIFO，进程间通信，命名管道；</li>
<li>套接字，网络间通信；  </li>
<li>符号链接<br>在<code>&lt;sys/stat.h&gt;</code>中定义了获取文件类型的宏，参数为<code>st_mode</code>成员。  </li>
</ul>
<table>
<thead>
<tr>
<th>宏</th>
<th>文件类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>S_ISREG()</td>
<td>普通文件</td>
</tr>
<tr>
<td>S_ISDIR()</td>
<td>目录文件</td>
</tr>
<tr>
<td>S_ISCHR()</td>
<td>字符特殊文件</td>
</tr>
<tr>
<td>S_ISBLK()</td>
<td>块特殊文件</td>
</tr>
<tr>
<td>S_ISFIFO()</td>
<td>管道或FIFO</td>
</tr>
<tr>
<td>S_ISLNK()</td>
<td>符号链接</td>
</tr>
<tr>
<td>S_ISSOCK()</td>
<td>套接字</td>
</tr>
</tbody>
</table>
<p><strong>3.文件的访问权限</strong><br>分为三类：用户、组、其他，而每类对应的权限为：读、写、执行。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-16/90333911-file_1494936405039_f79a.png" alt=""><br><strong>4.文件系统</strong><br>i节点：固定长度的记录项，保存着文件的大部分信息。<a href="http://www.ruanyifeng.com/blog/2011/12/inode.html">理解inode</a>。内核中，以inode编号来标识文件，而不是以文件名标识文件。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;UNIX环境高级编程读书笔记，第4章 文件和目录。&lt;br&gt;
    
    </summary>
    
      <category term="Linux" scheme="http://abumaster.com/categories/linux/"/>
    
    
      <category term="Linux" scheme="http://abumaster.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>UNIX环境高级编程-文件IO</title>
    <link href="http://abumaster.com/2017/05/15/UNIX%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B-%E6%96%87%E4%BB%B6IO/"/>
    <id>http://abumaster.com/2017/05/15/UNIX环境高级编程-文件IO/</id>
    <published>2017-05-15T12:29:43.000Z</published>
    <updated>2017-05-16T12:46:55.147Z</updated>
    
    <content type="html"><![CDATA[<p>UNIX环境高级编程读书笔记，第3章 文件 I/O。
<a id="more"></a></p>
<h3 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h3><p>Linux一切皆文件，无论是设备还是文档都是一个文件，这种抽象显示了Linux系统的灵活和通用性。文件描述符一般是一个非负整数，当打开或者创建一个文件时，内核向进程返回一个文件描述符，此描述符用于其他操作的参数。<br>通常在<code>unistd.h</code>中定义了常量：<code>STDIN_FILENO STDOUT_FILENO STDERR_FILENO</code>分别代表数字0,1,2是标准输入输出错误输出三种基本的文件描述符。<br><strong>open函数</strong><br>描述：打开或者创建文件，返回文件描述符或者-1<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">oepn</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span>* pathname, <span class="keyword">int</span> flags,...<span class="comment">/*mode_t mode*/</span>)</span></span>;</div></pre></td></tr></table></figure></p>
<p><strong>creat函数</strong><br>描述：创建一个文件，只能只写的方式打开，成功返回文件描述符，失败-1<br><strong>close函数</strong><br>描述：关闭文件描述符<br><strong>lseek函数</strong><br>描述：为一个打开的文件描述符设置偏移量，成功返回新的文件偏移量，失败-1<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="keyword">off_t</span> lseek(<span class="keyword">int</span> filedes, <span class="keyword">off_t</span> offset, <span class="keyword">int</span> whence);</div></pre></td></tr></table></figure></p>
<p>偏移量的方式取决于第三个参数。<code>SEEK_SET</code> 开始处设置偏移量，绝对偏移量；<code>SEEK_CUR</code> 当前位置设置偏移量，相对偏移量；<code>SEEK_END</code> 结束开始设置偏移量，相对于文件末端偏移量。<br><strong>read函数</strong><br>打开的文件中读取数据，返回读取的字节数，如果剩余文件不够要读的字节数。<br><strong>write函数</strong><br>向打开的文件中写数据，返回实际写入的数据字节数。  </p>
<h3 id="文件共享"><a href="#文件共享" class="headerlink" title="文件共享"></a>文件共享</h3><p>不同进程之间共享打开的文件，内核使用三种数据结构表示打开的文件。<br><strong>1.进程表项</strong><br>描述一个打开的文件描述表，每个文件描述符表包含了两项：  </p>
<ul>
<li>文件描述符标志   </li>
<li>指向文件表项的指针<br><strong>2.文件表</strong><br>每个文件表包含如下信息：  </li>
<li>文件状态标志（读写…)  </li>
<li>当前文件偏移量  </li>
<li>指向文件v节点表项的指针<br><strong>3.v节点表</strong><br>v节点表表示文件类型，以及对文件进行各种操作的指针，也包含了i节点及文件长度等信息。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-15/62478241-file_1494854203087_11715.png" alt=""><br>不同进程打开同一个文件的各项状态。  </li>
</ul>
<p><strong>dup和dup2函数</strong><br>用来复制一个现存的文件描述符。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">dup</span><span class="params">(<span class="keyword">int</span> filedes)</span></span>;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">dup2</span><span class="params">(<span class="keyword">int</span> filedes, <span class="keyword">int</span> filedes2)</span></span>;</div></pre></td></tr></table></figure></p>
<p>dup返回的文件描述符是当前可用文件描述符的最小值；dup2可以用filedes来指定新的描述符，如果filedes2已经打开，则先将其关闭，如果相等，则返回filedes2，不必关闭。<br>执行dup后，文件表项和v节点表项不变。<br>作用：一般用于重定向和共享文件，如父进程处理了一些文件，现在需要子进程处理，可以dup一份；同样dup2的使用，可以看为<code>dup2(源, 目标)</code>，目标将会被源替换掉。具体<a href="http://blog.csdn.net/zhouhong1026/article/details/8151235">使用</a>。<br><strong>fcntl函数</strong><br>可以读取和改变打开文件的性质。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">fcntl</span><span class="params">(<span class="keyword">int</span> filedes, <span class="keyword">int</span> cmd, ...<span class="comment">/*int arg*/</span>)</span></span>;</div></pre></td></tr></table></figure></p>
<p>fnctl的功能：  </p>
<p><1>    复制一个现有的描述符，cmd=F_DUPFD</1>  </p>
<p><2>    获取/设置文件描述符标记(cmd=F_GETFD / F_SETFD)</2>  </p>
<p><3>    获得和设置文件状态标志<code>cmd=F_GETFL F_SETFL</code></3>  </p>
<p><4>    获取和设置异步I/O所有权<code>cmd=F_GETOWN F_SETOWN</code></4>  </p>
<p><5>    获得和设置记录锁<code>cmd = F_GETLK F_SETLK</code></5><br>同样，复制文件描述符函数：<code>dup(filedes)</code>等价于<code>fcntl(filedes, F_DUPFD, 0)</code>。调用<code>dup2(filedes1,filedes2)</code>相当于调用：<code>close(filedes2); fcntl(filedes1, F_DUPFD, filedes2)</code>。不同之处在于dup2函数是原子操作，而用fcntl是两个函数调用。<br>dup2的功能:<br><figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">dup2(fd, <span class="number">0</span>);</div><div class="line">dup2(fd, <span class="number">1</span>);</div><div class="line">dup2(fd, <span class="number">2</span>);</div><div class="line"><span class="keyword">if</span>(fd &gt; <span class="number">2</span>)</div><div class="line">	close(fd);</div></pre></td></tr></table></figure></p>
<p>假设fd=1，则执行后的结果图如下：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-16/22619423-file_1494918444995_14a6d.png" alt=""><br>fd=3时，结果同，把3的文件复制到前3个上，删除以后的。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;UNIX环境高级编程读书笔记，第3章 文件 I/O。
    
    </summary>
    
      <category term="Linux" scheme="http://abumaster.com/categories/linux/"/>
    
    
      <category term="Linux" scheme="http://abumaster.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>High-performance Semantic Segmentation using VDFC</title>
    <link href="http://abumaster.com/2017/05/10/High-performance-Semantic-Segmentation-using-VDFC/"/>
    <id>http://abumaster.com/2017/05/10/High-performance-Semantic-Segmentation-using-VDFC/</id>
    <published>2017-05-10T07:37:56.000Z</published>
    <updated>2017-05-10T13:22:27.862Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>High-performance Semantic Segmentation Using Very Deep Fully Convolution [1] ，论文阅读笔记。</p>
</blockquote>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
</script>

<a id="more"></a>
<p>本文做的贡献：</p>
<ul>
<li>探索不同的<strong>全卷积残差网络</strong>找到更好的配置，诸如，网络的层数、特征图的分辨率、感受野的大小等，由于内存的限制等因素，提出了用低分辨率网络来模拟高分辨网络进行训练和测试；  </li>
<li>提出了<strong>在线引导（online booststrapping）</strong>的方法进行训练，已经论证可以达到更好的正确率；  </li>
<li>将传统的dropout应用到残差块中；  </li>
<li>达到了很好的结果。</li>
</ul>
<h4 id="1-低分辨率近似高分辨率的模型"><a href="#1-低分辨率近似高分辨率的模型" class="headerlink" title="1.低分辨率近似高分辨率的模型"></a>1.低分辨率近似高分辨率的模型</h4><p><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-10/90074102-file_1494405779021_148f4.png" alt=""><br>由于内存的限制，网络不允许输入过大分辨率的图像，但是分辨率大的图像往往可以保存更多的细节信息，可以达到更好的分割效果，所以，提出了这个低分辨率来近似高分辨率的模型。基本的做法是：如果输入一个图像，经过了中间的若干层，图像的分辨率会下降，假设缩小为原始的1/8，（1）产生了一个1/8的特征图，这时，（2）可以在上一层池化层提取出剩下1/8的图像，（3）分别获得两个1/8的得分图，（4）组合，得到1/4的得分图或者是标签。</p>
<h4 id="2-损失函数"><a href="#2-损失函数" class="headerlink" title="2.损失函数"></a>2.损失函数</h4><p>$$ e = -\frac{1}{\sum_i^N \sum_j^K{1\{y_i=j\ and\ p_{ij}&lt;t\}}}(\sum_i^N\sum_j^K1\{y_i=j \ and\ p_{ij}&lt;t\}logp_{ij})$$   </p>
<p>[1] Wu Z, Shen C, Hengel A. High-performance semantic segmentation using very deep fully convolutional networks[J]. arXiv preprint arXiv:1604.04339, 2016.</p>
<p>K表示语义标签，N表示像素的个数，$p_{ij}$表示像素$a_i$分到标签$c_j$的概率，$y_i$表示$a_i$的正确标签。符号$1{.}$表示满足括号里的条件为1，不满足为0。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;High-performance Semantic Segmentation Using Very Deep Fully Convolution [1] ，论文阅读笔记。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;
&lt;/script&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>宏定义</title>
    <link href="http://abumaster.com/2017/05/09/%E5%AE%8F%E5%AE%9A%E4%B9%89/"/>
    <id>http://abumaster.com/2017/05/09/宏定义/</id>
    <published>2017-05-09T12:36:26.000Z</published>
    <updated>2017-05-09T13:35:49.257Z</updated>
    
    <content type="html"><![CDATA[<p>宏定义进入编译器之前展开替换。<br><a id="more"></a>
<strong>宏常量</strong><br><code>#define MAX 100</code>用100替换符号MAX，c++中一般不推荐使用，通常用常量const定义；<br><strong>用于条件编译的宏</strong><br>如避免包含重复头文件的宏：
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#ifdefine XXX </span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> XXX </span></div><div class="line"><span class="comment">//some include file</span></div><div class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></div><div class="line">`</div></pre></td></tr></table></figure></p>
<p><strong>宏函数</strong><br>避免函数调用，提高执行效率，以空间换取时间。<br>对于一些重复的函数可以声明为宏函数，就像内联函数一样…<br>例子：
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(*Onefunction)</span><span class="params">()</span></span>;<span class="comment">//定义函数指针</span></div><div class="line"><span class="keyword">typedef</span> <span class="built_in">map</span>&lt;<span class="built_in">string</span>, Onefunction&gt; OneMap;<span class="comment">//名称，函数指针相关联的map</span></div><div class="line">OneMap g_one_map;<span class="comment">//全局变量保存</span></div><div class="line"></div><div class="line"><span class="comment">//注册函数的宏，其中展开为一个按名定义的类，</span></div><div class="line"><span class="comment">//构造函数,将函数地址和函数名称放入全局的map中</span></div><div class="line"><span class="comment">//最后一个简单的类对象声明，可以保证构造函数的执行，</span></div><div class="line"><span class="comment">//作用域可以保证在执行完后对象的销毁，用过即销毁。</span></div><div class="line"><span class="meta">#<span class="meta-keyword">define</span> RegisterOneFunction(func) \</div><div class="line">&#123; \</div><div class="line">class __Register_##func &#123; \</div><div class="line">public: \</div><div class="line">__Register_##func() &#123; \</div><div class="line">g_one_map[#func] = &amp;func; \</div><div class="line">&#125; \</div><div class="line">&#125;; \</div><div class="line">__Register_##func g_register_##func; \</div><div class="line">&#125;</span></div><div class="line"><span class="comment">//自定义的函数，无参，返回int</span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">func1</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"func1 out...\n"</span>;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">func2</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="string">"func2 out...222\n"</span>;</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div><div class="line"><span class="comment">//调用宏，注册函数</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">WrapperRegisterFunction</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	RegisterOneFunction(func1);</div><div class="line">	RegisterOneFunction(func2);</div><div class="line">&#125;</div><div class="line"><span class="comment">//根据函数名称获得函数的指针</span></div><div class="line"><span class="function">Onefunction <span class="title">GetOneFunction</span><span class="params">(<span class="keyword">const</span> <span class="built_in">string</span>&amp; fname)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">if</span>(g_one_map.count(fname))</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">return</span> g_one_map[fname];</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">else</span></div><div class="line">	&#123;</div><div class="line">		<span class="built_in">cout</span> &lt;&lt; <span class="string">"not found"</span>&lt;&lt;<span class="built_in">endl</span>;</div><div class="line">		<span class="keyword">for</span>(OneMap::iterator it=g_one_map.begin();</div><div class="line">			it!=g_one_map.end(); it++)</div><div class="line">		&#123;</div><div class="line">			<span class="built_in">cout</span> &lt;&lt;it-&gt;first&lt;&lt;<span class="string">" "</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</div><div class="line">		<span class="keyword">return</span> <span class="literal">NULL</span>;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">string</span> funNmae;</div><div class="line"></div><div class="line">	WrapperRegisterFunction();</div><div class="line"></div><div class="line">	<span class="built_in">cin</span> &gt;&gt; funNmae;</div><div class="line">	<span class="comment">//以名称来使用函数</span></div><div class="line">	GetOneFunction(funNmae)();</div><div class="line"></div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>注意事项</strong>  </p>
<p>1.普通宏定义  </p>
<ul>
<li>宏名一般用大写  </li>
<li>使用宏可提高程序的通用性和易读性，减少不一致性，减少输入错误和便于修改  </li>
<li>预处理是在编译之前的处理，而编译工作的任务之一就是语法检查，预处理不做语法检查  </li>
<li>宏定义末尾不加分号  </li>
<li>宏定义写在函数的花括号外边，作用域为其后的程序，通常在文件的最开头  </li>
<li>可以用#undef命令终止宏定义的作用域  </li>
<li>宏定义可以嵌套   </li>
<li>字符串””中永远不包含宏  </li>
<li>宏定义不分配内存，变量定义分配内存<br>2.带参宏定义  </li>
<li>实参如果是表达式容易出问题  </li>
<li>宏名和参数的括号间不能有空格  </li>
<li>宏替换只作替换，不做计算，不做表达式求解  </li>
<li>函数调用在编译后程序运行时进行，并且分配内存。宏替换在编译前进行，不分配内存  </li>
<li>宏的哑实结合不存在类型，也没有类型转换  </li>
<li>函数只有一个返回值，利用宏则可以设法得到多个值  </li>
<li>宏展开使源程序变长，函数调用不会  </li>
<li>宏展开不占运行时间，只占编译时间，函数调用占运行时间（分配内存、保留现场、值传递、返回值）  </li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;宏定义进入编译器之前展开替换。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>caffe学习-分类</title>
    <link href="http://abumaster.com/2017/05/07/%E2%80%98caffe%E5%AD%A6%E4%B9%A0-%E5%88%86%E7%B1%BB/"/>
    <id>http://abumaster.com/2017/05/07/‘caffe学习-分类/</id>
    <published>2017-05-07T11:29:00.000Z</published>
    <updated>2017-05-08T12:39:47.386Z</updated>
    
    <content type="html"><![CDATA[<p>在用caffe的c++接口时，遇到了许多问题，学习源码中解决问题，熟悉一些细节。<br><a id="more"></a>
<strong>1.预测分类的流程图</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-8/16381803-file_1494210884331_288e.png" alt="预测流程图">  </p>
<p><strong>2.代码注释</strong><br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div></pre></td><td class="code"><pre><div class="line">//classification.cpp</div><div class="line">/*一些头文件*/</div><div class="line">#ifdef USE_OPENCV</div><div class="line">/* Pair (label, confidence) </div><div class="line"> * 代表一个预测结果，标签和概率的组合</div><div class="line"> */</div><div class="line">typedef std::pair&lt;string, float&gt; Prediction;</div><div class="line">//定义一个分类的类</div><div class="line">class Classifier &#123;</div><div class="line"> public:</div><div class="line">  Classifier(const string&amp; model_file,</div><div class="line">             const string&amp; trained_file,</div><div class="line">             const string&amp; mean_file,</div><div class="line">             const string&amp; label_file);</div><div class="line">//提供给外部的接口，返回一个预测。参数：需要预测的图像和概率最大的N个结果</div><div class="line">  std::vector&lt;Prediction&gt; Classify(const cv::Mat&amp; img, int N = 5);</div><div class="line"></div><div class="line"> private:</div><div class="line">  void SetMean(const string&amp; mean_file);//设置中值</div><div class="line">  std::vector&lt;float&gt; Predict(const cv::Mat&amp; img);</div><div class="line">  void WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels);</div><div class="line">  void Preprocess(const cv::Mat&amp; img,</div><div class="line">                  std::vector&lt;cv::Mat&gt;* input_channels);</div><div class="line"></div><div class="line"> private:</div><div class="line">  shared_ptr&lt;Net&lt;float&gt; &gt; net_;</div><div class="line">  cv::Size input_geometry_;</div><div class="line">  int num_channels_;</div><div class="line">  cv::Mat mean_;</div><div class="line">  std::vector&lt;string&gt; labels_;</div><div class="line">&#125;;</div><div class="line"></div><div class="line">Classifier::Classifier(const string&amp; model_file,</div><div class="line">                       const string&amp; trained_file,</div><div class="line">                       const string&amp; mean_file,</div><div class="line">                       const string&amp; label_file) &#123;</div><div class="line">#ifdef CPU_ONLY</div><div class="line">  Caffe::set_mode(Caffe::CPU);</div><div class="line">#else</div><div class="line">  Caffe::set_mode(Caffe::GPU);</div><div class="line">#endif</div><div class="line">  //加载网络配置并初始化</div><div class="line">  net_.reset(new Net&lt;float&gt;(model_file, TEST));</div><div class="line">  net_-&gt;CopyTrainedLayersFrom(trained_file);</div><div class="line">  CHECK_EQ(net_-&gt;num_inputs(), 1) &lt;&lt; "Network should have exactly one input.";</div><div class="line">  CHECK_EQ(net_-&gt;num_outputs(), 1) &lt;&lt; "Network should have exactly one output.";</div><div class="line">  //取出输入层的blob结构，可以提取出通道和输入图像的高宽</div><div class="line">  Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];</div><div class="line">  num_channels_ = input_layer-&gt;channels();</div><div class="line">  CHECK(num_channels_ == 3 || num_channels_ == 1)</div><div class="line">    &lt;&lt; "Input layer should have 1 or 3 channels.";</div><div class="line">  input_geometry_ = cv::Size(input_layer-&gt;width(), input_layer-&gt;height());</div><div class="line"></div><div class="line">  //加载中值文件</div><div class="line">  SetMean(mean_file);</div><div class="line"></div><div class="line">  //加载标签文件</div><div class="line">  std::ifstream labels(label_file.c_str());</div><div class="line">  CHECK(labels) &lt;&lt; "Unable to open labels file " &lt;&lt; label_file;</div><div class="line">  string line;</div><div class="line">  while (std::getline(labels, line))</div><div class="line">    labels_.push_back(string(line));</div><div class="line">  //检查标签数目和输出维度是否匹配</div><div class="line">  Blob&lt;float&gt;* output_layer = net_-&gt;output_blobs()[0];</div><div class="line">  CHECK_EQ(labels_.size(), output_layer-&gt;channels())</div><div class="line">    &lt;&lt; "Number of labels is different from the output layer dimension.";</div><div class="line">&#125;</div><div class="line">//自定义比较函数，用于排序预测结果</div><div class="line">static bool PairCompare(const std::pair&lt;float, int&gt;&amp; lhs,</div><div class="line">                        const std::pair&lt;float, int&gt;&amp; rhs) &#123;</div><div class="line">  return lhs.first &gt; rhs.first;</div><div class="line">&#125;</div><div class="line">//返回v中元素最大的N个数的下标索引</div><div class="line">static std::vector&lt;int&gt; Argmax(const std::vector&lt;float&gt;&amp; v, int N) &#123;</div><div class="line">  std::vector&lt;std::pair&lt;float, int&gt; &gt; pairs;</div><div class="line">  for (size_t i = 0; i &lt; v.size(); ++i)</div><div class="line">    pairs.push_back(std::make_pair(v[i], static_cast&lt;int&gt;(i)));</div><div class="line">  std::partial_sort(pairs.begin(), pairs.begin() + N, pairs.end(), PairCompare);</div><div class="line"></div><div class="line">  std::vector&lt;int&gt; result;</div><div class="line">  for (int i = 0; i &lt; N; ++i)</div><div class="line">    result.push_back(pairs[i].second);</div><div class="line">  return result;</div><div class="line">&#125;</div><div class="line">//输入图像，返回前N个概率最大的预测(标签，概率)</div><div class="line">std::vector&lt;Prediction&gt; Classifier::Classify(const cv::Mat&amp; img, int N) &#123;</div><div class="line">  std::vector&lt;float&gt; output = Predict(img);</div><div class="line"></div><div class="line">  N = std::min&lt;int&gt;(labels_.size(), N);</div><div class="line">  std::vector&lt;int&gt; maxN = Argmax(output, N);</div><div class="line">  std::vector&lt;Prediction&gt; predictions;</div><div class="line">  for (int i = 0; i &lt; N; ++i) &#123;</div><div class="line">    int idx = maxN[i];</div><div class="line">    predictions.push_back(std::make_pair(labels_[idx], output[idx]));</div><div class="line">  &#125;</div><div class="line">  return predictions;</div><div class="line">&#125;</div><div class="line"></div><div class="line">/* Load the mean file in binaryproto format. */</div><div class="line">void Classifier::SetMean(const string&amp; mean_file) &#123;</div><div class="line">  BlobProto blob_proto;</div><div class="line">  ReadProtoFromBinaryFileOrDie(mean_file.c_str(), &amp;blob_proto);</div><div class="line"></div><div class="line">  /* Convert from BlobProto to Blob&lt;float&gt; */</div><div class="line">  Blob&lt;float&gt; mean_blob;</div><div class="line">  mean_blob.FromProto(blob_proto);</div><div class="line">  CHECK_EQ(mean_blob.channels(), num_channels_)</div><div class="line">    &lt;&lt; "Number of channels of mean file doesn't match input layer.";</div><div class="line"></div><div class="line">  /* The format of the mean file is planar 32-bit float BGR or grayscale. */</div><div class="line">  std::vector&lt;cv::Mat&gt; channels;</div><div class="line">  float* data = mean_blob.mutable_cpu_data();</div><div class="line">  for (int i = 0; i &lt; num_channels_; ++i) &#123;</div><div class="line">    /* Extract an individual channel. */</div><div class="line">    cv::Mat channel(mean_blob.height(), mean_blob.width(), CV_32FC1, data);</div><div class="line">    channels.push_back(channel);</div><div class="line">    data += mean_blob.height() * mean_blob.width();</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  /* Merge the separate channels into a single image. */</div><div class="line">  cv::Mat mean;</div><div class="line">  cv::merge(channels, mean);</div><div class="line"></div><div class="line">  /* Compute the global mean pixel value and create a mean image</div><div class="line">   * filled with this value. */</div><div class="line">  cv::Scalar channel_mean = cv::mean(mean);</div><div class="line">  mean_ = cv::Mat(input_geometry_, mean.type(), channel_mean);</div><div class="line">&#125;</div><div class="line">//预测函数，返回输出的概率</div><div class="line">std::vector&lt;float&gt; Classifier::Predict(const cv::Mat&amp; img) &#123;</div><div class="line">  Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];</div><div class="line">  input_layer-&gt;Reshape(1, num_channels_,</div><div class="line">                       input_geometry_.height, input_geometry_.width);</div><div class="line">  /* Forward dimension change to all layers. */</div><div class="line">  net_-&gt;Reshape();</div><div class="line"></div><div class="line">  std::vector&lt;cv::Mat&gt; input_channels;</div><div class="line">  WrapInputLayer(&amp;input_channels);</div><div class="line"></div><div class="line">  Preprocess(img, &amp;input_channels);</div><div class="line"></div><div class="line">  net_-&gt;Forward();</div><div class="line"></div><div class="line">  /* Copy the output layer to a std::vector */</div><div class="line">  Blob&lt;float&gt;* output_layer = net_-&gt;output_blobs()[0];</div><div class="line">  const float* begin = output_layer-&gt;cpu_data();</div><div class="line">  const float* end = begin + output_layer-&gt;channels();</div><div class="line">  return std::vector&lt;float&gt;(begin, end);</div><div class="line">&#125;</div><div class="line"> /* 包装网络的输入层，将每个通道保存为Mat对象，</div><div class="line">  * 最后直接将分割的通道写入到输入层中 */</div><div class="line">void Classifier::WrapInputLayer(std::vector&lt;cv::Mat&gt;* input_channels) &#123;</div><div class="line">  Blob&lt;float&gt;* input_layer = net_-&gt;input_blobs()[0];</div><div class="line"></div><div class="line">  int width = input_layer-&gt;width();</div><div class="line">  int height = input_layer-&gt;height();</div><div class="line">  //获取可更改的输入层数据指针</div><div class="line">  float* input_data = input_layer-&gt;mutable_cpu_data();</div><div class="line">  for (int i = 0; i &lt; input_layer-&gt;channels(); ++i) &#123;</div><div class="line">    cv::Mat channel(height, width, CV_32FC1, input_data);</div><div class="line">    input_channels-&gt;push_back(channel);</div><div class="line">    input_data += width * height;</div><div class="line">  &#125;//将各个通道变为Mat，依次放入vector中</div><div class="line">&#125;</div><div class="line">//图像拷贝入输入层中</div><div class="line">void Classifier::Preprocess(const cv::Mat&amp; img,</div><div class="line">                            std::vector&lt;cv::Mat&gt;* input_channels) &#123;</div><div class="line">  /* 将输入图像转换为网络要求的输入格式 */</div><div class="line">  //通道数</div><div class="line">  cv::Mat sample;</div><div class="line">  if (img.channels() == 3 &amp;&amp; num_channels_ == 1)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_BGR2GRAY);</div><div class="line">  else if (img.channels() == 4 &amp;&amp; num_channels_ == 1)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_BGRA2GRAY);</div><div class="line">  else if (img.channels() == 4 &amp;&amp; num_channels_ == 3)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_BGRA2BGR);</div><div class="line">  else if (img.channels() == 1 &amp;&amp; num_channels_ == 3)</div><div class="line">    cv::cvtColor(img, sample, cv::COLOR_GRAY2BGR);</div><div class="line">  else</div><div class="line">    sample = img;</div><div class="line">  //大小</div><div class="line">  cv::Mat sample_resized;</div><div class="line">  if (sample.size() != input_geometry_)</div><div class="line">    cv::resize(sample, sample_resized, input_geometry_);</div><div class="line">  else</div><div class="line">    sample_resized = sample;</div><div class="line">  //浮点数</div><div class="line">  cv::Mat sample_float;</div><div class="line">  if (num_channels_ == 3)</div><div class="line">    sample_resized.convertTo(sample_float, CV_32FC3);</div><div class="line">  else</div><div class="line">    sample_resized.convertTo(sample_float, CV_32FC1);</div><div class="line">  //归一化处理：减去中值</div><div class="line">  cv::Mat sample_normalized;</div><div class="line">  cv::subtract(sample_float, mean_, sample_normalized);</div><div class="line">  //直接将mat拷贝到输入层，已经处理过输入层为Mat对象了</div><div class="line">  cv::split(sample_normalized, *input_channels);</div><div class="line">  CHECK(reinterpret_cast&lt;float*&gt;(input_channels-&gt;at(0).data)</div><div class="line">        == net_-&gt;input_blobs()[0]-&gt;cpu_data())</div><div class="line">    &lt;&lt; "Input channels are not wrapping the input layer of the network.";</div><div class="line">&#125;</div><div class="line">//主函数命令行调用</div><div class="line">int main(int argc, char** argv) &#123;</div><div class="line">  if (argc != 6) &#123;</div><div class="line">    std::cerr &lt;&lt; "Usage: " &lt;&lt; argv[0]</div><div class="line">              &lt;&lt; " deploy.prototxt network.caffemodel"</div><div class="line">              &lt;&lt; " mean.binaryproto labels.txt img.jpg" &lt;&lt; std::endl;</div><div class="line">    return 1;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  ::google::InitGoogleLogging(argv[0]);</div><div class="line"></div><div class="line">  string model_file   = argv[1];</div><div class="line">  string trained_file = argv[2];</div><div class="line">  string mean_file    = argv[3];</div><div class="line">  string label_file   = argv[4];</div><div class="line">  Classifier classifier(model_file, trained_file, mean_file, label_file);</div><div class="line"></div><div class="line">  string file = argv[5];</div><div class="line"></div><div class="line">  std::cout &lt;&lt; "---------- Prediction for "</div><div class="line">            &lt;&lt; file &lt;&lt; " ----------" &lt;&lt; std::endl;</div><div class="line"></div><div class="line">  cv::Mat img = cv::imread(file, -1);</div><div class="line">  CHECK(!img.empty()) &lt;&lt; "Unable to decode image " &lt;&lt; file;</div><div class="line">  std::vector&lt;Prediction&gt; predictions = classifier.Classify(img);</div><div class="line"></div><div class="line">  /* Print the top N predictions. */</div><div class="line">  for (size_t i = 0; i &lt; predictions.size(); ++i) &#123;</div><div class="line">    Prediction p = predictions[i];</div><div class="line">    std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(4) &lt;&lt; p.second &lt;&lt; " - \""</div><div class="line">              &lt;&lt; p.first &lt;&lt; "\"" &lt;&lt; std::endl;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">#else</div><div class="line">int main(int argc, char** argv) &#123;</div><div class="line">  LOG(FATAL) &lt;&lt; "This example requires OpenCV; compile with USE_OPENCV.";</div><div class="line">&#125;</div><div class="line">#endif  // USE_OPENCV</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在用caffe的c++接口时，遇到了许多问题，学习源码中解决问题，熟悉一些细节。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>Caffe笔记</title>
    <link href="http://abumaster.com/2017/05/01/Caffe%E7%AC%94%E8%AE%B0/"/>
    <id>http://abumaster.com/2017/05/01/Caffe笔记/</id>
    <published>2017-05-01T06:41:52.000Z</published>
    <updated>2017-05-01T12:02:51.565Z</updated>
    
    <content type="html"><![CDATA[<p>Caffe学习中的遇到的一些问题拾遗。<br><a id="more"></a>
<strong>1..solverstate的使用</strong><br>在网络训练过程中当保存一个快照时，会保存两个文件：<code>**.caffemodel</code> 和 <code>**.solverstate</code> 第一个文件是训练过程中，迭代了N次，保存的模型，第二个文件是训练过程意外暂停，如<code>ctrl+C</code> 或者电脑死机，保存的网络状态，下一次网络可以接着训练，参考<a href="https://github.com/BVLC/caffe/wiki/Training-and-Resuming">Caffe Wiki - Training and Resuming</a>。<br>使用：  </p>
<ul>
<li>命令行<br>训练：<code>caffe train -solver solver.prototxt</code><br>状态中恢复训练：<code>caffe train -solver solver.prototxt -snapshot train_190000.solverstate</code>  </li>
<li>Python 接口<br>从模型中copy参数：<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">weights = <span class="string">'../ilsvrc-nets/vgg16-fcn.caffemodel'</span></div><div class="line"><span class="comment"># init</span></div><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)</div><div class="line">solver.net.copy_from(weights)</div></pre></td></tr></table></figure>
</li>
</ul>
<p>从状态中恢复训练：
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)</div><div class="line">solver.restore(<span class="string">'snapshot/train_iter_2000.solverstate'</span>)</div></pre></td></tr></table></figure></p>
<p>这时不需要copy参数了。  </p>
<p><strong>2.编写网络配置文件</strong><br>通常创建一个创建一个 solver 来表示网络的参数信息，包括：迭代次数，训练策略以及保存快照等。其中包含了一个训练网络模型定义和一个测试网络模型定义文件，也可以写在一个配置文件中，当写在一个文件中的时候，要在网络的不同之处加上：
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">include &#123;</div><div class="line">    phase: TEST (TRAIN)</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p>
<p><strong>3.网络运行过程</strong>  </p>
<ul>
<li>加载 solver 有两种方式（Python 接口）：<br><code>solver = caffe.get_solver(&#39;models/bvlc_reference_caffenet/solver.prototxt&#39;)</code> 和<br><code>solver = caffe.SGDSolver(&#39;models/bvlc_reference_caffenet/solver.prototxt&#39;)</code>  </li>
<li>开始训练：  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">solver.net.forward()  <span class="comment"># train net</span></div><div class="line">solver.test_nets[<span class="number">0</span>].forward()  <span class="comment"># test net (there can be more than one)</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>这是一次从输入层到损失层的计算过程，最后计算出loss，反向传播时，可以写为：<code>solver.net.backward()</code>，这是计算从损失层到输入层的梯度，并更新网络中各层的参数信息。前向传播和反向传播可以合并写，表示一次完整的计算：<code>solver.step(1)</code>。如果要按照配置文件中的最大迭代次数运行网络，则写为：<code>solver.solve()</code>。  </p>
<p><strong>4.验证模型正确率</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">accuracy = <span class="number">0</span></div><div class="line">batch_size = solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'data'</span>].num <span class="comment">#训练批次</span></div><div class="line">test_iters = int(len(Xt) / batch_size) <span class="comment">#迭代次数</span></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(test_iters):</div><div class="line">    solver.test_nets[<span class="number">0</span>].forward() <span class="comment">#测试网络</span></div><div class="line">    accuracy += solver.test_nets[<span class="number">0</span>].blobs[<span class="string">'accuracy'</span>].data <span class="comment">#相加每次迭代的正确率</span></div><div class="line">accuracy /= test_iters <span class="comment">#平均正确率</span></div><div class="line">print(<span class="string">"Accuracy: &#123;:.3f&#125;"</span>.format(accuracy))</div></pre></td></tr></table></figure></p>
<p><strong>5.定义自己的Python层</strong><br>Python层通常用来对输入数据进行预处理，如在图像语义分割中，输入为Python层，用于读取训练图像和分割图像。<br>自定义Python层是，需在prototxt文件中指明层的类型为python并且指明需要的函数，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: <span class="string">'MyPythonLayer'</span></div><div class="line">  type: <span class="string">'Python'</span></div><div class="line">  top: <span class="string">'output'</span></div><div class="line">  bottom: <span class="string">'conv'</span></div><div class="line">  python_param &#123;</div><div class="line">    module: <span class="string">'mypythonlayer'</span></div><div class="line">    layer: <span class="string">'MyLayer'</span></div><div class="line">    param_str: <span class="string">"'num': 21"</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>然后，需要按以下格式定义自己的Python文件，如：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> yaml</div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span><span class="params">(caffe.Layer)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setup</span><span class="params">(self, bottom, top)</span>:</span></div><div class="line">        self.num = yaml.load(self.param_str)[<span class="string">"num"</span>]</div><div class="line">        <span class="keyword">print</span> <span class="string">"Parameter num : "</span>, self.num</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">reshape</span><span class="params">(self, bottom, top)</span>:</span></div><div class="line">        <span class="keyword">pass</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, bottom, top)</span>:</span> <span class="comment">#前传</span></div><div class="line">        top[<span class="number">0</span>].reshape(*bottom[<span class="number">0</span>].shape)</div><div class="line">        top[<span class="number">0</span>].data[...] = bottom[<span class="number">0</span>].data + self.num</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backward</span><span class="params">(self, top, propagate_down, bottom)</span>:</span></div><div class="line">        <span class="keyword">pass</span></div></pre></td></tr></table></figure></p>
<p>使用时还与普通网络调用一样进行，只是会直接用python定义的层完成输入数据的重新组织，再进行传递。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Caffe学习中的遇到的一些问题拾遗。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>尺度感知模型</title>
    <link href="http://abumaster.com/2017/04/25/%E5%B0%BA%E5%BA%A6%E6%84%9F%E7%9F%A5%E6%A8%A1%E5%9E%8B/"/>
    <id>http://abumaster.com/2017/04/25/尺度感知模型/</id>
    <published>2017-04-25T07:02:25.000Z</published>
    <updated>2017-04-25T11:44:08.513Z</updated>
    
    <content type="html"><![CDATA[<p>来自 2016 年 ICCV 论文：Attention to Scale: Scale-aware Semantic Image Segmentation，注意尺度：尺度敏感图像语义分割。在全卷积网络中合并多尺度特征已经是提高图像语义分割效果的一个关键因素。通过不同图像尺寸的输入，提取出不同尺度的信息，通过一个注意力模型获得权重融合特征图，最终得到分割图像。<br><a id="more"></a>
<strong>1.注意力模型 Attention model</strong><br>Attention model(AM)最先在计算机视觉中被应用于图片识别的问题，之后在自然语言处理(NLP)和计算机视觉(CV)中经常结合递归神经网络结构RNN、GRU、LSTM等深度学习算法，被称之为Recurrent Attention Model(RAM)，其核心就是一个Encoder-Decoder的过程。图像识别中，经常把图像缩放成固定大小，引起信息的丢失，结合人看物体时，目光会沿着感兴趣的方向移动，甚至聚焦感兴趣的区域，Attention（注意力）就是在网络中加入关注区域的移动、缩放机制、连续部分信息序列化输入。<a href="https://www.zhihu.com/question/36591394">知乎问题回答</a>。可以分为两种模型：  </p>
<ul>
<li>hard：Attention 每次移动固定大小区域；  </li>
<li>soft：Attention 每次是所有区域的一个加权和。<br><strong>注意力</strong>，人看一副图像不是按像素点去看的，往往是一个区域一个区域看的，关注感兴趣区域（Region of Interest），Attention 可以自动寻找感兴趣的区域？强化学习。<br><strong>2.如何利用多尺度信息</strong><br>在 FCNs 场景下，有两种方式利用多尺度信息，如图所示：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-25/98403353-file_1493107872063_3e36.png" alt="">  </li>
<li>利用网络中间层信息，由于随着网络层数的增加，图像不断缩小，图像的特征也会不断地丢失，在经典的FCN-8s网络中提出了融合中间层的特征图，优化最后的分割结果；  </li>
<li>多尺度图像输入，网络共享权重，不同尺度会产生不同大小的特征图，每个尺度的特征图关注点也不同，通过在最后对不同尺度特征图的融合，产生最终的分割结果。<br><strong>3.模型介绍</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-25/24866344-file_1493107637433_24f2.png" alt="model"><br>模型如何运作？<br>不同尺度图像输入 FCNs 中会生成不同的热力图（得分图），然后，如何融合不同的得分图，论文中提出了一个<em>注意力模型</em>，对于每个尺度特征图输出一个权重图，权重是如何生成的呢，通过学习，对于大物体在褚略的特征图上置为较大的权重。有了权重图，结合特征图，很容易加权融合多个尺度特征图，得到最后的输出。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-25/73523202-file_1493108587550_a9.png" alt=""><br>每个尺度，对应着一个score map，这里乘以由尺度获得的权重图，得到最终的输出图。权重是由注意力模型产生的score map的所占比重决定的，表示摸个尺度的重要性。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;来自 2016 年 ICCV 论文：Attention to Scale: Scale-aware Semantic Image Segmentation，注意尺度：尺度敏感图像语义分割。在全卷积网络中合并多尺度特征已经是提高图像语义分割效果的一个关键因素。通过不同图像尺寸的输入，提取出不同尺度的信息，通过一个注意力模型获得权重融合特征图，最终得到分割图像。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>零散</title>
    <link href="http://abumaster.com/2017/04/19/%E9%9B%B6%E6%95%A3/"/>
    <id>http://abumaster.com/2017/04/19/零散/</id>
    <published>2017-04-19T06:25:45.000Z</published>
    <updated>2017-05-19T14:03:42.963Z</updated>
    
    <content type="html"><![CDATA[<h4 id="VMware虚拟机在Windows下错误"><a href="#VMware虚拟机在Windows下错误" class="headerlink" title="VMware虚拟机在Windows下错误"></a>VMware虚拟机在Windows下错误</h4><blockquote>
<p>出现如下错误：VMware Workstation and Device/Credential Guard are not compatible</p>
</blockquote>
<a id="more"></a>
<p>Windows的虚拟化技术Hyper-v和VMware的虚拟化技术不兼容的问题！<br><strong>解决方案：</strong><br>1.关闭hyper-v服务<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-13/57980487-file_1494663243567_46cf.png" alt=""><br>如图，关闭红色框内的功能。<br>2.增加开机启动选项<br><a href="http://stackoverflow.com/questions/39858200/vmware-workstation-and-device-credential-guard-are-not-compatible/41968105#41968105">stackoverflow 问题回答</a>在CMD管理员身份运行，注意不能用PowerShell。编辑bcd。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">C:\&gt;bcdedit /copy &#123;current&#125; /d &quot;No Hyper-V&quot; </div><div class="line">The entry was successfully copied to &#123;ff-23-113-824e-5c5144ea&#125;. </div><div class="line"></div><div class="line">C:\&gt;bcdedit /set &#123;ff-23-113-824e-5c5144ea&#125; hypervisorlaunchtype off </div><div class="line">The operation completed successfully.</div></pre></td></tr></table></figure></p>
<p>重启经过一段时间配置，开机启动项出现了两个选项：</p>
<ul>
<li>Windows 10  </li>
<li>No Hyper-V  </li>
</ul>
<p><em>删除开启启动项：</em><br>在CMD中输入：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">C:\&gt;bcdedit /v</div><div class="line">列出了开机启动项，删除对应的选项即可。</div><div class="line">C:\&gt;bcdedit /delete &#123;ff-23-113-824e-5c5144ea&#125;</div></pre></td></tr></table></figure></p>
<p>另一种，在系统配置中直接配置引导项。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-5-13/2502438-file_1494663696605_e059.png" alt="">  </p>
<p>图像分类：
Krizhevsky A, Sutskever I, Hinton G E. Imagenet classification with deep convolutional neural networks[C]//Advances in neural information processing systems. 2012: 1097-1105.<br>Simonyan K, Zisserman A. Very deep convolutional networks for large-scale image recognition[J]. arXiv preprint arXiv:1409.1556, 2014.<br>Papandreou G, Kokkinos I, Savalle P A. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 390-399.  </p>
<p>物体检测：
Girshick R, Donahue J, Darrell T, et al. Rich feature hierarchies for accurate object detection and semantic segmentation[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2014: 580-587.<br>Erhan D, Szegedy C, Toshev A, et al. Scalable object detection using deep neural networks[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2014: 2147-2154.<br>Ren S, He K, Girshick R, et al. Faster r-cnn: Towards real-time object detection with region proposal networks[C]//Advances in neural information processing systems. 2015: 91-99.<br>He K, Zhang X, Ren S, et al. Deep residual learning for image recognition[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 770-778.  </p>
<p><strong>CNN用于图像分割</strong><br>Schulz H, Behnke S. Learning Object-Class Segmentation with Convolutional Neural Networks[C]//ESANN. 2012.<br>Farabet C, Couprie C, Najman L, et al. Scene parsing with multiscale feature learning, purity trees, and optimal covers[J]. arXiv preprint arXiv:1202.2160, 2012.<br>Farabet C, Couprie C, Najman L, et al. Learning hierarchical features for scene labeling[J]. IEEE transactions on pattern analysis and machine intelligence, 2013, 35(8): 1915-1929.<br>Dai J, He K, Sun J. Convolutional feature masking for joint object and stuff segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3992-4000.</p>
<p>Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.  </p>
<p>刘丹,刘学军,王美珍. 一种多尺度CNN的图像语义分割算法[J]. 遥感信息,2017,(01):57-64.<br>蒋应锋,张桦,薛彦兵,周冕,徐光平,高赞. 一种新的多尺度深度学习图像语义理解方法研究[J]. 光电子·激光,2016,(02):224-230.  </p>
<p>Mostajabi M, Yadollahpour P, Shakhnarovich G. Feedforward semantic segmentation with zoom-out features[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3376-3385.<br>Lin G, Shen C, van den Hengel A, et al. Efficient piecewise training of deep structured models for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 3194-3203.  </p>
]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;VMware虚拟机在Windows下错误&quot;&gt;&lt;a href=&quot;#VMware虚拟机在Windows下错误&quot; class=&quot;headerlink&quot; title=&quot;VMware虚拟机在Windows下错误&quot;&gt;&lt;/a&gt;VMware虚拟机在Windows下错误&lt;/h4&gt;&lt;blockquote&gt;
&lt;p&gt;出现如下错误：VMware Workstation and Device/Credential Guard are not compatible&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>Caffe的C++接口调用</title>
    <link href="http://abumaster.com/2017/04/18/Caffe%E7%9A%84C-%E6%8E%A5%E5%8F%A3%E8%B0%83%E7%94%A8/"/>
    <id>http://abumaster.com/2017/04/18/Caffe的C-接口调用/</id>
    <published>2017-04-18T12:25:06.000Z</published>
    <updated>2017-04-18T13:20:27.571Z</updated>
    
    <content type="html"><![CDATA[<p>Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。<br><a id="more"></a></p>
<h2 id="1-配置第三方库"><a href="#1-配置第三方库" class="headerlink" title="1.配置第三方库"></a>1.配置第三方库</h2><p>Windows上运行的是官方的 Caffe-Windows 项目，第三方库是从别人打包好的下载，主要分为几大类：boost、gflags、glog、hdf5、LevelDB、lmdb、OpenBLAS、OpenCV、protobuf。配置内容包括（调试器最好配置Release版本的x64平台）：<br><strong>头文件</strong><br>新建一个工程，打开项目-&gt;工程属性页，C/C++ -&gt; 常规 -&gt; 附加包含目录，添加caffe相关的头文件,caffe及第三方依赖库，我的如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">D:\caffeDev\caffe-master\include;D:\caffeDev\NugetPackages\boost.1.59.0.0\lib\native\include;D:\caffeDev\NugetPackages\OpenCV.2.4.10\build\native\include;D:\caffeDev\NugetPackages\gflags.2.1.2.1\build\native\include;D:\caffeDev\NugetPackages\glog.0.3.3.0\build\native\include;D:\caffeDev\NugetPackages\hdf5-v120-complete.1.8.15.2\lib\native\include;D:\caffeDev\NugetPackages\lmdb-v120-clean.0.9.14.0\lib\native\include;D:\caffeDev\NugetPackages\protobuf-v120.2.6.1\build\native\include;D:\caffeDev\NugetPackages\OpenBLAS.0.2.14.1\lib\native\include;</div></pre></td></tr></table></figure></p>
<p><strong>附加库目录</strong><br>链接器 -&gt; 常规 -&gt; 附加库目录 ，添加内容为lib库所在的目录：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;AdditionalLibraryDirectories&gt;D:\caffeDev\NugetPackages\glog.0.3.3.0\build\native\lib\x64\v120\Release\dynamic;D:\caffeDev\caffe-master\Build\x64\Release;D:\caffeDev\NugetPackages\OpenCV.2.4.10\build\native\lib\x64\v120\Release;D:\caffeDev\NugetPackages\boost_date_time-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_filesystem-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_system-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\protobuf-v120.2.6.1\build\native\lib\x64\v120\Release;D:\caffeDev\NugetPackages\boost_thread-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\boost_chrono-vc120.1.59.0.0\lib\native\address-model-64\lib;D:\caffeDev\NugetPackages\hdf5-v120-complete.1.8.15.2\lib\native\lib\x64;D:\caffeDev\NugetPackages\gflags.2.1.2.1\build\native\x64\v120\dynamic\Lib;D:\caffeDev\NugetPackages\OpenBLAS.0.2.14.1\lib\native\lib\x64;%(AdditionalLibraryDirectories)&lt;/AdditionalLibraryDirectories&gt;</div></pre></td></tr></table></figure></p>
<p><strong>依赖项</strong><br>输入 -&gt; 附加依赖项，中填写需要的链接库，为上述目录中的链接库：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div></pre></td><td class="code"><pre><div class="line">&lt;AdditionalDependencies&gt;</div><div class="line">opencv_calib3d2410.lib;</div><div class="line">opencv_contrib2410.lib;</div><div class="line">opencv_core2410.lib;</div><div class="line">opencv_features2d2410.lib;</div><div class="line">opencv_flann2410.lib;</div><div class="line">opencv_gpu2410.lib;</div><div class="line">opencv_highgui2410.lib;</div><div class="line">opencv_imgproc2410.lib;</div><div class="line">opencv_legacy2410.lib;</div><div class="line">opencv_ml2410.lib;</div><div class="line">opencv_nonfree2410.lib;</div><div class="line">opencv_objdetect2410.lib;</div><div class="line">opencv_ocl2410.lib;</div><div class="line">opencv_photo2410.lib;</div><div class="line">opencv_stitching2410.lib;</div><div class="line">opencv_superres2410.lib;</div><div class="line">opencv_ts2410.lib;</div><div class="line">opencv_video2410.lib;</div><div class="line">opencv_videostab2410.lib;</div><div class="line">libglog.lib;</div><div class="line">caffe.lib;</div><div class="line">libprotobuf.lib;</div><div class="line">libcaffe.lib;</div><div class="line">gflags.lib;</div><div class="line">gflags_nothreads.lib;</div><div class="line">hdf5.lib;</div><div class="line">hdf5_cpp.lib;</div><div class="line">hdf5_f90cstub.lib;</div><div class="line">hdf5_fortran.lib;</div><div class="line">hdf5_hl.lib;</div><div class="line">hdf5_hl_cpp.lib;</div><div class="line">hdf5_hl_f90cstub.lib;</div><div class="line">hdf5_hl_fortran.lib;</div><div class="line">hdf5_tools.lib;</div><div class="line">szip.lib;</div><div class="line">zlib.lib;</div><div class="line">libopenblas.dll.a;</div><div class="line">%(AdditionalDependencies)</div><div class="line">&lt;/AdditionalDependencies&gt;</div></pre></td></tr></table></figure></p>
<h2 id="2-运行时问题"><a href="#2-运行时问题" class="headerlink" title="2.运行时问题"></a>2.运行时问题</h2><p>实际新建一个项目（从caffe工程中拷的源码，配置好一切环境），可以编译成功，但是运行时出现问题：<br><strong>F0519 14:54:12.494139 14504 layer_factory.hpp:77] Check failed: registry.count(type) == 1 (0 vs. 1) Unknown layer type: Input (known types: Input )</strong><br>一者说，只有在caffe解决方案中新建项目，才可以正常运行<a href="https://github.com/Microsoft/caffe/issues/45">问题</a>。还有利用别人改进的caffe来减少外部的依赖关系，<a href="https://github.com/dtmoodie/caffe">dtmoodie</a>。<br>另外一种，<a href="http://blog.csdn.net/fangjin_kl/article/details/50936952#0-tsina-1-63793-397232819ff9a47a7b7e80a40613cfe1">解决方法</a>主要解决方案是将caffe中的各层都放进一个头文件中包含进工程中，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/common.hpp"</span>  </span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"caffe/layers/input_layer.hpp"</span></span></div><div class="line"><span class="function"><span class="keyword">extern</span> <span class="title">INSTANTIATE_CLASS</span><span class="params">(InputLayer)</span></span>;<span class="comment">//添加层信息</span></div><div class="line">REGISTER_LAYER_CLASS(Input);<span class="comment">//注册层信息</span></div></pre></td></tr></table></figure></p>
<p>可以完美运行了。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Caffe的原生接口是C++，但是使用起来相对于Python和MATLAB也是最麻烦的，一个是需要配置各种第三方库，二是Windows下用VS新建C++工程出现各种编译问题。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>高效分片训练结构化模型用于图像语义分割</title>
    <link href="http://abumaster.com/2017/04/17/%E9%AB%98%E6%95%88%E5%88%86%E7%89%87%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%84%E5%8C%96%E6%A8%A1%E5%9E%8B%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/17/高效分片训练结构化模型用于图像语义分割/</id>
    <published>2017-04-17T08:58:15.000Z</published>
    <updated>2017-04-18T02:13:45.979Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic
Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。  </p>
</blockquote>
<a id="more"></a>
<p><strong>特点：</strong>  </p>
<ol>
<li>制定了基于CNN的在CRFs上总体分段潜在函数模型用于衡量语义图像片之间的关系；  </li>
<li>分段训练CRFs，避免重复推导，提高速度；  </li>
<li>多尺度图像输入，用于探索图像背景和前景上下文信息；  </li>
</ol>
<hr>
<p><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/28980161-file_1492432013053_14485.png" alt=""><br>Featmap-Net是一个卷积网络，用于输出特征图，低分辨率的特征图；
创建CRF图，首先对于卷积网络生成的特征图，创建一些边界框，在边界框内被认为空间近似，顶点才会全连接，不同空间会创建不同的边界框。  </p>
<p><strong>上下文深度CRFs</strong><br>分为一元组的图的顶点和二元组的图的边，分别对应一个能量函数，通过一元和二元网络对应生成了类别的预测。<br><strong>利用背景上下文</strong><br>产生特征图的网络：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-18/67947492-file_1492479486028_4096.png" alt=""></p>
<p>首先将输入图像缩放为三个不同的大小，放入网络，共享权重。图像缩放大小为1.2,0.8,0.4，再经过一层独立的卷积产生多尺度特征图，然后经过滑动金字塔池化产生了组合的特征图，金字塔池化如下图所示：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-18/81267394-file_1492479935056_11ffe.png" alt=""><br>使用双线性上采样和简单的边界优化对粗糙的预测结果进行后期处理，可能又更复杂的优化方式，比如：训练反卷积网络，训练复杂的从粗糙到精细的网络，利用中间特征图到高分辨率的预测。</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;cvpr 论文：Efficient Piecewise Training of Deep Structured Models for Semantic
Segmentation 利用上下文信息提高分割图的精度。从两个方面入手：物体与物体之间、物体与背景之间。前者使用CNN结合CRF，来构造临近像素之间的关系；后者通过多尺度图像输入和滑动的金字塔池化。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>拉普拉斯重建和细化用于图像语义分割</title>
    <link href="http://abumaster.com/2017/04/16/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%8D%E5%BB%BA%E5%92%8C%E7%BB%86%E5%8C%96%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/16/拉普拉斯重建和细化用于图像语义分割/</id>
    <published>2017-04-16T08:05:56.000Z</published>
    <updated>2017-04-17T07:21:41.177Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。  </p>
</blockquote>
<a id="more"></a>
<p><em>空间语义不确定性原则</em>，探索在CNN特征层次结构中的空间和语义正确性。网络的顶层图像语义预测准确，但是带来的缺陷是在低分辨率下的图像空间上的定位，边界清晰但是标签有噪声。提出了一种重建模型在给定层次上提高空间定位的准确性，和一种细化技术用来融合多层的信息来优化图像的语义分割结果。<br>与传统FCN的区别：<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-16/29818085-file_1492332368566_59f2.png" alt=""><br>不同之处在于，上采样和重建。<br><strong>CNN 特征图固有的缺少空间细节信息</strong>用一些不同的方法可以解决，如条件随机场、超像素、边界检测。还有一些成对的特征映射，可以进行反向传播进行训练。此论文的方法是<strong>直接提高输出激活图空间分辨率</strong>。<br><strong>双线性上采样是从低分辨率特征图中计算出高分辨率分割图的一种标准方法</strong>，首先卷积网络从特征图中计算出低分辨率的得分图，然后使用线性过滤器上采样为高分辨率的得分图。这种方法<em>可能会从多通道低分辨率特征图中丢失定位信息</em>。为了保留更多的空间信息，论文避免了将高维特征图折叠成低分辨率的类别预测。取而代之的是利用高分辨率基函数的线性组合对高分辨率的分类得分图的空间模式进行编码，这些函数的权重被高维特征图预测得到。实现：将高分辨率的特征图分成不重叠的图像块，大小取决于网络中池化层的个数次幂，通过一个卷积网络预测从高纬度低分辨率到特征图像块的映射。这些特征图像块和类别系数与一个基本函数集合相乘，再与一个基本的去卷积层相加，得到期望的全分辨率类别图。<br><strong>连接样条插值</strong><br>更高阶的样条插值替代上采样。<br><strong>学习基本函数</strong><br><strong>基本结构</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/25758666-file_1492397377051_a8d3.png" alt=""><br>首先，网络从上到下，分辨率越来越小。在每一次缩小时，特征图重建，再进行组合，产生对应倍数特征图的分割得分图，上图的水平方向，通过组合不同倍数的得分图。<br>一种从高分辨率中减去低频成分的方法，边界masking，孤立出边界成分。<br>金字塔的应用：<br>下层分割图得分上采样作为上一层采样的参考，用于得分图和像素对的产生。<br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-17/99567344-file_1492411678446_ecd2.png" alt=""><br><strong>Conclusion</strong>  </p>
<ul>
<li>以特定类重建为基础作为上采样；  </li>
<li>合成低分辨率的语义丰富的特征图和拥有更多空间特性的高分辨率特征图，多层拉普拉斯金字塔重建结构。  </li>
<li>最后可以加上CRF进行后期处理，优化结果。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;来自论文：Laplacian Reconstruction and Refinement for Semantic Segmentation，论文有两个贡献：1）证明了卷积特征图的空间低分辨率，但是在高维特征表示中包含重要的子像素定位信息；2）提出了一种类似拉普拉斯金字塔的多分辨率重建结构，对高分辨率特征图的跳跃连接可以从低分辨率特征图重建并成功细化分割图像的边界。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="计算机视觉" scheme="http://abumaster.com/tags/computerversion/"/>
    
  </entry>
  
  <entry>
    <title>网易2017春招笔试编程题</title>
    <link href="http://abumaster.com/2017/04/14/%E7%BD%91%E6%98%932017%E6%98%A5%E6%8B%9B%E7%AC%94%E8%AF%95%E7%BC%96%E7%A8%8B%E9%A2%98/"/>
    <id>http://abumaster.com/2017/04/14/网易2017春招笔试编程题/</id>
    <published>2017-04-14T06:14:18.000Z</published>
    <updated>2017-04-14T06:45:55.647Z</updated>
    
    <content type="html"><![CDATA[<p><strong>感悟</strong>：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。<br><a id="more"></a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;感悟&lt;/strong&gt;：读的算法书，练习的算法题目都学到狗身上去了？不能活学活用，也就不能灵光乍现，难以进步。看似简单的题目，往往没有经过深思熟虑，导致复杂度高，无法通过。欠缺思考。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="算法" scheme="http://abumaster.com/tags/algorithm/"/>
    
  </entry>
  
  <entry>
    <title>FCN图像语义分割计算的细节问题</title>
    <link href="http://abumaster.com/2017/04/11/FCN%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2%E8%AE%A1%E7%AE%97%E7%9A%84%E7%BB%86%E8%8A%82%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/04/11/FCN图像语义分割计算的细节问题/</id>
    <published>2017-04-11T08:59:57.000Z</published>
    <updated>2017-04-12T01:09:31.691Z</updated>
    
    <content type="html"><![CDATA[<p>Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。<br><a id="more"></a>
从论文中地址中，下载<a href="https://github.com/shelhamer/fcn.berkeleyvision.org">FCN</a>源码到本地。
<strong>1.使用现有模型进行图像语义分割</strong>
解压源代码，在根目录下，有一个infer.py的文件，打开，配置自己的模型路径，运行即可。
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"><span class="comment"># load image, switch to BGR, subtract mean, and make dims C x H x W for Caffe</span></div><div class="line">im = Image.open(<span class="string">'voc-fcn8s/21.jpg'</span>)</div><div class="line">in_ = np.array(im, dtype=np.float32)</div><div class="line">in_ = in_[:,:,::<span class="number">-1</span>]</div><div class="line"><span class="comment">#in_ -= np.array((104.00698793,116.66876762,122.67891434))</span></div><div class="line">in_ -= np.array((<span class="number">106.08069</span>,<span class="number">103.75618</span>,<span class="number">100.05657</span>))</div><div class="line">in_ = in_.transpose((<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</div><div class="line"><span class="comment"># load net</span></div><div class="line">net = caffe.Net(<span class="string">'voc-fcn8s/deploy.prototxt'</span>, <span class="string">'voc-fcn8s/fcn8s-heavy-pascal.caffemodel'</span>, caffe.TEST)</div><div class="line"><span class="comment"># shape for input (data blob is N x C x H x W), set data</span></div><div class="line">net.blobs[<span class="string">'data'</span>].reshape(<span class="number">1</span>, *in_.shape)</div><div class="line">net.blobs[<span class="string">'data'</span>].data[...] = in_</div><div class="line"><span class="comment"># run net and take argmax for prediction</span></div><div class="line">net.forward()</div><div class="line">out = net.blobs[<span class="string">'score'</span>].data[<span class="number">0</span>].argmax(axis=<span class="number">0</span>)</div><div class="line"><span class="comment">#print out</span></div><div class="line">plt.imshow(out,cmap=<span class="string">'gray'</span>);</div><div class="line">plt.axis(<span class="string">'off'</span>)</div><div class="line">plt.savefig(<span class="string">'test1.png'</span>)</div></pre></td></tr></table></figure></p>
<p><strong>2.源码阅读</strong>
在源码的voc-fcn32s问价夹下，net.py用于生成网络的配置文件：train.prototxt、val.prototxt，solve.py用来运行训练网络，solver.prototxt是训练的配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">train_net: &quot;train.prototxt&quot;</div><div class="line">test_net: &quot;val.prototxt&quot;</div><div class="line">test_iter: 736</div><div class="line"># make test net, but don&apos;t invoke it from the solver itself</div><div class="line">test_interval: 999999999</div><div class="line">display: 20</div><div class="line">average_loss: 20</div><div class="line">lr_policy: &quot;fixed&quot;</div><div class="line"># lr for unnormalized softmax</div><div class="line">base_lr: 1e-10</div><div class="line"># high momentum</div><div class="line">momentum: 0.99</div><div class="line"># no gradient accumulation</div><div class="line">iter_size: 1</div><div class="line">max_iter: 100000</div><div class="line">weight_decay: 0.0005</div><div class="line">snapshot: 4000</div><div class="line">snapshot_prefix: &quot;snapshot/train&quot;</div><div class="line">test_initialization: false</div></pre></td></tr></table></figure></p>
<p><strong>solve.py 文件解读</strong><br>它调用了根目录下的 surgery.py 和 score.py 文件，后面再介绍。<br>主要作用：  </p>
<ul>
<li>用现有的分类网络模型初始化网络；  </li>
<li>自定义上采样层的卷积核；  </li>
<li>加载验证图片，自定义最后的得分输出。<br>初始化网络：  <figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">weights = <span class="string">'../ilsvrc-nets/vgg16-fcn.caffemodel'</span> <span class="comment">#加载训练好的分类模型</span></div><div class="line">solver = caffe.SGDSolver(<span class="string">'solver.prototxt'</span>)<span class="comment">#加载网络配置文件</span></div><div class="line">solver.net.copy_from(weights)<span class="comment">#从模型中复制权重</span></div><div class="line"><span class="comment">#也可以写为如下方式：</span></div><div class="line"><span class="comment">#solver = caffe.SGDSolver('solver.prototxt')</span></div><div class="line"><span class="comment">#vgg_net = caffe.Net('solver.prototxt', weights, caffe.TRAIN)</span></div><div class="line"><span class="comment">#surgery.transplant(solver.net, vgg_net)</span></div><div class="line"><span class="comment">#del vgg_net</span></div></pre></td></tr></table></figure>
</li>
</ul>
<p>调用surgery.py中的上采样层，双线性插值，将图像变为原始大小。
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">interp_layers = [k <span class="keyword">for</span> k <span class="keyword">in</span> solver.net.params.keys() <span class="keyword">if</span> <span class="string">'up'</span> <span class="keyword">in</span> k]</div><div class="line">surgery.interp(solver.net, interp_layers)</div></pre></td></tr></table></figure></p>
<p>得分层
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># scoring</span></div><div class="line">val = np.loadtxt(<span class="string">'../data/segvalid11.txt'</span>, dtype=str)<span class="comment">#加载验证图片</span></div><div class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">25</span>):</div><div class="line">    solver.step(<span class="number">4000</span>)</div><div class="line">    score.seg_tests(solver, <span class="keyword">False</span>, val, layer=<span class="string">'score'</span>)<span class="comment">#测试网络的得分情况</span></div></pre></td></tr></table></figure></p>
<p><strong>surgery.py 文件解读</strong><br>主要作用是制作适用于给定长宽的双线性插值内核，用于上采样。主要函数为:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">upsample_filt</span><span class="params">(size)</span>:</span></div><div class="line">    <span class="string">"""</div><div class="line">    Make a 2D bilinear kernel suitable for upsampling of the given (h, w) size.</div><div class="line">    """</span></div><div class="line">    factor = (size + <span class="number">1</span>) // <span class="number">2</span></div><div class="line">    <span class="keyword">if</span> size % <span class="number">2</span> == <span class="number">1</span>:</div><div class="line">        center = factor - <span class="number">1</span></div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        center = factor - <span class="number">0.5</span></div><div class="line">    og = np.ogrid[:size, :size]</div><div class="line">    <span class="keyword">return</span> (<span class="number">1</span> - abs(og[<span class="number">0</span>] - center) / factor) * \</div><div class="line">           (<span class="number">1</span> - abs(og[<span class="number">1</span>] - center) / factor)</div></pre></td></tr></table></figure></p>
<p><strong>score.py 文件解读</strong><br>主要作用：计算当前网络分割图的准确性。主要有以下几个标准：mean loss, overall accuracy, per-class accuracy, per-class IU。如何计算的呢？<br>首先理解两个函数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#计算a和b对应相同的就在矩阵中对应坐标加1。a和b保存着各个像素的分的类别0-20共21类</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">fast_hist</span><span class="params">(a, b, n)</span>:</span></div><div class="line">    k = (a &gt;= <span class="number">0</span>) &amp; (a &lt; n)<span class="comment">#过滤掉多余的分类</span></div><div class="line">    <span class="comment">#bincount用于统计在范围内出现的个数，即直方图，如果不够n^2个，</span></div><div class="line">    <span class="comment">#那就填充到n^2，这样可以reshpe为n*n的矩阵，正好表示分割图和正确标记图在相同</span></div><div class="line">    <span class="comment">#类别上像素出现的个数</span></div><div class="line">    <span class="keyword">return</span> np.bincount(n * a[k].astype(int) + b[k], minlength=n**<span class="number">2</span>).reshape(n, n)</div><div class="line"><span class="comment">#调用计算直方图函数，指定了数据来源</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_hist</span><span class="params">(net, save_dir, dataset, layer=<span class="string">'score'</span>, gt=<span class="string">'label'</span>)</span>:</span></div><div class="line">    n_cl = net.blobs[layer].channels<span class="comment">#得到score层的通道数，fcn中为21通道，21类物体</span></div><div class="line">    <span class="keyword">if</span> save_dir:<span class="comment">#是否将分割图保存为文件</span></div><div class="line">        os.mkdir(save_dir)</div><div class="line">    <span class="comment">#hist表示：分割图中21类和标记图21类出现的像素数</span></div><div class="line">    <span class="comment">#如：在i,j像素位置上分割图标记为2类物体，而实际标记为3那么在hist（2,3）+=1</span></div><div class="line">    <span class="comment">#    在i,j+1像素位置分割图标记2类物体，实际标记图也为2类，则hist(2,2)+=1</span></div><div class="line">    <span class="comment">#    可以看出hist对角矩阵是正确的分割；</span></div><div class="line">    hist = np.zeros((n_cl, n_cl))<span class="comment">#初始化21*21的二维矩阵</span></div><div class="line">    loss = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> dataset:</div><div class="line">        net.forward()<span class="comment">#网络向前传播</span></div><div class="line">        <span class="comment">#展开为一维数组</span></div><div class="line">        hist += fast_hist(net.blobs[gt].data[<span class="number">0</span>, <span class="number">0</span>].flatten(),</div><div class="line">                          net.blobs[layer].data[<span class="number">0</span>].argmax(<span class="number">0</span>).flatten(),n_cl)</div><div class="line">        <span class="keyword">if</span> save_dir:</div><div class="line">            im = Image.fromarray(net.blobs[layer].data[<span class="number">0</span>].argmax(<span class="number">0</span>).astype(np.uint8), mode=<span class="string">'P'</span>)</div><div class="line">            im.save(os.path.join(save_dir, idx + <span class="string">'.png'</span>))</div><div class="line">        <span class="comment"># compute the loss as well 计算网络的损失</span></div><div class="line">        loss += net.blobs[<span class="string">'loss'</span>].data.flat[<span class="number">0</span>]<span class="comment">#flat[0]取第一个数</span></div><div class="line">    <span class="keyword">return</span> hist, loss / len(dataset)</div></pre></td></tr></table></figure></p>
<p>计算几个分割效果指标：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#mean loss</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'loss'</span>, loss</div><div class="line">   <span class="comment"># overall accuracy</span></div><div class="line">   acc = np.diag(hist).sum() / hist.sum()<span class="comment">#对角线正确像素/总像素</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'overall accuracy'</span>, acc</div><div class="line">   <span class="comment"># per-class accuracy</span></div><div class="line">   acc = np.diag(hist) / hist.sum(<span class="number">1</span>)<span class="comment">#每一类的</span></div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'mean accuracy'</span>, np.nanmean(acc)</div><div class="line">   <span class="comment"># per-class IU</span></div><div class="line">   iu = np.diag(hist) / (hist.sum(<span class="number">1</span>) + hist.sum(<span class="number">0</span>) - np.diag(hist))</div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'mean IU'</span>, np.nanmean(iu)</div><div class="line">   freq = hist.sum(<span class="number">1</span>) / hist.sum()</div><div class="line">   <span class="keyword">print</span> <span class="string">'&gt;&gt;&gt;'</span>, datetime.now(), <span class="string">'Iteration'</span>, iter, <span class="string">'fwavacc'</span>, \</div><div class="line">           (freq[freq &gt; <span class="number">0</span>] * iu[freq &gt; <span class="number">0</span>]).sum()</div></pre></td></tr></table></figure></p>
<p>其他文件：训练文件的输入层类型是Python，作者自定义了一个voc_layers.py的Python数据加载层。  </p>
<ul>
<li>setup函数，设置voc训练集的路径，及中值文件，挑选数据的随机数；</li>
<li>load_image和load_label函数，用于从数据集中加载图像和标记图像，并转换成数组形式，图像减去中值并转换成<code>chanl*height*weight</code>形式，label变为<code>1*height*weight</code>形式；</li>
<li>forward和backward函数，前向传播将图像、标签复制到top[0]和top[1]中，反向传播不需要任何操作。  </li>
</ul>
<p><strong>学习到的东西</strong><br>Python中numpy中的一些函数，诸如bincount、flatten、diag等。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Fully Convolutional Networks for Semantic Segmentation论文中的源代码阅读笔记。详细描述了分类网络如何变为一个分割网络，并输出最后的分割图。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="学习" scheme="http://abumaster.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>Stanford Background Dataset介绍和使用</title>
    <link href="http://abumaster.com/2017/04/10/Stanford-Background-Dataset%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8/"/>
    <id>http://abumaster.com/2017/04/10/Stanford-Background-Dataset介绍和使用/</id>
    <published>2017-04-10T06:35:07.000Z</published>
    <updated>2017-04-11T00:58:07.351Z</updated>
    
    <content type="html"><![CDATA[<p><a href="http://dags.stanford.edu/projects/scenedataset.html">Stanford Background Dataset</a>是一个从各个数据库（LabelMe, MSRC, PASCAL
VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。</p>
<ul>
<li><p>images文件夹包含了715张图像；  </p>
</li>
<li><p>horizons.txt  图像名称、大小、水平线位置；  </p>
<a id="more"></a>
</li>
<li><p>labels/*.regions.txt 标识每个像素的语义，0-7代表八类语义；  </p>
</li>
<li><p>labels/*.surfaces.txt 标识每个像素的几何类别（天空，水平，垂直）； </p>
</li>
<li><p>labels/*.layers.txt    表示不同图像区域的整数矩阵。  </p>
</li>
</ul>
<p><strong>读取图像和分割图像</strong><br>1.首先读取标签文件<br><figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">vector&lt;char&gt; vec;//保存像素标记</div><div class="line">void readlabel(string labelname)</div><div class="line">&#123;</div><div class="line">	ifstream infile(labelname.c_str(), std::ios::in);</div><div class="line">	char line[1024] = &#123; 0 &#125;;</div><div class="line">	while (infile.getline(line, sizeof(line)))</div><div class="line">	&#123;</div><div class="line">		stringstream word(line);</div><div class="line">		char ch;</div><div class="line">		while (word &gt;&gt; ch)</div><div class="line">		&#123;</div><div class="line">			vec.push_back(ch);</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>2.显示分割图像，根据语义标签，设置不同的颜色以区别  </p>
<pre><code class="c++"><span class="comment">//显示分割图像</span>
    <span class="function">Mat <span class="title">colorim</span><span class="params">(im.rows, im.cols, CV_8UC3)</span></span>;
    <span class="keyword">int</span> index = <span class="number">0</span>;
    <span class="comment">//遍历所有像素，并设置像素值</span>
    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colorim.rows; ++i)
    {
        <span class="comment">//获取第 i 行首像素指针</span>
        Vec3b * p = colorim.ptr&lt;Vec3b&gt;(i);
        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; colorim.cols; ++j)
        {
            <span class="keyword">int</span> lab = vec[index++];
            <span class="keyword">switch</span> (lab)
            {
            <span class="keyword">case</span> <span class="string">'0'</span>:<span class="comment">//sky</span>
                p[j][<span class="number">0</span>] = <span class="number">128</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">128</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">128</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'1'</span>:<span class="comment">//tree</span>
                p[j][<span class="number">0</span>] = <span class="number">84</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">230</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">80</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'2'</span>:<span class="comment">//road</span>
                p[j][<span class="number">0</span>] = <span class="number">115</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">100</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'3'</span>:<span class="comment">//grass</span>
                p[j][<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">255</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">0</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'4'</span>:<span class="comment">//water</span>
                p[j][<span class="number">0</span>] = <span class="number">255</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">0</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'5'</span>:<span class="comment">//building</span>
                p[j][<span class="number">0</span>] = <span class="number">0</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">0</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">160</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'6'</span>:<span class="comment">//mountain</span>
                p[j][<span class="number">0</span>] = <span class="number">63</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">214</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">8</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">case</span> <span class="string">'7'</span>:<span class="comment">//obj</span>
                p[j][<span class="number">0</span>] = <span class="number">37</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">159</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">230</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;
            <span class="keyword">default</span>:<span class="comment">//somthing else</span>
                p[j][<span class="number">0</span>] = <span class="number">255</span>; <span class="comment">//Blue</span>
                p[j][<span class="number">1</span>] = <span class="number">255</span>; <span class="comment">//Green</span>
                p[j][<span class="number">2</span>] = <span class="number">255</span>; <span class="comment">//Red</span>
                <span class="keyword">break</span>;

            }

        }
    }
    imshow(<span class="string">"分割图"</span>, colorim);
</code></pre>
<p><strong>结果</strong><br><img src="http://oo7zsi4t8.bkt.clouddn.com/17-4-11/35996483-file_1491872210006_c82e.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://dags.stanford.edu/projects/scenedataset.html&quot;&gt;Stanford Background Dataset&lt;/a&gt;是一个从各个数据库（LabelMe, MSRC, PASCAL
VOC, Geometric Context）中精选出715张室外图像分为sky, tree, road, grass, water, building, mountain, foreground object共八大类的图像。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;images文件夹包含了715张图像；  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;horizons.txt  图像名称、大小、水平线位置；  &lt;/p&gt;
    
    </summary>
    
      <category term="其他" scheme="http://abumaster.com/categories/other/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="dataset" scheme="http://abumaster.com/tags/dataset/"/>
    
  </entry>
  
  <entry>
    <title>caffe提取各层特征</title>
    <link href="http://abumaster.com/2017/04/09/caffe%E6%8F%90%E5%8F%96%E5%90%84%E5%B1%82%E7%89%B9%E5%BE%81/"/>
    <id>http://abumaster.com/2017/04/09/caffe提取各层特征/</id>
    <published>2017-04-09T12:07:29.000Z</published>
    <updated>2017-04-10T02:03:08.407Z</updated>
    
    <content type="html"><![CDATA[<p>根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：<br><strong>1.caffe创建分类器</strong><br>Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\python\caffe下。<br><a id="more"></a>
初始化这个分类器的时候，出现了一个问题：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">net = caffe.Classifier(caffe_root + <span class="string">'models/bvlc_reference_caffenet/deploy.prototxt'</span>,</div><div class="line">caffe_root + <span class="string">'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span>)</div><div class="line"></div><div class="line">net.set_phase_test()</div><div class="line">net.set_mode_cpu()</div><div class="line">net.set_mean(<span class="string">'data'</span>, caffe_root + <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)</div><div class="line">net.set_channel_swap(<span class="string">'data'</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>)) </div><div class="line">net.set_input_scale(<span class="string">'data'</span>, <span class="number">255</span>)</div></pre></td></tr></table></figure></p>
<p>就是在网络设置时，一直提示没有<code>set_phase_test(*)</code>的成员函数，试了几个平台都是如此提示，后来在网上找到了一点<a href="http://www.programcreek.com/python/example/83400/caffe.set_phase_test">信息</a>其中提到了，可以直接创建的时候初始化，对应于函数的声明所需的参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">net = caffe.Classifier(MODEL_FILE, PRETRAINED,</div><div class="line">                        mean=np.load(os.path.join(CAFFE_DIR, <span class="string">'python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>)),</div><div class="line">                        channel_swap=(<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>),</div><div class="line">                        raw_scale=<span class="number">255</span>,</div><div class="line">                        image_dims=(<span class="number">256</span>, <span class="number">256</span>))</div></pre></td></tr></table></figure></p>
<p><strong>维度不匹配问题</strong>代码如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"> File &quot;one.py&quot;, line 14, in &lt;module&gt;</div><div class="line">    image_dims=(256, 256))</div><div class="line">  File &quot;/home/zgf/caffe-master/python/caffe/classifier.py&quot;, line 34, in __init__</div><div class="line">    self.transformer.set_mean(in_, mean)</div><div class="line">  File &quot;/home/zgf/caffe-master/python/caffe/io.py&quot;, line 259, in set_mean</div><div class="line">    raise ValueError(&apos;Mean shape incompatible with input shape.&apos;)</div><div class="line">ValueError: Mean shape incompatible with input shape.</div></pre></td></tr></table></figure></p>
<p>中值文件读取的错误，在网络上找到了解决<a href="http://stackoverflow.com/questions/30808735/error-when-using-classify-in-caffe">方案</a>，将读取中值文件改为：<code>mean=np.load(&#39;/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy&#39;).mean(1).mean(1)</code>可以解决。  </p>
<p><strong>2.显示特征图像问题</strong><br>按照文档描述依次往下进行，文档使用的工具为ipython，显示图片用：<code>ipt.show()</code>，而我用的工具是jupyter，所以一直找不到这个命令，无法查看图像，从网上查到，可以在代码前面加上一句<code>%matplotlib inline</code>然后用<code>import matplotlib as plt plt.imshow(img)</code>实现。  </p>
<p><strong>3.结果</strong><br>加载网络<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line">caffe_root=<span class="string">'/home/zgf/caffe-master/'</span></div><div class="line"><span class="keyword">import</span> sys</div><div class="line"><span class="keyword">import</span> os</div><div class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">'python/caffe'</span>)</div><div class="line"><span class="keyword">import</span> caffe</div><div class="line"></div><div class="line">plt.rcParams[<span class="string">'figure.figsize'</span>] = (<span class="number">10</span>, <span class="number">10</span>)</div><div class="line">plt.rcParams[<span class="string">'image.interpolation'</span>] = <span class="string">'nearest'</span></div><div class="line">plt.rcParams[<span class="string">'image.cmap'</span>] = <span class="string">'gray'</span></div><div class="line"></div><div class="line">ref_model_file = caffe_root+<span class="string">'/models/bvlc_reference_caffenet/deploy.prototxt'</span></div><div class="line">ref_pretrained = caffe_root+<span class="string">'/models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'</span></div><div class="line"></div><div class="line">net = caffe.Classifier(ref_model_file, ref_pretrained,</div><div class="line">       mean=np.load(<span class="string">'/home/zgf/caffe-master/python/caffe/imagenet/ilsvrc_2012_mean.npy'</span>).mean(<span class="number">1</span>).mean(<span class="number">1</span>),</div><div class="line">       channel_swap=(<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>),</div><div class="line">       raw_scale=<span class="number">255</span>,</div><div class="line">       image_dims=(<span class="number">256</span>, <span class="number">256</span>))</div><div class="line"></div><div class="line">scores = net.predict([caffe.io.load_image(caffe_root + <span class="string">'examples/images/cat.jpg'</span>)])</div><div class="line"><span class="comment">#显示网络的结构信息</span></div><div class="line">[(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.blobs.items()]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[(&apos;data&apos;, (10, 3, 227, 227)),</div><div class="line"> (&apos;conv1&apos;, (10, 96, 55, 55)),</div><div class="line"> (&apos;pool1&apos;, (10, 96, 27, 27)),</div><div class="line"> (&apos;norm1&apos;, (10, 96, 27, 27)),</div><div class="line"> (&apos;conv2&apos;, (10, 256, 27, 27)),</div><div class="line"> (&apos;pool2&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;norm2&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;conv3&apos;, (10, 384, 13, 13)),</div><div class="line"> (&apos;conv4&apos;, (10, 384, 13, 13)),</div><div class="line"> (&apos;conv5&apos;, (10, 256, 13, 13)),</div><div class="line"> (&apos;pool5&apos;, (10, 256, 6, 6)),</div><div class="line"> (&apos;fc6&apos;, (10, 4096)),</div><div class="line"> (&apos;fc7&apos;, (10, 4096)),</div><div class="line"> (&apos;fc8&apos;, (10, 1000)),</div><div class="line"> (&apos;prob&apos;, (10, 1000))]</div></pre></td></tr></table></figure></p>
<p>显示参数信息<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">[(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> net.params.items()]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[(&apos;conv1&apos;, (96, 3, 11, 11)),</div><div class="line"> (&apos;conv2&apos;, (256, 48, 5, 5)),</div><div class="line"> (&apos;conv3&apos;, (384, 256, 3, 3)),</div><div class="line"> (&apos;conv4&apos;, (384, 192, 3, 3)),</div><div class="line"> (&apos;conv5&apos;, (256, 192, 3, 3)),</div><div class="line"> (&apos;fc6&apos;, (4096, 9216)),</div><div class="line"> (&apos;fc7&apos;, (4096, 4096)),</div><div class="line"> (&apos;fc8&apos;, (1000, 4096))]</div></pre></td></tr></table></figure></p>
<p><strong>输入层</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line">%matplotlib inline</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">showimage</span><span class="params">(im)</span>:</span></div><div class="line">    <span class="keyword">if</span> im.ndim == <span class="number">3</span>:</div><div class="line">        m = im[:, :, ::<span class="number">-1</span>]</div><div class="line">    plt.imshow(im)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">vis_square</span><span class="params">(data, padsize=<span class="number">1</span>, padval=<span class="number">0</span>)</span>:</span></div><div class="line">    data -= data.min()</div><div class="line">    data /= data.max()</div><div class="line">    <span class="comment"># force the number of filters to be square</span></div><div class="line">    n = int(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</div><div class="line">    padding = ((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]), (<span class="number">0</span>, padsize), (<span class="number">0</span>, padsize)) + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>)</div><div class="line">    data = np.pad(data, padding, mode=<span class="string">'constant'</span>, constant_values=(padval, padval))</div><div class="line">    <span class="comment"># 对图像使用滤波器</span></div><div class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + tuple(range(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</div><div class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</div><div class="line">    showimage(data)</div><div class="line">    <span class="comment">#plt.imshow(data)</span></div><div class="line"><span class="comment"># index four is the center crop</span></div><div class="line"><span class="comment"># 输出输入的图像</span></div><div class="line">image = net.blobs[<span class="string">'data'</span>].data[<span class="number">4</span>].copy()</div><div class="line">image -= image.min()</div><div class="line">image /= image.max()</div><div class="line">showimage(image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</div><div class="line"><span class="comment">#plt.imshow(image.transpose(1,2,0))</span></div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i4.buimg.com/567571/2d78079157ce4c40.png" alt=""><br>第一个卷积层，参数有[weight, biases]对应索引0,1。的96个过滤器：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">filters = net.params[<span class="string">'conv1'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</div><div class="line"><span class="comment">#96 feature map</span></div><div class="line">feat = net.blobs[<span class="string">'conv1'</span>].data[<span class="number">4</span>, :<span class="number">96</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i4.buimg.com/567571/64897ccff6d61745.jpg" alt=""><br>第二卷积层的过滤器，每个尺寸5*5*48，显示前48个，机器对应的输出只显示36张。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">filters = net.params[<span class="string">'conv2'</span>][<span class="number">0</span>].data</div><div class="line">vis_square(filters[:<span class="number">48</span>].reshape(<span class="number">48</span>**<span class="number">2</span>, <span class="number">5</span>, <span class="number">5</span>))</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv2'</span>].data[<span class="number">4</span>, :<span class="number">36</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><img src="http://i2.muimg.com/567571/441dcc7e494e611a.jpg" alt=""><br>接下来的卷积层的提取和输出一样：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'conv3'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.5</span>)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'conv4'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.5</span>)</div><div class="line"><span class="comment">#第5卷积层</span></div><div class="line">feat = net.blobs[<span class="string">'conv5'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">0.2</span>)</div><div class="line"><span class="comment">#池化层</span></div><div class="line">feat = net.blobs[<span class="string">'pool5'</span>].data[<span class="number">4</span>]</div><div class="line">vis_square(feat, padval=<span class="number">1</span>)</div></pre></td></tr></table></figure></p>
<p>最后的全连接层fc6和fc7，输出直方图：
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'fc6'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div><div class="line"></div><div class="line">feat = net.blobs[<span class="string">'fc7'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</div><div class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</div></pre></td></tr></table></figure></p>
<p><img src="http://i1.piimg.com/567571/44bbc67d60e82537.jpg" alt="fc"><br>最后的输出层，显示1000类概率的直方图信息：
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">feat = net.blobs[<span class="string">'prob'</span>].data[<span class="number">4</span>]</div><div class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</div><div class="line">plt.plot(feat.flat)</div></pre></td></tr></table></figure></p>
<p><img src="http://i1.piimg.com/567571/c9d3333a6724e4d0.jpg" alt="prob"><br>显示最后的类别信息top5：
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">imagenet_labels_filename = caffe_root + <span class="string">'data/ilsvrc12/synset_words.txt'</span></div><div class="line"><span class="keyword">try</span>:</div><div class="line">    labels = np.loadtxt(imagenet_labels_filename, str, delimiter=<span class="string">'\t'</span>)</div><div class="line"><span class="keyword">except</span>:</div><div class="line">    !../data/ilsvrc12/get_ilsvrc_aux.sh</div><div class="line">labels = np.loadtxt(imagenet_labels_filename, str, delimiter=<span class="string">'\t'</span>)</div><div class="line">top_k = net.blobs[<span class="string">'prob'</span>].data[<span class="number">4</span>].flatten().argsort()[<span class="number">-1</span>:<span class="number">-6</span>:<span class="number">-1</span>]</div><div class="line"><span class="keyword">print</span> labels[top_k]</div></pre></td></tr></table></figure></p>
<p><em>[out]：</em><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[&apos;n02123045 tabby, tabby cat&apos; </div><div class="line"> &apos;n02123159 tiger cat&apos;</div><div class="line"> &apos;n02124075 Egyptian cat&apos; </div><div class="line"> &apos;n02119022 red fox, Vulpes vulpes&apos;</div><div class="line"> &apos;n02127052 lynx, catamount&apos;]</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;根据薛开宇的caffe学习笔记中逐层可视化特征进行实践，中间出现了一些问题，记录如下：&lt;br&gt;&lt;strong&gt;1.caffe创建分类器&lt;/strong&gt;&lt;br&gt;Classifier继承自Net，可以从网络配置文件和模型中初始化网络，提供了一个predict函数，输入是一幅图片(w*H*K)返回的是一张N*C的numpy.ndarry。代表每张图片有可能对应的C个类别。也就是说，你以后用这个class会很方便，直接省去图片的初始化。源码位于：caffe-master\python\caffe下。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>结合特定任务边缘检测的图像语义分割</title>
    <link href="http://abumaster.com/2017/04/07/%E7%BB%93%E5%90%88%E7%89%B9%E5%AE%9A%E4%BB%BB%E5%8A%A1%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/04/07/结合特定任务边缘检测的图像语义分割/</id>
    <published>2017-04-07T07:38:22.000Z</published>
    <updated>2017-04-08T02:30:39.618Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。  </p>
</blockquote>
<a id="more"></a>
<p><strong>主要思想</strong><br>取代最后的全连接条件随机场和与其关联的双向过滤器，变为域变换（DT）一种边缘感知过滤器。域变换的递归公式等于信号的自适应递归滤波，其中信息不允许在某些参考信号中跨越边缘传播。速度快。<br><strong>前期工作</strong>  </p>
<ul>
<li>图像语义分割<br>网络中最大池化和下采样的出现，使稠密网络最后的输出图无法精准定位物体的边界信息，为了解决这个问题，出现了很多解决方案：组合中间特征图信息；反卷积和上采样；超像素等底层的分割方法；条件随机场，利用像素之间的依赖关系。  </li>
<li>边缘检测<br>学习物体的边界直接优化图像语义分割的表现。  </li>
<li>长距离依赖（Long range dependency）<br>通过DT输入进行反向传播，以共同学习端对端可训练系统中的分割图得分和边缘图。<br><strong>提出模型</strong><br>论文中提出的模型图：<br><img src="http://i4.buimg.com/567571/1043df45dae88c0c.png" alt=""><br>分为三个部分：<br>1.语义分割预测，得出一个大致的分割图，与全卷积网络输出图类似；<br>2.边缘预测网络，生成一个边缘预测图；<br>3.域转换，使用物体边界限制分割图。<br><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
x表示需要过滤的原始信号量，y表示域转换密度信号d。使用递归公式计算，初始化y1=x1，然后递归计算<code>i=2,...,N</code>：<br>$$y_i=(1-w_i)x_i+w_iy_{i-1}$$<br>其中权重wi的计算依赖di：<br>$$w_i=exp(-\sqrt2d_i/{\sigma_{s}})$$<br>一维计算树，前向和反向传播的计算：<br><img src="http://i2.muimg.com/567571/08cbd87d8bbbe172.png" alt=""><br>$$\frac{\partial L}{\partial x_i}\leftarrow (1-w_i)\frac{\partial L}{\partial y_i}$$<br>$$\frac{\partial L}{\partial w_i}\leftarrow \frac{\partial L}{\partial w_i}+(y_{i-1}-x_i)\frac{\partial L}{\partial y_i}$$<br>$$\frac{\partial L}{\partial y_{i-1}}\leftarrow \frac{\partial L}{\partial y_{i-1}}+w_i\frac{\partial L}{\partial y_i}$$<br>源码和模型<a href="http://liangchiehchen.com/projects/DeepLab.html">地址</a>。接下来学习。</li>
</ul>
<p><strong>参考文献</strong><br>[1] “Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform”
Liang-Chieh Chen, Jonathan T. Barron, George Papandreou, Kevin Murphy, and Alan L. Yuille
In Conference on Computer Vision and Pattern Recognition (CVPR), 2016</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;DeepLab作者团队另一篇论文：Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform[1]。指出传统的FCN-CRF模型最后基于图模型的全连接条件随机场虽然可以定位物体边界更加准确，但是它的计算代价大，因而提出了一种新的解决方案，空间转换（DT）替换crfs，这是一种边缘过滤保留方法。计算速度有一定的提升。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>进制转换</title>
    <link href="http://abumaster.com/2017/04/06/%E8%BF%9B%E5%88%B6%E8%BD%AC%E6%8D%A2/"/>
    <id>http://abumaster.com/2017/04/06/进制转换/</id>
    <published>2017-04-06T13:16:07.000Z</published>
    <updated>2017-04-06T14:09:19.093Z</updated>
    
    <content type="html"><![CDATA[<p><strong>题目描述</strong><br>将任意长度的二进制转换成十进制。<br>要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：<em>数字的n次方</em>、<em>大数相加</em>、<em>大数相乘</em>。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。<br><a id="more"></a>
<strong>解法</strong><br>二进制转换成十进制<br>观察：<code>10001000</code>的计算过程，转换成十进制为：<code>2^7+0+0+0+2^3+0+0+0</code>。<br>因此问题分为两个部分：计算二进制位置上为1时对应的十进制数是多少；对所有的位置得到的数字求和。<br>代码如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</div><div class="line"> * bin2dec 二进制转换成十进制</div><div class="line"> * @param decnum 十进制数字串</div><div class="line"> * @param n      二进制1后面的0的个数</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">bin2dec</span><span class="params">(<span class="keyword">int</span> *decnum, <span class="keyword">int</span> n)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> index = LEN<span class="number">-1</span>;</div><div class="line">	decnum[index] = <span class="number">1</span>;</div><div class="line">	<span class="keyword">int</span> jinwei = <span class="number">0</span>;</div><div class="line">	<span class="keyword">while</span> (n--) <span class="comment">//总共几个0</span></div><div class="line">	&#123;</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i = LEN<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> nowtemp = <span class="number">2</span>*decnum[i]+jinwei;</div><div class="line">			<span class="keyword">if</span>(nowtemp&gt;=<span class="number">10</span>)<span class="comment">//需要进位</span></div><div class="line">			&#123;</div><div class="line">				decnum[i] = nowtemp%<span class="number">10</span>; <span class="comment">//改变当前的数值</span></div><div class="line">				jinwei = nowtemp/<span class="number">10</span>; <span class="comment">//进位的多少</span></div><div class="line">			&#125;</div><div class="line">			<span class="keyword">else</span></div><div class="line">			&#123;</div><div class="line">				decnum[i] = nowtemp;</div><div class="line">				jinwei=<span class="number">0</span>;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</div><div class="line"> * 将两个大数合并，放入左边数组</div><div class="line"> * @param left  相加结果放入此</div><div class="line"> * @param right 数组</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">sumbignum</span><span class="params">(<span class="keyword">int</span> *left, <span class="keyword">int</span> *right, <span class="keyword">int</span> n=LEN)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> jinwei = <span class="number">0</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=n<span class="number">-1</span>; i&gt;=<span class="number">0</span>; i--)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> temp = left[i]+right[i]+jinwei;<span class="comment">//俩数之和加上进位标志</span></div><div class="line">		<span class="keyword">if</span>(temp &gt;= <span class="number">10</span>)<span class="comment">//需要进位的</span></div><div class="line">		&#123;</div><div class="line">			left[i] = temp%<span class="number">10</span>;</div><div class="line">			jinwei = temp/<span class="number">10</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">else</span> <span class="comment">//不用进位</span></div><div class="line">		&#123;</div><div class="line">			left[i] = temp;</div><div class="line">			jinwei = <span class="number">0</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>十进制转换成二进制</strong><br>同理，位数少的十进制转换成二进制一般应用除2求余，然后直到商为0。<a href="http://baike.baidu.com/link?url=QHeUym9N6IWCVV6zLmIHIX6Y6CMPOfthTCyDRkfsq9TAxCjewlxrfhHYUw2sarVURML8-Oyz0bCASXtMqHqUWYGGRieuENcGHN30Qzmx6Ef_XdJSIaiBCn0vfvUrrILr4t15XLZWOj6RIdcgit792Vn5iQGGQYVyOfQF4R2ggfm">参考</a>。<br>对于大数，可以保存在一个数组中，用前一位的余数与当前的位数拼成一个数，除以2，商替换原数字对应的位数上，余数更新，直到把数字的位数计算完，算作得出二进制的一位（最后得出的余数）。直到商为0结束。代码如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></div><div class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="keyword">int</span> LEN = <span class="number">100</span>;</div><div class="line"><span class="comment">/**</div><div class="line"> * 检查数组代表的数字是否为空</div><div class="line"> * @param  arr [description]</div><div class="line"> * @param  len [description]</div><div class="line"> * @return     [description]</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsZero</span><span class="params">(<span class="keyword">int</span> *arr, <span class="keyword">int</span> len)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">bool</span> ret = <span class="literal">true</span>;</div><div class="line">	<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">if</span>(arr[i] != <span class="number">0</span>)</div><div class="line">		&#123;</div><div class="line">			ret = <span class="literal">false</span>;</div><div class="line">			<span class="keyword">break</span>;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	<span class="keyword">return</span> ret;</div><div class="line">&#125;</div><div class="line"><span class="comment">/**</div><div class="line"> * 十进制转换成二进制的核心函数</div><div class="line"> * @param decnum 十进制保存位置</div><div class="line"> * @param binnum 二进制字符串</div><div class="line"> * @param len    十进制长度</div><div class="line"> */</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">dec2binCore</span><span class="params">(<span class="keyword">int</span> *decnum, <span class="keyword">int</span> *binnum, <span class="keyword">int</span> len)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> mod;</div><div class="line">	<span class="keyword">int</span> index = LEN<span class="number">-1</span>;</div><div class="line">	<span class="keyword">while</span>(!IsZero(decnum, len))<span class="comment">//十进制表示的数字不为0</span></div><div class="line">	&#123;</div><div class="line">		mod = <span class="number">0</span>;</div><div class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i =<span class="number">0</span>; i&lt;len; i++)</div><div class="line">		&#123;</div><div class="line">			<span class="keyword">int</span> tempnum = <span class="number">10</span>*mod+decnum[i];</div><div class="line">			<span class="keyword">int</span> sang = tempnum/<span class="number">2</span>;</div><div class="line">			mod = tempnum%<span class="number">2</span>;</div><div class="line">			decnum[i] = sang; <span class="comment">//更新商</span></div><div class="line">		&#125;</div><div class="line">		binnum[index--] = mod;<span class="comment">//最后的余数是二进制</span></div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">PrintInt</span><span class="params">(<span class="keyword">int</span> *arr, <span class="keyword">int</span> n)</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="keyword">int</span> start = <span class="number">0</span>;<span class="comment">//bug</span></div><div class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n<span class="number">-1</span>; i++)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> j = i+<span class="number">1</span>;</div><div class="line">		<span class="keyword">if</span>(arr[i]==<span class="number">0</span> &amp;&amp; arr[j]!=<span class="number">0</span> &amp;&amp; !start)</div><div class="line">		&#123;</div><div class="line">			start = <span class="number">1</span>;</div><div class="line">		&#125;</div><div class="line">		<span class="keyword">if</span> (start)</div><div class="line">			<span class="built_in">cout</span> &lt;&lt; arr[j];</div><div class="line">	&#125;</div><div class="line">	<span class="built_in">cout</span> &lt;&lt; <span class="built_in">endl</span>;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">testdec2bin</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	<span class="built_in">string</span> strnum;</div><div class="line">	<span class="keyword">while</span>(<span class="built_in">cin</span> &gt;&gt; strnum)</div><div class="line">	&#123;</div><div class="line">		<span class="keyword">int</span> len = strnum.size();</div><div class="line">		<span class="keyword">int</span> *decnum = <span class="keyword">new</span> <span class="keyword">int</span>[len];</div><div class="line">		<span class="built_in">memset</span>(decnum, <span class="number">0</span>, len*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)</div><div class="line">			decnum[i]= strnum[i]-<span class="string">'0'</span>;</div><div class="line">		<span class="keyword">int</span> *binnum = <span class="keyword">new</span> <span class="keyword">int</span>[LEN];</div><div class="line">		<span class="built_in">memset</span>(binnum, <span class="number">0</span>, LEN*<span class="keyword">sizeof</span>(<span class="keyword">int</span>));</div><div class="line">		dec2binCore(decnum, binnum, len);</div><div class="line">		PrintInt(binnum, LEN);</div><div class="line">	&#125;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></div><div class="line"></span>&#123;</div><div class="line">	testdec2bin();</div><div class="line"></div><div class="line">	system(<span class="string">"pause"</span>);</div><div class="line">	<span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>感悟</strong>
看似简单的问题，还要细思量。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;题目描述&lt;/strong&gt;&lt;br&gt;将任意长度的二进制转换成十进制。&lt;br&gt;要求任意长度，所以，不能常规的按照整型或长整型来表示，任意长度的数字，这里还要考虑溢出。因此，考虑字符串表示，同样的题目还有：&lt;em&gt;数字的n次方&lt;/em&gt;、&lt;em&gt;大数相加&lt;/em&gt;、&lt;em&gt;大数相乘&lt;/em&gt;。主要思想：用字符串或者数组保存数字，计算时利用进位和标准运算进行。&lt;br&gt;
    
    </summary>
    
      <category term="编程" scheme="http://abumaster.com/categories/programming/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
      <category term="技巧" scheme="http://abumaster.com/tags/jq/"/>
    
  </entry>
  
  <entry>
    <title>全卷积网络和全连接条件随机场</title>
    <link href="http://abumaster.com/2017/04/05/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/"/>
    <id>http://abumaster.com/2017/04/05/全卷积网络和全连接条件随机场/</id>
    <published>2017-04-05T07:08:55.000Z</published>
    <updated>2017-04-06T13:10:41.589Z</updated>
    
    <content type="html"><![CDATA[<p>来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015.  主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。<br><a id="more"></a>
<strong>主要创新点：</strong><br>1.带孔卷积<br>在最后两个池化层后，跳过子采样，修改之后的卷积过滤器，变为卷积层。命名为孔算法，解释如图：<br><img src="http://i1.piimg.com/567571/ceb8871164ae116c.png" alt="">  </p>
<ul>
<li>高效的特征提取算法，有效的稠密滑动窗口特征提取器  </li>
<li>控制接受域大小，加速卷积网络的计算  </li>
</ul>
<p>2.边界恢复问题<br>目前定位物体边界的挑战主要从两个方面：  </p>
<ul>
<li>利用融合不同层特征图的相关信息，估计物体边界  </li>
<li>利用超像素表征，将任务委托给低层次的分割任务  </li>
</ul>
<p>模型：<br><img src="http://i1.piimg.com/567571/17c50f02e9958365.png" alt="">  </p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>
$$E(x)=\sum_i\theta_i(x_i)+\sum_{ij}\theta_{ij}(x_i,x_j)$$<br>有一元项和二元项。<br>3.多尺度预测<br>为了增加边界定位的准确性，用了多尺度预测。具体是，为输入图像和第一个四层最大池化层附加一个双层MLP（第一层：<code>128 个3*3的卷积核</code>，第二层：<code>128个1*1的卷积核</code>）与最后一层的特征图连接。汇总的特征图，放入softmax层，产生<code>5*128=640</code>通道。  </p>
<p><strong>系统实现</strong><br>DeepLab：使用深度卷积网络，atrous卷积和全连接crfs的图像语义分割模型。<br>针对传统方法的不足：  </p>
<ul>
<li>减少特征解析度（重复的最大池化和下采样）  </li>
<li>存在多个尺度的对象  </li>
<li>由于深度网络的稳定性导致定位精度下降<br>提出的优化方案：  </li>
<li>不采样  </li>
<li>atrous spatial pyramid pooling 空间金字塔池化  </li>
<li>结合条件随机场<br><strong>细节</strong><br>atrous卷积的计算，一维信号量示例如图：<br><img src="http://i1.piimg.com/567571/e4d2c7eb9eaa6b1e.png" alt=""><br>$$y[i]=\sum_{k=1}^Kx[i+r\cdot{k}]w[k]$$<br>全连接条件随机场：<br>关于能量函数，第一项由预测网络给出的预测值；第二项：<br><img src="http://i1.piimg.com/567571/c38b63130a578629.png" alt=""><br>公式分为两项，第一项是节点值不相等时为1，相等时为0，为了表示不同的标签将要受到惩罚。第二项，有两个高斯核组成，第一个是用像素的位置和像素的值表示，第二个是用像素之间的位置表示，他们是不同空间的特征。
<img src="http://i2.muimg.com/567571/020f15b2235a3483.png" alt=""></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;来自论文Semantic image segmentation with deep convolutional nets and fully connected crfs 2015.  主要针对将深度卷积网络应用到图像标记任务中的两个问题：下采样，和从分类网络中获得以物体为中心的描述。提出了像素级别的条件随机场和基于DCNN的一元项的结合的模型。优点：速度快，正确度高，模型简单。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
</feed>
