<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>张国丰</title>
  <subtitle>张国丰的博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://abumaster.com/"/>
  <updated>2017-03-29T06:20:44.238Z</updated>
  <id>http://abumaster.com/</id>
  
  <author>
    <name>abumaster</name>
    <email>1902819397@qq.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>图床测试‘ </title>
    <link href="http://abumaster.com/2017/03/29/%E5%9B%BE%E5%BA%8A%E6%B5%8B%E8%AF%95/"/>
    <id>http://abumaster.com/2017/03/29/图床测试/</id>
    <published>2017-03-29T06:20:44.000Z</published>
    <updated>2017-03-29T06:20:44.238Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Feedforward semantic segmentation with zoom-out features</title>
    <link href="http://abumaster.com/2017/03/27/Feedforward-semantic-segmentation-with-zoom-out-features/"/>
    <id>http://abumaster.com/2017/03/27/Feedforward-semantic-segmentation-with-zoom-out-features/</id>
    <published>2017-03-27T06:21:29.000Z</published>
    <updated>2017-03-29T02:49:47.429Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>使用缩小特征的前馈语义分割 Feedforward semantic segmentation with zoom-out features 2015年CVPR论文，在PASCAL VOC 2012测试集上达到了69.9%的正确率。将小的图像元素（超像素）映射到丰富的特征表示中，这些特征是从嵌套的增加区域中获得。这些区域通过从超像素一直缩小到场景级别的分辨率获得。这种方法充分利用了图像和隐藏空间中的统计结构，而不显式设置结构化预测机制，从而避免了复杂、昂贵的推论。从而超像素是由多层前馈网络进行分类。  </p>
</blockquote>
<a id="more"></a>
<p>从大量的现代分割著作中，得到了一种被广泛接受的知识，<strong>分割可以看成一个结构化预测的任务</strong>，可以用条件随机场和结构化支持向量机模型。作者脱离传统，提出<strong>图像语义分割看作单阶段的分类任务，其中每个像素元素（超像素）被标记为一个标签，使用一个前馈模型，依据从图像计算的证据</strong>。用在前馈分类中的证据不是从孤立的局部区域中获得，而是从序列中获得，序列是怎么组成的呢？首先得到一个超像素，再向外扩展，获得一个更大的闭合区域，直到扩展到整张图片。计算每一个层次的丰富特征，结合所有特征，放入分类网络中。<br><img src="/photos/zoom-out.jpg" alt="zoom-out">  </p>
<p>###缩小的特征融合<br>将图像的类别分割转换成对一组超像素分类。由于我们期望为每个超级像素应用相同的分类机，我们希望超像素的性质是相似的，特别是它们的大小。使用了SLIC。<br><strong>本地</strong><br>超像素本身有很窄的范围，我们希望特征提取器可以捕获更多的本地信息：颜色，上下文，其他一些属性，在临近的超像素之间这些属性有很大的不同。<br><strong>近似</strong><br><strong>距离</strong><br><strong>场景</strong>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;使用缩小特征的前馈语义分割 Feedforward semantic segmentation with zoom-out features 2015年CVPR论文，在PASCAL VOC 2012测试集上达到了69.9%的正确率。将小的图像元素（超像素）映射到丰富的特征表示中，这些特征是从嵌套的增加区域中获得。这些区域通过从超像素一直缩小到场景级别的分辨率获得。这种方法充分利用了图像和隐藏空间中的统计结构，而不显式设置结构化预测机制，从而避免了复杂、昂贵的推论。从而超像素是由多层前馈网络进行分类。  &lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>全卷积网络用于图像语义分割</title>
    <link href="http://abumaster.com/2017/03/25/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>http://abumaster.com/2017/03/25/全卷积网络用于图像语义分割/</id>
    <published>2017-03-25T07:31:02.000Z</published>
    <updated>2017-03-26T08:52:35.544Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>全卷积网络用于图像语义分割 (Fully Convolutional Networks for Semantic Segmentation)<sup>[1]</sup>  </p>
</blockquote>
<p>全卷积网络实际上就是把普通卷积网络的最后的全连接层变为卷积层，因为全连接层会把空间信息隐藏，全部展开为一维向量，换为卷积可以保留空间信息。如VGG-16网络在处理ImageNet数据集时，最后的1000个输出，是1000维向量，来表示1000类事物的概率，当换为卷积层时，输出了1000个1*1大小的输出，对此上采样，可以输出对应的heat-map。这是分类网络作为稠密输出的关键。<br><a id="more"></a></p>
<p><strong>文章解决的问题是如何生成稠密的预测即dense prediction</strong>  </p>
<ol>
<li><del>Shift-and-stitch</del><br>假设原图和FCN输出图之间的降采样因子<code>f</code>，对于原图的每个<code>f*f</code>区域，对于<code>0 &lt;= x,y &lt;f</code>处理这 f<sup>2</sup> 个输入，并且交替输出，使得预测在接受域的中心像素。每个像素对应一个中心像素，因此为稠密输出。缺点：感受野没变，但是原图被划分为了<code>f*f</code>大小的图像片作为输入图像，使得网络无法感受更加精细的信息。   </li>
<li>稀疏过滤器<br>调整下采样过程中的步长，变为1，可以保证下采样不会损失图像的大小。缺点：下采样的功能被减弱，同时保留了更多信息，接受域相对变小，可能损失全局信息，同样为卷积层带来了更多的运算。  </li>
<li>上采样<br>上采样（Upsampling）也称反卷积（Deconvolution），参数和卷积一样可以在训练中学习。运算也和卷积类似，为逆过程。<br>设输入大小<code>w0*h0</code>，经过卷积后的大小为<code>w1*h1</code>，计算公式如下：<br><em>卷积运算：</em><br><code>w1 = (w0 + 2*pad - kernelsize)/stride + 1</code><br><code>h1 = (h0 + 2*pad - kernelsize)/stride + 1</code><br><em>反卷积运算：</em><br><code>w0 = (w1 - 1)*stride + kernelsize - 2*pad</code><br><code>h0 = (h1 - 1)*stride + kernelsize - 2*pad</code><br>经过上采样后的图像可能会比原图大，需要裁剪为原图像大小，caffe中的crop层，提供了很好的算法。  </li>
</ol>
<p><strong>语义分割的框架结构</strong><br>文中提出的框架结构如图所示：<br><img src="/photos/fcn.png" alt="fcn"><br>作者发现32倍率的上采样导致输出图非常粗糙，因此想出了利用上层的一些特征来优化输出图像，就有了FCN-16s和FCN-8s的方案，其主要思想是利用上层的池化层的信息，减少上采样的倍率，保留了更多的特征。 </p>
<p><strong>具体的实践</strong><br>针对传统网络的全连接层变为卷积层，如VGG-16网络中第一个卷积层是<code>25088*4096</code>，将之解释为<code>512*7*7*4096</code>。产生端对端的训练模型。在论文提供的源码中，FCN-32s的配置文件，第一个卷积层为：  </p>
<pre><code>layer {
  name: &quot;conv1_1&quot;
  type: &quot;Convolution&quot;
  bottom: &quot;data&quot;
  top: &quot;conv1_1&quot;
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 100 #填充100
    kernel_size: 3
    stride: 1
  }
}
</code></pre><p>填充100的原因为：在VGG-16网络中卷积的参数，kernersize=3，stride=1，pad=1，所以卷积层不会改变图像的大小，所以图像只有在池化层改变大小，且变为原大小的一半。为了方便将图像看为一维的，设原图像大小h，经过了5层池化后，图像缩小了32倍，变为<code>h5 = h/32</code>，紧接着全连接层，可以看成是卷积层，卷积参数为：<code>kernelsize=7 pad=0 stride=1</code>，根据卷积计算公式，经过卷积层fc6后的输出图像大小为<code>h6 = (h5-7)/1 + 1 = (h-192)/32</code> 因此，图像小于192的就无法往下计算了，所以要<code>pad=100</code>，解决了网络输入图像固定大小的弊端，全卷积网络可以输入任意大小的图像。  </p>
<hr>
<p><strong>例子</strong><br>根据FCN-32s的配置文件<br>如果输入图像大小为<code>3*320*320</code><br>经过了卷积conv1的输出为：<code>64*518*518</code><br>经过了池化pool1的输出为：<code>64*259*259</code><br>经过了卷积conv2的输出为：<code>128*259*259</code><br>经过了池化pool2的输出为：<code>128*130*130</code><br>经过了卷积conv3的输出为：<code>256*130*130</code><br>经过了池化pool3的输出为：<code>256*65*65</code><br>经过了卷积conv4的输出为：<code>512*65*65</code><br>进过了池化pool4的输出为：<code>512*32*32</code><br>经过了卷积conv5的输出为：<code>512*32*32</code><br>经过了池化pool5的输出为：<code>512*16*16</code><br>经过了fc6的卷积后输出为：<code>4096*10*10</code><br>经过了fc7的卷积后输出为：<code>4096*10*10</code><br>经过score_fr的卷积输出：<code>21*10*10</code><br>上采样（反卷积）输出为：<code>21*352*352</code><br>score层裁剪后输出为：<code>21*320*320</code>  </p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;全卷积网络用于图像语义分割 (Fully Convolutional Networks for Semantic Segmentation)&lt;sup&gt;[1]&lt;/sup&gt;  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;全卷积网络实际上就是把普通卷积网络的最后的全连接层变为卷积层，因为全连接层会把空间信息隐藏，全部展开为一维向量，换为卷积可以保留空间信息。如VGG-16网络在处理ImageNet数据集时，最后的1000个输出，是1000维向量，来表示1000类事物的概率，当换为卷积层时，输出了1000个1*1大小的输出，对此上采样，可以输出对应的heat-map。这是分类网络作为稠密输出的关键。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>卷积网络应该注意的问题</title>
    <link href="http://abumaster.com/2017/03/24/%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E5%BA%94%E8%AF%A5%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98/"/>
    <id>http://abumaster.com/2017/03/24/卷积网络应该注意的问题/</id>
    <published>2017-03-24T06:28:18.000Z</published>
    <updated>2017-03-25T07:05:46.835Z</updated>
    
    <content type="html"><![CDATA[<p>卷积神经网络简介，由于其出色的特征提取特性，使得在计算机视觉方面有了很好的应用，并取得了出色的成绩。<br><strong>卷积</strong><br>卷积操作是卷积网络中的核心操作，其主要目的是为了提取图像的显著特征，降低特征维数，进而来减少计算量。在 caffe 代码中的主要参数如下：<br><a id="more"></a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;conv1&quot;</div><div class="line">  type: &quot;Convolution&quot;</div><div class="line">  bottom: &quot;data&quot; #上层是数据层</div><div class="line">  top: &quot;conv1&quot;</div><div class="line">  param &#123; #权重学习参数</div><div class="line">    lr_mult: 1 #权重学习率 需要乘以基础学习率base\_lr</div><div class="line">    decay_mult: 1</div><div class="line">  &#125;</div><div class="line">  param &#123; #偏置学习参数</div><div class="line">    lr_mult: 2</div><div class="line">    decay_mult: 0</div><div class="line">  &#125;</div><div class="line">  convolution_param &#123; #卷积参数</div><div class="line">    num_output: 96 #卷积操作后的输出特征图</div><div class="line">    kernel_size: 11 #卷积核大小</div><div class="line">    stride: 4 #步长 #可能也有pad为扩充边缘 </div><div class="line">    weight_filler &#123; #权值初始化</div><div class="line">      type: &quot;gaussian&quot; #类型为weight-filter 或xavier算法等，默认constant，全部0</div><div class="line">      std: 0.01</div><div class="line">    &#125;</div><div class="line">    bias_filler &#123; #偏置的初始化</div><div class="line">      type: &quot;constant&quot;</div><div class="line">      value: 0</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>输入：<code>n*c0*w0*h0</code><br>输出：<code>n*c1*w1*h2</code><br>c1对应num_output，输出对应的大小计算:<br><code>w1 = (w0 + 2*pad - kernersize)/stride + 1</code><br><code>h1 = (h0 + 2*pad - kernelsize)/stride + 1</code><br>在 <strong>caffe</strong> 源码中的计算是将图像和卷积核通过 im2col 转换成矩阵，再对两矩阵内积。 </p>
<p><strong>池化</strong><br>池化也称下采样，为了减少运算和数据维度的一种方式，被分为：  </p>
<ul>
<li>最大池化（Max Pooling），取最大值；  </li>
<li>均值池化（Mean Pooling），取均值；  </li>
<li>高斯池化。<br><strong>caffe</strong> 中的配置代码：  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;pool1&quot;</div><div class="line">  type: &quot;Pooling&quot;</div><div class="line">  bottom: &quot;norm1&quot;</div><div class="line">  top: &quot;pool1&quot;</div><div class="line">  pooling_param &#123; #池化参数</div><div class="line">    pool: MAX #池化类型</div><div class="line">    kernel_size: 3 #池化核大小</div><div class="line">    stride: 2 #步长，重叠</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<p>池化的计算公式与卷积操作类似：<br>输入：<code>n*c0*w0*h0</code><br>输出：<code>n*c1*w1*h2</code><br>c1对应num_output，输出对应的大小计算:<br><code>w1 = (w0 + 2*pad - kernersize)/stride + 1</code><br><code>h1 = (h0 + 2*pad - kernelsize)/stride + 1</code>  </p>
<p><strong>LRN层</strong><br>LRN全称为Local Response Normalization，即局部响应归一化层，没什么用，有一些网络中加入了这一层，对局部区域进行归一化，配置信息和参数说明如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">layer &#123;</div><div class="line">  name: &quot;norm1&quot;</div><div class="line">  type: &quot;LRN&quot;</div><div class="line">  bottom: &quot;conv1&quot;</div><div class="line">  top: &quot;norm1&quot;</div><div class="line">  lrn_param &#123; #参数</div><div class="line">    local_size: 5 #（1）通道间归一化时表示求和的通道数；</div><div class="line">    #（2）通道内归一化时表示求和区间的边长；</div><div class="line">    alpha: 0.0001 #缩放因子</div><div class="line">    beta: 0.75 #指数项</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p><strong>激活函数</strong></p>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script><br>激活函数需要具有以下特性：  </p>
<ul>
<li>非线性；  </li>
<li>单调、连续可微分；  </li>
<li>范围不饱和，避免梯度为0；  </li>
<li>原点近似线性。<br>常用的激活函数有：<strong>Sigmoid 函数</strong>、<strong>Tanh 函数</strong>、<strong>ReLU 函数</strong>等。<br>如 <strong>AlexNet</strong> 中用到的ReLU激活函数：<br>$$f(x)=max(0,x)$$<br>这种激活函数的特点是：无梯度损耗，收敛速度快，网络稀疏性大，计算量小。缺点是，梯度大的话，导致权重更新以后变大，输出0，使得神经元不再更新。因此要注意学习率的设置。  </li>
</ul>
<p><strong>全连接层</strong><br>全连接层又称内积层（Inner-Product），是将特征图像全部展开为一维向量。<br><strong>caffe</strong> 中的文档显示：  </p>
<ul>
<li>Input<br><code>n * c_i * h_i * w_i</code>  </li>
<li>Output<br><code>n * c_o * 1 * 1</code><br>这里引用了<a href="http://www.cnblogs.com/dupuleng/articles/4312149.html">dupuleng</a>的例子。<br>lenet 网络配置文件中的一段：  </li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">layers &#123;</div><div class="line">  name: &quot;conv2&quot;</div><div class="line">  type: CONVOLUTION</div><div class="line">  bottom: &quot;pool1&quot;</div><div class="line">  top: &quot;conv2&quot;</div><div class="line">  blobs_lr: 1</div><div class="line">  blobs_lr: 2</div><div class="line">  convolution_param &#123;</div><div class="line">    num_output: 50</div><div class="line">    kernel_size: 5</div><div class="line">    stride: 1</div><div class="line">    weight_filler &#123;</div><div class="line">      type: &quot;xavier&quot;</div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: &quot;constant&quot;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">layers &#123;</div><div class="line">  name: &quot;pool2&quot;</div><div class="line">  type: POOLING</div><div class="line">  bottom: &quot;conv2&quot;</div><div class="line">  top: &quot;pool2&quot;</div><div class="line">  pooling_param &#123;</div><div class="line">    pool: MAX</div><div class="line">    kernel_size: 2</div><div class="line">    stride: 2</div><div class="line">  &#125;</div><div class="line">&#125;</div><div class="line">layers &#123;</div><div class="line">  name: &quot;ip1&quot;</div><div class="line">  type: INNER_PRODUCT</div><div class="line">  bottom: &quot;pool2&quot;</div><div class="line">  top: &quot;ip1&quot;</div><div class="line">  blobs_lr: 1</div><div class="line">  blobs_lr: 2</div><div class="line">  inner\_product\_param &#123;</div><div class="line">    num_output: 500</div><div class="line">    weight_filler &#123;</div><div class="line">      type: &quot;xavier&quot;</div><div class="line">    &#125;</div><div class="line">    bias_filler &#123;</div><div class="line">      type: &quot;constant&quot;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>conv2 的输入图像是<code>256*27*27</code>经过了卷积操作，输出<code>50*22*22</code>同样作为了pool2的输入，进行池化，pool2的输出<code>50*11*11</code>，下一层全连接层，输出<code>500*1*1</code>的向量，是如何进行计算的呢？要把所有通道全部展开做卷积，首先要把pool2输出的特征图展开为一维向量，共需要<code>500*50*11*11</code>个参数，进行卷积，输出<code>500*1*1</code>的一维向量。  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;卷积神经网络简介，由于其出色的特征提取特性，使得在计算机视觉方面有了很好的应用，并取得了出色的成绩。&lt;br&gt;&lt;strong&gt;卷积&lt;/strong&gt;&lt;br&gt;卷积操作是卷积网络中的核心操作，其主要目的是为了提取图像的显著特征，降低特征维数，进而来减少计算量。在 caffe 代码中的主要参数如下：&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
      <category term="caffe" scheme="http://abumaster.com/tags/caffe/"/>
    
  </entry>
  
  <entry>
    <title>Conditional Random Fields as Recurrent Neural Networks</title>
    <link href="http://abumaster.com/2017/03/21/CRFs-as-RNN/"/>
    <id>http://abumaster.com/2017/03/21/CRFs-as-RNN/</id>
    <published>2017-03-21T08:00:18.000Z</published>
    <updated>2017-03-21T12:40:34.307Z</updated>
    
    <content type="html"><![CDATA[<blockquote>
<p>2015 年 ICCV 会议文章 Conditional Random Fields as Recurrent Neural Networks<sup>[1]</sup> 的阅读笔记。    </p>
</blockquote>
<p><strong>关键词</strong><br>图像语义分割<br>CRF as RNN<br><strong>摘要</strong><br>像素级别的标注任务，例如图像语义分割在图像理解方面占据着重要的作用。最近的方法开始利用深度学习技术在图像识别任务上的能力来解决像素级别的标注任务。现在的核心问题是深度学习方法在描绘可视化物体具有限制性。为了解决这个问题，我们提出了一个新形式的卷积网络，它结合了卷积网络的优势和条件随机场的概率图模型。为此，我们制定了使用高斯对模型和中值近似的条件随机场作为循环神经网络。这个网路就是 CRF-RNN 被嵌入到 CNN 中，最为一个集 CNNs 和 CRFs 优点于一体的深度网络。更重要的是，我们的系统完全在 CNNs 中集成了 CRF 模型，让使用传统的反向传播算法训练端对端的系统成为了可能，不需要额外的后期处理物体的边界。<br><a id="more"></a><br><del><strong>MarkDown 中使用公式</strong></del>  </p>
<ol>
<li>加入脚本定义，现在用到的是 MathJax 引擎<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;</div><div class="line">&lt;/script&gt;</div></pre></td></tr></table></figure>
</li>
</ol>
<p><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>  </p>
<ol>
<li>使用Tex公式 $$行间公式；\\行内公式，参考<a href="https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference">MathJax basic tutorial and quick reference</a>  </li>
<li>示例<br>$$x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}$$  </li>
</ol>
<hr>
<p><strong>引言</strong><br>低层次计算机视觉问题，为图像中的像素分配标签。特征表示在个体像素分类中占有重要的作用。同样要考虑到图像的边界和特征、空间关系，以此来获得较为准确地分割结果。<br>设计出一个<strong>强大的特征表示器是像素级别标记的关键挑战</strong>。传统的方法不再讨论，现在深度学习的方法利用大尺度的卷积网络，在高层次视觉上取得了非常大的成果。这激励着利用卷积网络去解决低层次的问题。主要利用卷积网络提取特征替代以前的手工标注特征。<br>将用于高层视觉的分类网络转换成低层次视觉的任务依然存在着一些问题提出了几个问题：  </p>
<ul>
<li>传统的卷积网络有大接受域的卷积过滤器，会产生比较粗糙的输出图。最大池化层的出现，过滤掉一些特征，导致了输出的分割图不够精细。  </li>
<li>缺少了平滑度约束，没有考虑到相似的像素，空间或者外形相似的约束，导致了输出图的边界不明确，或者出现杂散区域。<br>尤其是马尔科夫随机场（MRFs）和它的变体条件随机场（CRFs）已经成为应用到计算机视觉领域中一个成功的模型。<strong>用于像素标记的CRFs推理主要的思想是将语义标签分配问题转换成概率推理问题，包括了相似像素之间一致性并入假设</strong>。CRFs可以微调分割图的细节，优化边界问题，克服了单纯利用CNNs的缺点。<del>用CRFs作为后期的处理，无法发挥出CRF的优势，卷积网络在训练的阶段也无法根据CRF的表现来调整权重</del>。本文将CNN与CRF结合为一个统一的框架，可以共同训练。<br><strong>相关工作</strong><br>许多方法用深度学习来解决图像语义分割问题，可以归为以下两个类别：  </li>
</ul>
<ul>
<li>特征提取和分割分离开的策略。使用CNN提取有意义的图像特征，利用超像素去构造图像的模式。首先从图像中获得超像素，再用特征提取器提取特征。存在着一个致命的缺点，前期如果有误差，后面误差越来越大。与他们的方案不同，此文用典型的图模型CRF可以被作为RNN，指定为深度网络的一部分。结合CNN实现端对端的训练。  </li>
<li>直接学习从原始图像到标记图像的非线性模型。例如FCN等网络，去掉了最后的全连接层变为卷积层。<br><strong>全连接条件随机场</strong>  <div align=center> <img src="/photos/crfs.jpg" alt="CRFs"></div><br>条件随机场进行图像语义分割的能量函数：定义隐变量Xi为像素点i的分类标签，取值范围为分类语义标签L={l1,l2,l3,…,ln}；Yi为每个随机变量Xi的观测值，即是每个像素的颜色值。条件随机场的目标就是通过观测变量Yi，推理出潜变量Xi的标签。<br>对于一张图像，可以看成图模型<code>G=(V,E)</code>，每个顶点对应了<code>V={X1,X2,...,Xn}</code>，对于边来说，全连接的条件随机场，顶点与所有的点都有连线。<br>条件随机场的目标函数：<br>能量函数有一元势函数和二元势函数，分别表示了当像素点i的观测值是yi时，该像素点属于标签xi的概率。可以直接从cnn中计算出。二元是函数是两个像素值相似或者相邻则两个像素属于同一类的概率很大。<br><strong>实现</strong><br><div align=center> <img src="/photos/algo.png" alt="algorithm"></div>  


</li>
</ul>
<p><strong>参考文献</strong><br>[1] Zheng S, Jayasumana S, Romera-Paredes B, et al. Conditional random fields as recurrent neural networks[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 1529-1537.</p>
]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;2015 年 ICCV 会议文章 Conditional Random Fields as Recurrent Neural Networks&lt;sup&gt;[1]&lt;/sup&gt; 的阅读笔记。    &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;关键词&lt;/strong&gt;&lt;br&gt;图像语义分割&lt;br&gt;CRF as RNN&lt;br&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;br&gt;像素级别的标注任务，例如图像语义分割在图像理解方面占据着重要的作用。最近的方法开始利用深度学习技术在图像识别任务上的能力来解决像素级别的标注任务。现在的核心问题是深度学习方法在描绘可视化物体具有限制性。为了解决这个问题，我们提出了一个新形式的卷积网络，它结合了卷积网络的优势和条件随机场的概率图模型。为此，我们制定了使用高斯对模型和中值近似的条件随机场作为循环神经网络。这个网路就是 CRF-RNN 被嵌入到 CNN 中，最为一个集 CNNs 和 CRFs 优点于一体的深度网络。更重要的是，我们的系统完全在 CNNs 中集成了 CRF 模型，让使用传统的反向传播算法训练端对端的系统成为了可能，不需要额外的后期处理物体的边界。&lt;br&gt;
    
    </summary>
    
      <category term="深度学习" scheme="http://abumaster.com/categories/deeplearning/"/>
    
    
      <category term="论文" scheme="http://abumaster.com/tags/lunwen/"/>
    
      <category term="深度学习" scheme="http://abumaster.com/tags/deeplearn/"/>
    
  </entry>
  
  <entry>
    <title>柔性数组</title>
    <link href="http://abumaster.com/2017/03/12/%E6%9F%94%E6%80%A7%E6%95%B0%E7%BB%84/"/>
    <id>http://abumaster.com/2017/03/12/柔性数组/</id>
    <published>2017-03-12T13:59:48.000Z</published>
    <updated>2017-03-21T08:45:40.231Z</updated>
    
    <content type="html"><![CDATA[<h3 id="C-C-中的0长数组"><a href="#C-C-中的0长数组" class="headerlink" title="C/C++中的0长数组"></a>C/C++中的0长数组</h3><hr>
<p>定义：柔性数组（Flexible Array）也叫伸缩性数组、变长数组。<br></p>
<h2 id="作用-：放入结构体中，可以存放动态长度的字符串、数组等。"><a href="#作用-：放入结构体中，可以存放动态长度的字符串、数组等。" class="headerlink" title="作用 ：放入结构体中，可以存放动态长度的字符串、数组等。"></a>作用 ：放入结构体中，可以存放动态长度的字符串、数组等。</h2><ul>
<li>用法举例：<br><br>放在结构体的最后，长度为0的数组。长度为0不占用任何空间，数组名只是一个符号，代表了一个不可改变的地址。  </li>
</ul>
<a id="more"></a>
<figure class="highlight c"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">struct</span> package &#123;</div><div class="line">	<span class="keyword">int</span> len;</div><div class="line">	<span class="keyword">char</span> data[<span class="number">0</span>];</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<ul>
<li>用途：<br>根据变长数组的特性很容易构造出一些数据结构，缓冲区、数据包等。不会浪费多余的空间，用多少申请多少。<br></li>
<li>使用:<br>假设用上面的结构来发送1024字节大小的数据包，首先要构造一个数据包：<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">char *pMsg = (char *)malloc(sizeof(package)+1024); </div><div class="line">package *pPack = (package*)pMsg;</div><div class="line">pPack-&gt;len = 1024;</div><div class="line">memcpy(pPack-&gt;data, source, 1024);</div></pre></td></tr></table></figure>
</li>
</ul>
<p>强制类型转换，将package类型的指针指向了申请的内存的开始，分为两个部分：前一部分表示字符串的长度，后一部分表示实际的内容。将整个数据包发出去，不会浪费一点额外的空间，在网络中传输节省了流量，提升了速度。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;C-C-中的0长数组&quot;&gt;&lt;a href=&quot;#C-C-中的0长数组&quot; class=&quot;headerlink&quot; title=&quot;C/C++中的0长数组&quot;&gt;&lt;/a&gt;C/C++中的0长数组&lt;/h3&gt;&lt;hr&gt;
&lt;p&gt;定义：柔性数组（Flexible Array）也叫伸缩性数组、变长数组。&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&quot;作用-：放入结构体中，可以存放动态长度的字符串、数组等。&quot;&gt;&lt;a href=&quot;#作用-：放入结构体中，可以存放动态长度的字符串、数组等。&quot; class=&quot;headerlink&quot; title=&quot;作用 ：放入结构体中，可以存放动态长度的字符串、数组等。&quot;&gt;&lt;/a&gt;作用 ：放入结构体中，可以存放动态长度的字符串、数组等。&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;用法举例：&lt;br&gt;&lt;br&gt;放在结构体的最后，长度为0的数组。长度为0不占用任何空间，数组名只是一个符号，代表了一个不可改变的地址。  &lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="学习" scheme="http://abumaster.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="C++" scheme="http://abumaster.com/tags/C/"/>
    
  </entry>
  
</feed>
